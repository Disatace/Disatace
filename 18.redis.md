# redis

[面试官：看你简历上有写Redis，来请讲下 (qq.com)](https://mp.weixin.qq.com/s/s6Hg_Z7sC5l07RxkJQXePw)



![img](https://pic1.zhimg.com/80/v2-dcde092d40c3105d494cd47b2333fa80_720w.webp)

## 什么是NoSQL 

NoSQL，指的是非关系型的数据库。NoSQL有时也称作Not Only SQL的缩写，是对不同于传统的关系 型数据库的数据库管理系统的统称。

- 优点：
  - 高可扩展性 
  - 分布式计算 
  - 低成本
  -  架构的灵活性，半结构化数据
  -  没有复杂的关系
- 缺点：
  - 没有标准化 
  - 有限的查询功能（到目前为止） 
  - 最终一致是不直观的程序

# 缓存的概念

缓存是为了调节速度不一致的两个或多个不同的物质的速度，在中间对速度较快的一方起到一个加速访 问速度较慢的一方的作用 

比如 CPU 的一级、二级缓存是保存了 CPU 最近经常访问的数据，内存是保存 CPU 经常访问硬盘的数 据，而且硬盘也有大小不一的缓存，甚至是物理服务器的 raid 卡有也缓存   

为了起到加速 CPU 访问硬盘数据的目的，因为 CPU 的速度太快了， CPU 需要的数据硬盘往往不能在短 时间内满足 CPU 的需求， 

因此 PCU 缓存、内存、 Raid 卡以及硬盘缓存就在一定程度上满足了 CPU 的数据需求，即 CPU 从缓存 读取数据可以大幅提高 CPU 的工作效率。

![image-20220209221522517](http://cdn.gtrinee.top/image-20220209221522517.png)



**缓存的位置**

- 客户端：浏览器
- 内存：本地服务器
- 硬盘

**缓存的特性**

- 自动过期：给缓存的数据加上有效时间，超出时间后自动过期删除 
- 过期时间：强制过期，源网站更新图片后 CDN 是不会更新的，需要强制是图片缓存过期 
- 命中率：即缓存的读取命中率

## 系统缓存

### buffer与cache

buffer：**缓冲**也叫写缓冲，一般用于写操作，可以将数据**先写入内存再写入磁盘**，buffer 一般用于写缓 冲，用于**解决不同介质的速度不一致的缓冲，先将数据临时写入到里自己最近的地方**，以提高写入速 度，CPU 会把数据先写到内存的**磁盘缓冲区**，然后就认为数据已经写入完成看，然后由内核在后续的时 间再写入磁盘，所以服务器突然断电会丢失内存中的部分数据。 

cache：**缓存**也叫读缓存，**一般用于读操作**，CPU 读文件从内存读，如果内存没有就先从硬盘读到内存 再读到 CPU，将需要频繁读取的数据放在里自己最近的缓存区域，下次读取的时候即可快速读取。



### 用户层缓存

**DNS 缓存** 

- 默认为 60 秒，即 60 秒之内在访问同一个域名就不再进行 DNS 解析 
- 查看 chrome 浏览器的 DNS 缓存：chrome://net-internals/#dns 
- DNS 预获取，仅在HTML5中支持，当一个页面中包含多个域名的时候浏览器会先尝试解析域名并 进行缓存，之后再使用的时候即可直接使用不需要再进行DNS 解析

![image-20230202170412755](http://cdn.gtrinee.top/image-20230202170412755.png)

## 浏览器缓存

### 最后修改时间 

系统调用会获取文件的最后修改时间，如果没有发生变化就返回给浏览器304 的状态码，表示没有发生 变化，然后浏览器就使用的本地的缓存展示资源。 

### Etag标记 

基于Etag标记是否一直做判断页面是否发生过变化，比如基于Nginx的Etag on来实现 

### 过期时间 expires

 以上两种都需要发送请求，即不管资源是否过期都要发送请求进行协商，这样会消耗不必要的时间，因 此有了缓存的过期时间 

Expire 是 HttpHeader 中代表资源的过期时间，由服务器端设置。如果带有 Expire ，则在 Expire 过期 前不会发生 Http 请求，直接从缓存中读取。用户强制 F5 例外 

第一次请求资源时,响应报文带有资源的过期时间，默认为30天，当前此方式使用的比较多，但是无法保 证客户的时间都是准确并且一致的，因此会加入一个最大生存周期，使用用户本地的时间计算缓存数据 是否超过多少天，假如过期时间Expires:为2028年，但是缓存的最大生存周期Cache-Control: maxage=315360000，计算为天等于3650天即10年

## 混合使用和缓存刷新 

通常 Last-Modified,Etag,Expire 是一起混合使用的

- 特别是 Last-Modified 和 Expire 经常一起使用，因为 Expire 可以让浏览器完全不发起 Http 请 求，而当浏览器强制 F5 的时候又有 Last-Modified ，这样就很好的达到了浏览器段缓存的效果。 
- Etag 和 Expire 一起使用时，先判断 Expire ，如果已经过期，再发起 Http 请求，如果 Etag 变化 了，则返回 200 响应。如果 Etag 没有变化,则返回 304 响应。 
- Last-Modified,Etag,Expires 三个同时使用时。先判断 Expire ，然后发送 Http 请求，服务器先判 断 last-modified ，再判断 Etag ，必须都没有过期，才能返回 304 响应。

**缓存刷新** 

-  第一次访问,获取最新数据,返回 200响应码
-  鼠标点击二次访问 (Cache),输入地址后回车,浏览器对所有没有过期的内容直接使用本地缓存。 
- F5或点刷新按钮, 会向服务器发送请求缓存协商信息,last-modified和etag会有影响,但expires本地 过期时间不受影响,无变化返回304
-  按Ctrl+F5强制刷新,所有缓存不再使用,直接连接服务器,获取最新数据,返回200响应码

### cookie 和 session

Cookie是访问某些网站以后在本地存储的一些网站相关的信息，下次再访问的时候减少一些步骤,比如加 密后的账户名密码等信息

Cookies是服务器在客户端浏览器上存储的小段文本并随每一个请求发送至同一个服务器，是一种实现 客户端保持状态的方案。

session称为会话信息，位于web服务器上，主要负责访问者与网站之间的交互，当浏览器请求http地址 时，可以基于之前的session实现会话保持、session共享等。

## session和cookie的区别

- cookie数据存放在客户端的浏览器上，session数据 放在服务器上。
- session对cookie的使用:session虽然保存在服务器上，但是其正常运行还是需要客户端浏览器的支持。**因为session需要使用cookie作为识别标志**
- cookie比session更不安全，别人可以分析存放在本地的cookie并进行cookie欺骗。(可考虑对cookie加密)
- session会在一定时间内保存在服务器上。当访问增多时，会比较占用服务器的内容，考虑到减轻服务器负担，可以考虑使用cookie 
- 单个cookie保存的数据不能超过4K，浏览器都限制一个站点最多保存20个cookie。session没有这种限制。

## CDN 缓存

**CDN是什么？**

简单的说，CDN是Content Delivery Network的简称，即“内容分发网络”的意思。一般我们所说的CDN加速，一般是指网站加速或者用户下载资源加速。

CDN可以理解为分布在每个县城的火车票代售点，用户在浏览网站的时候，CDN会选择一个离用户最近的CDN边缘节点来响应用户的请求，这样海南移动用户的请求就不会千里迢迢跑到北京电信机房的服务器（假设源站部署在北京电信机房）上了。

**CDN的优势很明显：**

（1）CDN节点解决了跨运营商和跨地域访问的问题，访问延时大大降低；

（2）大部分请求在CDN边缘节点完成，CDN起到了分流作用，减轻了源站的负载。

如果某个用户想要访问优酷的视频点播内容，那么：





![img](https://pic2.zhimg.com/80/v2-5e53690a7bfaace4a5a61d1c2bfab609_720w.jpg)





具体步骤：

①、当用户点击APP上的内容，APP会根据URL地址去**本地DNS**（域名解析系统）寻求IP地址解析。

②、本地DNS系统会将域名的解析权交给**CDN专用DNS服务器**。

③、CDN专用DNS服务器，将CDN的全局负载均衡设备IP地址返回用户。

④、用户向**CDN的负载均衡设备**发起内容URL访问请求。

⑤、CDN负载均衡设备根据用户IP地址，以及用户请求的内容URL，选择一台用户所属区域的**缓存服务器**。

⑥、负载均衡设备告诉用户这台缓存服务器的IP地址，让用户向所选择的缓存服务器发起请求。

⑦、用户向缓存服务器发起请求，缓存服务器响应用户请求，将用户所需内容传送到用户终端。

⑧、如果这台缓存服务器上并没有用户想要的内容，那么这台缓存服务器就要网站的**源服务器**请求内容。

⑨、源服务器返回内容给缓存服务器，缓存服务器发给用户，并根据用户自定义的缓存策略，判断要不要把内容缓存到缓存服务器上。

## CDN如何选择离用户最近的服务器提供服务

的全称是 Content Delivery Network，翻译过来就是内容分发网络。它在网络的边缘节点上提供了大量的缓存服务器，能够让用户在距离自己最近的边缘节点上就获取到请求的内容，而不用请求到更远（意味着耗时更长）的业务服务器，从而提高内容获取的速度，提升用户体验


CDN **将请求的服务器域名解析成距离用户最近的 IP 地址**具体是怎么做的呢？

关键在于三点：

- 利用 `CNAME` 的能力，把对 `www.test.com` 域名的解析变成对特定 CDN 域名的解析，例如下图中的 `www.test.com.cdn.dnsv1.com`
- CDN 服务商维护着一个巨大而精确的 IP 地址数据库，能根据用户客户端的 IP 判断出客户端所在的地区、网络运营商等信息。
- 当解析 `www.test.com.cdn.dnsv1.com` 域名 IP 时，会向 CDN 服务的 DNS 域名发起请求（也就是下图中的第 2 步），此时 CDN 服务的 DNS 域名可以根据用户客户端的 IP 返回一个距离它最近的缓存服务器 IP

腾讯云文档里有一个图画的非常清晰：

![CDN DNS](https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/4b5cbde22b704b5ca312c97fc3aaf9aa~tplv-k3u1fbpfcp-zoom-in-crop-mark:1304:0:0:0.awebp?)[](https://zhuanlan.zhihu.com/p/34464685)





# Redis介绍

Redis 是一个使用 **C 语言**写成的，开源的 **key-value** 数据库。和Memcached类似，它支持存储的value 类型相对更多， **包括string(字符串)、list(链表)、set(集合)、zset(sorted set –有序集合)和hash（哈希类 型）**。这些数据类型都支持 push/pop、add/remove及取交集并集和差集及更丰富的操作，而且这些操 作都是原子性的。在此基础上，redis支持各 种不同方式的排序。与memcached一样，**为了保证效率， 数据都是缓存在内存中**。区别的是**redis会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记 录文件**，并且在**此基础上实现了master-slave(主从)同步。**

## **Redis是单线程还是多线程呢？**

Redis不同版本之间采用的线程模型是不一样的，在Redis4.0版本之前使用的是单线程模型，在4.0版本之后增加了多线程的支持。

在4.0之前虽然我们说Redis是单线程，也只是说它的网络I/O线程以及Set 和 Get操作是由一个线程完成的。但是Redis的持久化、集群同步还是使用其他线程来完成。

4.0之后添加了多线程的支持，主要是体现在大数据的异步删除功能上，例如 `unlink key`、`flushdb async`、`flushall async` 等

### 单线程特点

1. Redis 的大部分操作都在内存中完成，内存中的执行效率本身就很快，并且采用了高效的数据结构，比如哈希表和跳表。
2. 使用单线程避免了多线程的竞争，省去了多线程切换带来的时间和性能开销，并且不会出现死锁。
3. 采用 I/O 多路复用机制处理大量客户端的Socket请求，因为这是基于非阻塞的 I/O 模型，这就让Redis可以高效地进行网络通信，I/O的读写流程也不再阻塞。

- 速度快，redis虽然式单线程架构，但是由于redis的数据是运行在内存中的，所以redis的运行速度 非常快
-  支持丰富的数据类型，具有五大基本数据类型 
- 支持事务
-  丰富的功能特性



# Redis单线程架构

- redis是单线程来处理命令的，所以一条命令从客户端到达服务端不会立刻被执行，所有命令都会 进入一个队列中，然后被执行。当然发送命令、返回结果、命令排队并不是像排队那么简单，redis采用了I/O多路复用的技术来解决I/O的问题 
- 既然是单线程架构为什么redis还能这么快？
  -  第一，纯内存访问，Redis将所有数据放在内存中，内存的响应时间大约为100纳秒，这是 redis达到每秒万级别的访问的重要基础 
  - 第二，非阻塞I/O，Redis使用**epoll作为I/O多路复用技术的实现**，再加上Redis自身的事件处 理模型将epoll中的连接、读写、关闭都转换为事件，不在网络I/O上浪费过多的时间 
  - 第三，单线程避免了线程切换和竞态产生的消耗 客户端与服务端请求过程

![image-20220422193510451](http://cdn.gtrinee.top/image-20220422193510451.png)

# 安装部署

```bash
[root@localhost ~]# yum install epel-release.noarch -y
[root@localhost ~]# yum install redis -y
```

## 相关文件

```bash
[root@localhost ~]# rpm -ql redis
/etc/redis.conf # 主配置文件
/usr/bin/redis-benchmark # redis性能检测工具
/usr/bin/redis-check-aof # AOF文件修复工具
/usr/bin/redis-check-rdb # 文件检查工具
/usr/bin/redis-cli # redis客户端
/usr/bin/redis-server # redis服务端
/usr/lib/systemd/system/redis.service # 守护进程
/var/lib/redis # redis数据目录
/var/log/redis # redis日志文件
```

### 配置文件

```bash
[root@node1 ~]# cat /etc/redis.conf | grep -Ev "^$|^#"
==================================基础配置=============================================
bind 127.0.0.1 # 绑定IP地址
protected-mode yes
port 6379 # 监听端口
tcp-backlog 511
timeout 0 # 设置客户端连接超时时间
tcp-keepalive 300 # 检测客户端是否健康的周期时间
daemonize yes # 是否以守护进程方式启动
supervised no
pidfile /var/run/redis_6379.pid # PID文件
loglevel notice # 日志等级
logfile /var/log/redis/redis.log # 日志文件
databases 16 # 设置数据库的数目
==================================RDB触发条件===========================================
save 900 1
save 300 10
save 60 10000
stop-writes-on-bgsave-error yes # 当启用了RDB且最后一次后台保存数据失败，Redis是否
停止接收数据
rdbcompression yes # 对于存储到磁盘中的快照，可以设置是否进行压缩存储
rdbchecksum yes # 在存储快照后，我们还可以让redis使用CRC64算法来进行数据校验
dbfilename dump.rdb # 设置快照的文件名
dir /var/lib/redis # 设置快照文件的存放路径
==================================主从复制=============================================
slave-serve-stale-data yes
slave-read-only yes # 配置Redis的Slave实例是否接受写操作
repl-diskless-sync no # 主从数据复制是否使用无硬盘复制功能
repl-diskless-sync-delay 5 # 等待时间
repl-disable-tcp-nodelay no # 同步之后是否禁用从站上的TCP_NODELAY
slave-priority 100
==================================AOF相关配置=============================================
appendonly no # 默认redis使用的是rdb方式持久化
appendfilename "appendonly.aof" # 文件名
appendfsync everysec # aof持久化策略的配置
no-appendfsync-on-rewrite no # 在aof重写或者写入rdb文件的时候，不执行持久化策略
auto-aof-rewrite-percentage 100 # 当目前aof文件大小超过上一次重写的aof文件大小的百分之多少进行重写
auto-aof-rewrite-min-size 64mb # 设置允许重写的最小aof文件大小
aof-load-truncated yes # 当截断的aof文件被导入的时候，会自动发布一个log给客户端然后
load。
lua-time-limit 5000 # 一个lua脚本执行的最大时间

```



## Redis启动、登录与关闭

```bash
#启动时使用命令redis-server，参数是配置文件(可以指定参数配置文件，也可以不指定使其默认加载)
1 [root@localhost ~]# redis-server /etc/redis.conf

[root@localhost ~]# redis-cli --help
redis-cli 3.2.12
Usage: redis-cli [OPTIONS] [cmd [arg [arg ...]]]
-h <hostname> Server hostname (default: 127.0.0.1).
-p <port> Server port (default: 6379).
-s <socket> Server socket (overrides hostname and port).
-a <password> Password to use when connecting to the server.
-r <repeat> Execute specified command N times.
-i <interval> When -r is used, waits <interval> seconds per command.
It is possible to specify sub-second times like -i 0.1.
-n <db> Database number.
-x Read last argument from STDIN.
-d <delimiter> Multi-bulk delimiter in for raw formatting (default:
\n).
-c Enable cluster mode (follow -ASK and -MOVED
redirections).
[root@localhost ~]# redis-cli -h 127.0.0.1 -p 6379
127.0.0.1:6379>
#关闭redis服务
127.0.0.1:6379> SHUTDOWN
not connected>
```

## redis基础命令

- KEY *  ：查看所有键，该命令在生产环境中慎用，会一次性读取所有键，可能会导致阻塞

- dbsize：查看当前数据库中的所有键的数量

- exists key：检查某个键是否存在，存在返回1，不存在返回0

```bash
ttl命令会返回键过期时间
大于等于0的整数，键剩余过期的时间
-2：键不存在
127.0.0.1:6379> EXPIRE k3 20
(integer) 1
127.0.0.1:6379> TTL k3
(integer) 13
127.0.0.1:6379> TTL k3
(integer) -2
127.0.0.1:6379> TTL k2
(integer) -1
127.0.0.1:6379> get k2
"v2"
127.0.0.1:6379> get k3
(nil)

127.0.0.1:6379> TYPE k2 #查看数据类型
string

```

## 字符串命令

下表列出了常用的 redis 字符串命令：

| 序号 | 命令及描述                                                   |
| :--- | :----------------------------------------------------------- |
| 1    | [SET key value](https://www.runoob.com/redis/strings-set.html) 设置指定 key 的值 |
| 2    | [GET key](https://www.runoob.com/redis/strings-get.html) 获取指定 key 的值。 |
| 3    | [GETRANGE key start end](https://www.runoob.com/redis/strings-getrange.html) 返回 key 中字符串值的子字符 |
| 4    | [GETSET key value](https://www.runoob.com/redis/strings-getset.html) 将给定 key 的值设为 value ，并返回 key 的旧值(old value)。 |
| 5    | [GETBIT key offset](https://www.runoob.com/redis/strings-getbit.html) 对 key 所储存的字符串值，获取指定偏移量上的位(bit)。 |
| 6    | [MGET key1 [key2..\]](https://www.runoob.com/redis/strings-mget.html) 获取所有(一个或多个)给定 key 的值。 |
| 7    | [SETBIT key offset value](https://www.runoob.com/redis/strings-setbit.html) 对 key 所储存的字符串值，设置或清除指定偏移量上的位(bit)。 |
| 8    | [SETEX key seconds value](https://www.runoob.com/redis/strings-setex.html) 将值 value 关联到 key ，并将 key 的过期时间设为 seconds (以秒为单位)。 |
| 9    | [SETNX key value](https://www.runoob.com/redis/strings-setnx.html) 只有在 key 不存在时设置 key 的值。 |
| 10   | [SETRANGE key offset value](https://www.runoob.com/redis/strings-setrange.html) 用 value 参数覆写给定 key 所储存的字符串值，从偏移量 offset 开始。 |
| 11   | [STRLEN key](https://www.runoob.com/redis/strings-strlen.html) 返回 key 所储存的字符串值的长度。 |
| 12   | [MSET key value [key value ...\]](https://www.runoob.com/redis/strings-mset.html) 同时设置一个或多个 key-value 对。 |
| 13   | [MSETNX key value [key value ...\]](https://www.runoob.com/redis/strings-msetnx.html) 同时设置一个或多个 key-value 对，当且仅当所有给定 key 都不存在。 |
| 14   | [PSETEX key milliseconds value](https://www.runoob.com/redis/strings-psetex.html) 这个命令和 SETEX 命令相似，但它以毫秒为单位设置 key 的生存时间，而不是像 SETEX 命令那样，以秒为单位。 |
| 15   | [INCR key](https://www.runoob.com/redis/strings-incr.html) 将 key 中储存的数字值增一。 |
| 16   | [INCRBY key increment](https://www.runoob.com/redis/strings-incrby.html) 将 key 所储存的值加上给定的增量值（increment） 。 |
| 17   | [INCRBYFLOAT key increment](https://www.runoob.com/redis/strings-incrbyfloat.html) 将 key 所储存的值加上给定的浮点增量值（increment） 。 |
| 18   | [DECR key](https://www.runoob.com/redis/strings-decr.html) 将 key 中储存的数字值减一。 |
| 19   | [DECRBY key decrement](https://www.runoob.com/redis/strings-decrby.html) key 所储存的值减去给定的减量值（decrement） 。 |
| 20   | [APPEND key value](https://www.runoob.com/redis/strings-append.html) 如果 key 已经存在并且是一个字符串， APPEND 命令将指定的 value 追加到该 key 原来值（value）的末尾。 |



### 列表命令

| 序号 | 命令及描述                                                   |
| :--- | :----------------------------------------------------------- |
| 1    | [BLPOP key1 [key2 \] timeout](https://www.runoob.com/redis/lists-blpop.html) 移出并获取列表的第一个元素， 如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。 |
| 2    | [BRPOP key1 [key2 \] timeout](https://www.runoob.com/redis/lists-brpop.html) 移出并获取列表的最后一个元素， 如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。 |
| 3    | [BRPOPLPUSH source destination timeout](https://www.runoob.com/redis/lists-brpoplpush.html) 从列表中弹出一个值，将弹出的元素插入到另外一个列表中并返回它； 如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。 |
| 4    | [LINDEX key index](https://www.runoob.com/redis/lists-lindex.html) 通过索引获取列表中的元素 |
| 5    | [LINSERT key BEFORE\|AFTER pivot value](https://www.runoob.com/redis/lists-linsert.html) 在列表的元素前或者后插入元素 |
| 6    | [LLEN key](https://www.runoob.com/redis/lists-llen.html) 获取列表长度 |
| 7    | [LPOP key](https://www.runoob.com/redis/lists-lpop.html) 移出并获取列表的第一个元素 |
| 8    | [LPUSH key value1 [value2\]](https://www.runoob.com/redis/lists-lpush.html) 将一个或多个值插入到列表头部 |
| 9    | [LPUSHX key value](https://www.runoob.com/redis/lists-lpushx.html) 将一个值插入到已存在的列表头部 |
| 10   | [LRANGE key start stop](https://www.runoob.com/redis/lists-lrange.html) 获取列表指定范围内的元素 |
| 11   | [LREM key count value](https://www.runoob.com/redis/lists-lrem.html) 移除列表元素 |
| 12   | [LSET key index value](https://www.runoob.com/redis/lists-lset.html) 通过索引设置列表元素的值 |
| 13   | [LTRIM key start stop](https://www.runoob.com/redis/lists-ltrim.html) 对一个列表进行修剪(trim)，就是说，让列表只保留指定区间内的元素，不在指定区间之内的元素都将被删除。 |
| 14   | [RPOP key](https://www.runoob.com/redis/lists-rpop.html) 移除列表的最后一个元素，返回值为移除的元素。 |
| 15   | [RPOPLPUSH source destination](https://www.runoob.com/redis/lists-rpoplpush.html) 移除列表的最后一个元素，并将该元素添加到另一个列表并返回 |
| 16   | [RPUSH key value1 [value2\]](https://www.runoob.com/redis/lists-rpush.html) 在列表中添加一个或多个值 |
| 17   | [RPUSHX key value](https://www.runoob.com/redis/lists-rpushx.html) 为已存在的列表添加值 |

### 哈希命令

在以上实例中，我们设置了 redis 的一些描述信息(name, description, likes, visitors) 到哈希表的 **runoobkey** 中。

下表列出了 redis hash 基本的相关命令：

```bash
hset key field value
127.0.0.1:6379> hset user:1 name tom
(integer) 1
```



| 序号 | 命令及描述                                                   |
| :--- | :----------------------------------------------------------- |
| 1    | [HDEL key field1 [field2\]](https://www.runoob.com/redis/hashes-hdel.html) 删除一个或多个哈希表字段 |
| 2    | [HEXISTS key field](https://www.runoob.com/redis/hashes-hexists.html) 查看哈希表 key 中，指定的字段是否存在。 |
| 3    | [HGET key field](https://www.runoob.com/redis/hashes-hget.html) 获取存储在哈希表中指定字段的值。 |
| 4    | [HGETALL key](https://www.runoob.com/redis/hashes-hgetall.html) 获取在哈希表中指定 key 的所有字段和值 |
| 5    | [HINCRBY key field increment](https://www.runoob.com/redis/hashes-hincrby.html) 为哈希表 key 中的指定字段的整数值加上增量 increment 。 |
| 6    | [HINCRBYFLOAT key field increment](https://www.runoob.com/redis/hashes-hincrbyfloat.html) 为哈希表 key 中的指定字段的浮点数值加上增量 increment 。 |
| 7    | [HKEYS key](https://www.runoob.com/redis/hashes-hkeys.html) 获取所有哈希表中的字段 |
| 8    | [HLEN key](https://www.runoob.com/redis/hashes-hlen.html) 获取哈希表中字段的数量 |
| 9    | [HMGET key field1 [field2\]](https://www.runoob.com/redis/hashes-hmget.html) 获取所有给定字段的值 |
| 10   | [HMSET key field1 value1 [field2 value2 \]](https://www.runoob.com/redis/hashes-hmset.html) 同时将多个 field-value (域-值)对设置到哈希表 key 中。 |
| 11   | [HSET key field value](https://www.runoob.com/redis/hashes-hset.html) 将哈希表 key 中的字段 field 的值设为 value 。 |
| 12   | [HSETNX key field value](https://www.runoob.com/redis/hashes-hsetnx.html) 只有在字段 field 不存在时，设置哈希表字段的值。 |
| 13   | [HVALS key](https://www.runoob.com/redis/hashes-hvals.html) 获取哈希表中所有值。 |
| 14   | [HSCAN key cursor [MATCH pattern\] [COUNT count]](https://www.runoob.com/redis/hashes-hscan.html) 迭代哈希表中的键值对。 |

### Redis 集合(Set)

Redis 的 Set 是 String 类型的无序集合。集合成员是唯一的，这就意味着集合中不能出现重复的数据。

```bash
sadd key element [element ...]
返回结果为添加成功的元素个数
127.0.0.1:6379> exists myset
(integer) 0
127.0.0.1:6379> sadd myset a b c
(integer) 3
127.0.0.1:6379> sadd myset a b
(integer) 0

```

| 序号 | 命令及描述                                                   |
| :--- | :----------------------------------------------------------- |
| 1    | [SADD key member1 [member2\]](https://www.runoob.com/redis/sets-sadd.html) 向集合添加一个或多个成员 |
| 2    | [SCARD key](https://www.runoob.com/redis/sets-scard.html) 获取集合的成员数 |
| 3    | [SDIFF key1 [key2\]](https://www.runoob.com/redis/sets-sdiff.html) 返回第一个集合与其他集合之间的差异。 |
| 4    | [SDIFFSTORE destination key1 [key2\]](https://www.runoob.com/redis/sets-sdiffstore.html) 返回给定所有集合的差集并存储在 destination 中 |
| 5    | [SINTER key1 [key2\]](https://www.runoob.com/redis/sets-sinter.html) 返回给定所有集合的交集 |
| 6    | [SINTERSTORE destination key1 [key2\]](https://www.runoob.com/redis/sets-sinterstore.html) 返回给定所有集合的交集并存储在 destination 中 |
| 7    | [SISMEMBER key member](https://www.runoob.com/redis/sets-sismember.html) 判断 member 元素是否是集合 key 的成员 |
| 8    | [SMEMBERS key](https://www.runoob.com/redis/sets-smembers.html) 返回集合中的所有成员 |
| 9    | [SMOVE source destination member](https://www.runoob.com/redis/sets-smove.html) 将 member 元素从 source 集合移动到 destination 集合 |
| 10   | [SPOP key](https://www.runoob.com/redis/sets-spop.html) 移除并返回集合中的一个随机元素 |
| 11   | [SRANDMEMBER key [count\]](https://www.runoob.com/redis/sets-srandmember.html) 返回集合中一个或多个随机数 |
| 12   | [SREM key member1 [member2\]](https://www.runoob.com/redis/sets-srem.html) 移除集合中一个或多个成员 |
| 13   | [SUNION key1 [key2\]](https://www.runoob.com/redis/sets-sunion.html) 返回所有给定集合的并集 |
| 14   | [SUNIONSTORE destination key1 [key2\]](https://www.runoob.com/redis/sets-sunionstore.html) 所有给定集合的并集存储在 destination 集合中 |
| 15   | [SSCAN key cursor [MATCH pattern\] [COUNT count]](https://www.runoob.com/redis/sets-sscan.html) 迭代集合中的元素 |

### Redis 有序集合(sorted set)

Redis 有序集合和集合一样也是 string 类型元素的集合,且不允许重复的成员。

不同的是每个元素都会关联一个 double 类型的分数。redis 正是通过分数来为集合中的成员进行从小到大的排序。

有序集合的成员是唯一的,但分数(score)却可以重复。

```
redis 127.0.0.1:6379> ZADD runoobkey 1 redis
(integer) 1
redis 127.0.0.1:6379> ZADD runoobkey 2 mongodb
(integer) 1
redis 127.0.0.1:6379> ZADD runoobkey 3 mysql
(integer) 1
redis 127.0.0.1:6379> ZADD runoobkey 3 mysql
(integer) 0
redis 127.0.0.1:6379> ZADD runoobkey 4 mysql
(integer) 0
redis 127.0.0.1:6379> ZRANGE runoobkey 0 10 WITHSCORES

1) "redis"
2) "1"
3) "mongodb"
4) "2"
5) "mysql"
6) "4"
```

## Redis丰富特性

Redis除了提供五大基本数据类型，还提供了丰富的功能强大的附加功能 

- 慢查询分析：通过慢查询分析，找到有问题的命令进行优化。 
- Redis Shell：功能强大的Redis Shell会有意想不到的实用功能。 Pipeline：通过Pipeline（管道或者流水线）机制有效提高客户端性能。 事务与Lua：制作自己的专属原子命令。 Bitmaps：通过在字符串数据结构上使用位操作，有效节省内存，为开 发提供新的思路。 HyperLogLog：一种基于概率的新算法，难以想象地节省内存空间。 ·发布订阅：基于发布订阅模 式的消息通信机制。 GEO：Redis3.2提供了基于地理位置信息的功能。

## 慢查询分析

```bash
#可以通过config set命令动态修改参数，并使配置持久化到配置文件中
config set slowlog-log-slower-than 20000 # 单位为微秒
config set slowlog-max-len 1000
config rewrite
下面操作返回当前Redis的慢查询，参数n可以指定条数：
127.0.0.1:6379> slowlog get

可以看到每个慢查询日志有4个属性组成，分别是慢查询日志的标识
id、发生时间戳、命令耗时、执行命令和参数
slowlog len
例如，当前Redis中有45条慢查询：
127.0.0.1:6379> slowlog len
(integer) 45
slowlog reset
实际是对列表做清理操作，例如：
127.0.0.1:6379> slowlog len
(integer) 45
127.0.0.1:6379> slowlog reset
OK
127.0.0.1:6379> slowlog len
(integer) 0

```

## Redis 事务

Redis 事务可以一次执行多个命令， 并且带有以下三个重要的保证：

- 批量操作在发送 EXEC 命令前被放入队列缓存。
- 收到 EXEC 命令后进入事务执行，事务中任意命令执行失败，其余的命令依然被执行。
- 在事务执行过程，其他客户端提交的命令请求不会插入到事务执行命令序列中。

一个事务从开始到执行会经历以下三个阶段：

- 开始事务。
- 命令入队。
- 执行事务。

------

## 实例

以下是一个事务的例子， 它先以 **MULTI** 开始一个事务， 然后将多个命令入队到事务中， 最后由 **EXEC** 命令触发事务， 一并执行事务中的所有命令：

```
redis 127.0.0.1:6379> MULTI
OK

redis 127.0.0.1:6379> SET book-name "Mastering C++ in 21 days"
QUEUED

redis 127.0.0.1:6379> GET book-name
QUEUED

redis 127.0.0.1:6379> SADD tag "C++" "Programming" "Mastering Series"
QUEUED

redis 127.0.0.1:6379> SMEMBERS tag
QUEUED

redis 127.0.0.1:6379> EXEC
1) OK
2) "Mastering C++ in 21 days"
3) (integer) 3
4) 1) "Mastering Series"
   2) "C++"
   3) "Programming"
```

单个 Redis 命令的执行是原子性的，但 Redis 没有在事务上增加任何维持原子性的机制，所以 Redis 事务的执行并不是原子性的。

事务可以理解为一个打包的批量执行脚本，但批量指令并非原子化的操作，中间某条指令的失败不会导致前面已做指令的回滚，也不会造成后续的指令不做。

> **这是官网上的说明 From redis docs on [transactions](http://redis.io/topics/transactions):**
>
> It's important to note that even when a command fails, all the other commands in the queue are processed – Redis will not stop the processing of commands.

比如：

```
redis 127.0.0.1:7000> multi
OK
redis 127.0.0.1:7000> set a aaa
QUEUED
redis 127.0.0.1:7000> set b bbb
QUEUED
redis 127.0.0.1:7000> set c ccc
QUEUED
redis 127.0.0.1:7000> exec
1) OK
2) OK
3) OK
```

如果在 set b bbb 处失败，set a 已成功不会回滚，set c 还会继续执行。



## Redis shell

redis-cli 详解 -r（repeat）选项代表将命令执行多次，例如下面操作将会执行三次ping 命令

```bash
redis-cli -r 3 ping
PONG
PONG
PONG

-i（interval）选项代表每隔几秒执行一次命令，但是-i选项必须和-r选 项一起使用，下面的操作会
每隔1秒执行一次ping命令，一共执行5次
$ redis-cli -r 5 -i 1 ping
PONG
PONG
PONG
PONG
PONG

-x选项代表从标准输入（stdin）读取数据作为redis-cli的最后一个参 数，例如下面的操作会将字符
串world作为set hello的值：
$ echo "world" | redis-cli -x set hello
OK

-c（cluster）选项是连接Redis Cluster节点时需要使用的，-c选项可以防 止moved和ask异常
如果Redis配置了密码，可以用-a（auth）选项，有了这个选项就不需要 手动输入auth命令
略

```

## redis-server 详解

redis-server- -test-memory可以用来检测当前操作系统能否稳定地分配指定容量的内存给 Redis， 通过这种检测可以有效避免因为内存问题造成Redis崩溃，例如下面 操作检测当前操作系统能否提 供1G的内存给Redis

`redis-server --test-memory 1024`

### **redis-benchmark详解**

 redis-benchmark可以为Redis做基准性能测试，它提供了很多选项帮助开 发和运维人员测试Redis 的相关性能 

-c（clients）选项代表客户端的并发数量（默认是50）。

 -n（num）选项代表客户端请求总量（默认是100000）。

 -q选项仅仅显示redis-benchmark的requests per second信息。 在一个空的Redis上执行了redis-benchmark会发现只有3个键, 如果想向Redis插入更多的键，可以 执行使用

-r（random）选项，可以向 Redis插入更多随机的键。

## Pipeline

- Redis提供了批量操作命令（例如mget、mset等），有效地节约RTT。但 大部分命令是不支持批量 操作的，例如要执行n次hgetall命令，并没有 mhgetall命令存在，需要消耗n次RTT。 
- Pipeline（流水线）机制能改善上面这类问题，它能将一组Redis命令进 行组装，通过一次RTT传输 给Redis，再将这组Redis命令的执行结果按顺序返回给客户端

![image-20220422200945644](http://cdn.gtrinee.top/image-20220422200945644.png)

## Bitmaps

```bash
setbit key offset value
127.0.0.1:6379> setbit unique:users:2016-04-05 0 1
(integer) 0
127.0.0.1:6379> setbit unique:users:2016-04-05 5 1
(integer) 0
127.0.0.1:6379> setbit unique:users:2016-04-05 11 1
(integer) 0
127.0.0.1:6379> setbit unique:users:2016-04-05 15 1
(integer) 0
127.0.0.1:6379> setbit unique:users:2016-04-05 19 1
(integer) 0
#获取值
getbit key offset
127.0.0.1:6379> getbit unique:users:2016-04-05 8
(integer) 0
#bitcount [start][end]
下面操作计算2016-04-05这天的独立访问用户数量：
127.0.0.1:6379> bitcount unique:users:2016-04-05
(integer) 5
[start]和[end]代表起始和结束字节数，下面操作计算用户id在第1个字节
到第3个字节之间的独立访问用户数，对应的用户id是11，15，19。
127.0.0.1:6379> bitcount unique:users:2016-04-05 1 3
(integer) 3

bitop是一个复合操作，它可以做多个Bitmaps的and（交集）、or（并
集）、not（非）、xor（异或）操作并将结果保存在destkey中。
bitop op destkey key[key....]
计算出2016-04-04和2016-04-03两天都访问过网站的用户数
127.0.0.1:6379> bitop and unique:users:and:2016-04-04_03 unique: users:2016-
04-03
unique:users:2016-04-03
(integer) 2
127.0.0.1:6379> bitcount unique:users:and:2016-04-04_03
(integer) 2
```

![image-20220209232755984](http://cdn.gtrinee.top/image-20220209232755984.png)

# 消息队列

消息队列: 把要传输的数据放在队列中 

功能: 可以实现多个系统之间的解耦,异步,削峰/限流等 

常用的消息队列应用: kafka,rabbitMQ,redis



消息队列主要分为两种,这两种模式Redis都支持

-  生产者/消费者模式
-  发布者/订阅者模式

队列当中的消息由不同的生产者写入，也会有不同的消费者取出进行消费处理，但是一个消息一定是只 能被取出一次也就是被消费一次。

- 生产者发布消息

```bash
[root@localhost ~]# redis-cli
127.0.0.1:6379> lpush channel1 msg1
(integer) 1
127.0.0.1:6379> lpush channel1 msg2
(integer) 2
127.0.0.1:6379> lpush channel1 msg3
(integer) 3
127.0.0.1:6379> lpush channel1 msg4
(integer) 4
127.0.0.1:6379> lpush channel1 msg5
(integer) 5
```

- 查看队列消息

```bash
127.0.0.1:6379> lrange channel1 0 -1
1) "msg5"
2) "msg4"
3) "msg3"
4) "msg2"
5) "msg1"
#消费者消费消息
127.0.0.1:6379> rpop channel1
"msg1"
127.0.0.1:6379> rpop channel1
"msg2"
127.0.0.1:6379> rpop channel1
"msg3"
127.0.0.1:6379> rpop channel1
"msg4"
127.0.0.1:6379> rpop channel1
"msg5"
127.0.0.1:6379> rpop channel1
(nil)
```

## 发布订阅 

Redis提供了基于“发布/订阅”模式的消息机制，此种模式下，消息发布 者和订阅者不进行直接通信，发 布者客户端向指定的频道（channel）发布消 息，订阅该频道的每个客户端都可以收到该消息

Redis 发布订阅 (pub/sub) 是一种消息通信模式：发送者 (pub) 发送消息，订阅者 (sub) 接收消息。

Redis 客户端可以订阅任意数量的频道。

下图展示了频道 channel1 ， 以及订阅这个频道的三个客户端 —— client2 、 client5 和 client1 之间的关系：

![img](https://www.runoob.com/wp-content/uploads/2014/11/pubsub1.png)

当有新消息通过 PUBLISH 命令发送给频道 channel1 时， 这个消息就会被发送给订阅它的三个客户端：

![img](https://www.runoob.com/wp-content/uploads/2014/11/pubsub2.png)

## 实例

以下实例演示了发布订阅是如何工作的，需要开启两个 redis-cli 客户端。

在我们实例中我们创建了订阅频道名为 **runoobChat**:

## 第一个 redis-cli 客户端

```bash
redis 127.0.0.1:6379> SUBSCRIBE runoobChat

Reading messages... (press Ctrl-C to quit)
1) "subscribe"
2) "runoobChat"
3) (integer) 1

```



现在，我们先重新开启个 redis 客户端，然后在同一个频道 runoobChat 发布两次消息，订阅者就能接收到消息。

## 第二个 redis-cli 客户端

```bash
redis 127.0.0.1:6379> PUBLISH runoobChat "Redis PUBLISH test"

(integer) 1

redis 127.0.0.1:6379> PUBLISH runoobChat "Learn redis by runoob.com"

(integer) 1

```



\# 订阅者的客户端会显示如下消息
 \1) "message"
\2) "runoobChat"
\3) "Redis PUBLISH test"
 \1) "message"
\2) "runoobChat"
\3) "Learn redis by runoob.com"





# Redis GEO

Redis GEO 主要用于存储地理位置信息，并对存储的信息进行操作，该功能在 Redis 3.2 版本新增。

Redis GEO 操作方法有：

- geoadd：添加地理位置的坐标。
- geopos：获取地理位置的坐标。
- geodist：计算两个位置之间的距离。
- georadius：根据用户给定的经纬度坐标来获取指定范围内的地理位置集合。
- georadiusbymember：根据储存在位置集合里面的某个地点获取指定范围内的地理位置集合。
- geohash：返回一个或多个位置对象的 geohash 值。

### geoadd

geoadd 用于存储指定的地理空间位置，可以将一个或多个经度(longitude)、纬度(latitude)、位置名称(member)添加到指定的 key 中。

geoadd 语法格式如下：

```
GEOADD key longitude latitude member [longitude latitude member ...]
```

以下实例中 key 为 Sicily，Palermo 和 Catania 为位置名称 ：

## 实例

redis**>** GEOADD Sicily 13.361389 38.115556 "Palermo" 15.087269 37.502669 "Catania"
**(**integer**)** 2
redis**>** GEODIST Sicily Palermo Catania
"166274.1516"
redis**>** GEORADIUS Sicily 15 37 100 km
1**)** "Catania"
redis**>** GEORADIUS Sicily 15 37 200 km
1**)** "Palermo"
2**)** "Catania"
redis**>**

### geopos

geopos 用于从给定的 key 里返回所有指定名称(member)的位置（经度和纬度），不存在的返回 nil。

geopos 语法格式如下：

```
GEOPOS key member [member ...]
```

## 实例

redis**>** GEOADD Sicily 13.361389 38.115556 "Palermo" 15.087269 37.502669 "Catania"
**(**integer**)** 2
redis**>** GEOPOS Sicily Palermo Catania NonExisting
1**)** 1**)** "13.36138933897018433"
  2**)** "38.11555639549629859"
2**)** 1**)** "15.08726745843887329"
  2**)** "37.50266842333162032"
3**)** **(**nil**)**
redis**>**

### geodist

geodist 用于返回两个给定位置之间的距离。

geodist 语法格式如下：

```
GEODIST key member1 member2 [m|km|ft|mi]
```

member1 member2 为两个地理位置。

最后一个距离单位参数说明：

- m ：米，默认单位。

- km ：千米。

- mi ：英里。

- ft ：英尺。

- \> 计算 Palermo 与 Catania 之间的距离：

- 

- ## 实例

- redis**>** GEOADD Sicily 13.361389 38.115556 "Palermo" 15.087269 37.502669 "Catania"
  **(**integer**)** 2
  redis**>** GEODIST Sicily Palermo Catania
  "166274.1516"
  redis**>** GEODIST Sicily Palermo Catania km
  "166.2742"
  redis**>** GEODIST Sicily Palermo Catania mi
  "103.3182"
  redis**>** GEODIST Sicily Foo Bar
  **(**nil**)**
  redis**>**

- ### georadius、georadiusbymember

- georadius 以给定的经纬度为中心， 返回键包含的位置元素当中， 与中心的距离不超过给定最大距离的所有位置元素。

- georadiusbymember 和 GEORADIUS 命令一样， 都可以找出位于指定范围内的元素， 但是 georadiusbymember 的中心点是由给定的位置元素决定的， 而不是使用经度和纬度来决定中心点。

- georadius 与 georadiusbymember 语法格式如下：

- ```
  GEORADIUS key longitude latitude radius m|km|ft|mi [WITHCOORD] [WITHDIST] [WITHHASH] [COUNT count] [ASC|DESC] [STORE key] [STOREDIST key]
  GEORADIUSBYMEMBER key member radius m|km|ft|mi [WITHCOORD] [WITHDIST] [WITHHASH] [COUNT count] [ASC|DESC] [STORE key] [STOREDIST key]
  ```

- 参数说明：

- - m ：米，默认单位。
  - km ：千米。
  - mi ：英里。
  - ft ：英尺。
  - WITHDIST: 在返回位置元素的同时， 将位置元素与中心之间的距离也一并返回。
  - WITHCOORD: 将位置元素的经度和纬度也一并返回。
  - WITHHASH: 以 52 位有符号整数的形式， 返回位置元素经过原始 geohash 编码的有序集合分值。 这个选项主要用于底层应用或者调试， 实际中的作用并不大。
  - COUNT 限定返回的记录数。
  - ASC: 查找结果根据距离从近到远排序。
  - DESC: 查找结果根据从远到近排序。

- georadius 实例：

- ## 实例

- redis**>** GEOADD Sicily 13.361389 38.115556 "Palermo" 15.087269 37.502669 "Catania"
  **(**integer**)** 2
  redis**>** GEORADIUS Sicily 15 37 200 km WITHDIST
  1**)** 1**)** "Palermo"
    2**)** "190.4424"
  2**)** 1**)** "Catania"
    2**)** "56.4413"
  redis**>** GEORADIUS Sicily 15 37 200 km WITHCOORD
  1**)** 1**)** "Palermo"
    2**)** 1**)** "13.36138933897018433"
     2**)** "38.11555639549629859"
  2**)** 1**)** "Catania"
    2**)** 1**)** "15.08726745843887329"
     2**)** "37.50266842333162032"
  redis**>** GEORADIUS Sicily 15 37 200 km WITHDIST WITHCOORD
  1**)** 1**)** "Palermo"
    2**)** "190.4424"
    3**)** 1**)** "13.36138933897018433"
     2**)** "38.11555639549629859"
  2**)** 1**)** "Catania"
    2**)** "56.4413"
    3**)** 1**)** "15.08726745843887329"
     2**)** "37.50266842333162032"
  redis**>**

- georadiusbymember 实例：

- ## 实例

- redis**>** GEOADD Sicily 13.583333 37.316667 "Agrigento"
  **(**integer**)** 1
  redis**>** GEOADD Sicily 13.361389 38.115556 "Palermo" 15.087269 37.502669 "Catania"
  **(**integer**)** 2
  redis**>** GEORADIUSBYMEMBER Sicily Agrigento 100 km
  1**)** "Agrigento"
  2**)** "Palermo"
  redis**>**

- ### geohash

- Redis GEO 使用 geohash 来保存地理位置的坐标。

- geohash 用于获取一个或多个位置元素的 geohash 值。

- geohash 语法格式如下：

- ```
  GEOHASH key member [member ...]
  ```

- 实例：

- ## 实例

- redis**>** GEOADD Sicily 13.361389 38.115556 "Palermo" 15.087269 37.502669 "Catania"
  **(**integer**)** 2
  redis**>** GEOHASH Sicily Palermo Catania
  1**)** "sqc8b49rny0"
  2**)** "sqdtr74hyu0"
  redis**>**

# 数据持久化



Redis数据是存储在内存中的，为了保证Redis数据不丢失，那就要把**数据从内存存储到磁盘上**，以便在服务器重启后还能够从磁盘中恢复原有数据，这就是Redis的数据持久化。Redis数据持久化有三种方式。

- **AOF 日志（Append Only File，文件追加方式）：记录所有的操作命令，并以文本的形式追加到文件中。**
- **RDB 快照（Redis DataBase）：将某一个时刻的内存数据，以二进制的方式写入磁盘。**
- **混合持久化方式：Redis 4.0 新增了混合持久化的方式，集成了 RDB 和 AOF 的优点**。

## RDB持久化

# 一定要看！！

[16张图带你吃透Redis架构演进 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/349241304)

### 简介 

- RDB持久是把当前数据生成快照保存到硬盘的过程 
- 触发RDB持久化过程为手动触发和自动触发 
- 优点：
  -  RDB是一个非常紧凑(compact)的文件，它保存了redis 在某个时间点上的数据集。这种文件**非常适合用于进 行备份和灾难恢复。** 
  - RDB 在恢复大数据集时的速度比 AOF 的**恢复速度要快**。
-  缺点：
  -  RDB方式数据**没办法做到实时持久化/秒级持久化**。因为bgsave每次运行都要执行fork操作创 建子进程，属于 重量级操作(内存中的数据被克隆了一份，大致2倍的膨胀性需要考虑)，频繁 执行成本过高(影响性能) 
  - RDB文件使用**特定二进制格式保存**，Redis版本演进过程中有多个格式的RDB版本，存在**老版 本Redis服务无 法兼容新版RDB格**式的问题(版本不兼容)
  -  在一定间隔时间做一次备份，所以如果redis意外down掉的话，就会丢失最后一次快照后的所 有修改(数据有 丢失)

- 手动触发 
  - save命令：阻塞当前Redis服务器，直到RDB过程完成为止，对于内存 比较大的实例会造成 长时间阻塞，线上环境不建议使用。 
  - bgsave命令：Redis进程执行fork操作创建子进程，RDB持久化过程由子 进程负责，完成后 自动结束。阻塞只发生在fork阶段，一般时间很短。 
  - 默认情况下执行shutdown命令时，如果没有开启AOF持久化功能则 自动执行bgsave。

![image-20220422202521694](http://cdn.gtrinee.top/image-20220422202521694.png)



打开 redis.conf 文件，找到 SNAPSHOTTING 对应内容
1 RDB核心规则配置（重点）

```cpp
save <seconds> <changes>
# save ""
save 900 1
save 300 10
save 60 10000
```

解说：save <指定时间间隔> <执行指定次数更新操作>，满足条件就将内存中的数据同步到硬盘中。官方出厂配置默认是 900秒内有1个更改，300秒内有10个更改以及60秒内有10000个更改，则将内存中的数据快照写入磁盘。
若不想用RDB方案，可以把 save "" 的注释打开，下面三个注释。

2 指定本地数据库文件名，一般采用默认的 dump.rdb

```lua
dbfilename dump.rdb
```

3 指定本地数据库存放目录，一般也用默认配置

```bash
dir ./
```

4 默认开启数据压缩

```bash
rdbcompression yes
```

解说：配置存储至本地数据库时是否压缩数据，默认为yes。Redis采用LZF压缩方式，但占用了一点CPU的时间。若关闭该选项，但会导致数据库文件变的巨大。建议开启。



## AOF

- 以**独立日志的方式记录每次写命令**，重启时再重新执行AOF文 件中的命令达到恢复数据的目的。
- AOF 持久化的方法提供了多种的同步频率，即使使用**默认的同步频率每秒同步一次**，Redis 最 多也就丢失 1 秒的数据而已。

缺点

- 对于具有相同数据的的 Redis，**AOF 文件通常会比 RDB 文件体积更大**。 
- 虽然 AOF 提供了多种同步的频率，默认情况下，每秒同步一次的频率也具有较高的性能。但 在 Redis 的负载 较高时，RDB 比 AOF 具好更好的性能保证。
-  RDB 使用快照的形式来持久化整个 Redis 数据，而 AOF 只是将每次执行的命令追加到 AOF 文件中，因此从 理论上说，RDB 比 AOF 方式更健壮。官方文档也指出，AOF 的确也存在一 些 BUG，这些 BUG 在 RDB 没有 存在。

```bash
#开启AOF功能需要设置配置：appendonly yes，默认不开启。AOF文件名 通过appendfilename配置设置，默认文件名是appendonly.aof。保存路径同 RDB持久化方式一致，通过dir配置指定。

appendonly yes # 将配置文件中appendonly字段设置为yes即可
```

![image-20220209234430076](http://cdn.gtrinee.top/image-20220209234430076.png)

1. 所有的写入命令会追加到aof_buf（缓冲区）中。 
2.  AOF缓冲区根据对应的策略向硬盘做同步操作。 3
3. 随着AOF文件越来越大，需要定期对AOF文件进行重写，达到压缩 的目的。 
4.  当Redis服务器重启时，可以加载AOF文件进行数据恢复。

# 后写日志主要有两个风险

好吧，后写日志主要有两个风险可能会发生：

- 数据可能会丢失：如果 Redis 刚执行完命令，此时发生故障宕机，会导致这条命令存在丢失的风险。
- 可能阻塞其他操作：AOF 日志其实也是在主线程中执行，所以当 Redis 把日志文件写入磁盘的时候，还是会阻塞后续的操作无法执行。

我还有个问题是 **RDB做快照时会阻塞线程吗？**

小张：

Redis 提供了两个命令来生成 RDB 快照文件，分别是 `save` 和 `bgsave`。`save` 命令在主线程中执行，会导致阻塞。而 `bgsave` 命令则会创建一个子进程，用于写入 RDB 文件的操作，避免了对主线程的阻塞，这也是 Redis RDB 的默认配置。

面试官：

**RDB 做快照的时候数据能修改吗？**

save是同步的会阻塞客户端命令，bgsave的时候是可以修改的。

小张：

save是同步的会阻塞客户端命令，bgsave的时候是可以修改的。



这里主要是利用`bgsave`的子线程实现的，具体操作如下：

- 如果主线程执行读操作，则主线程和 `bgsave` 子进程互相不影响；
- 如果主线程执行写操作，则被修改的数据会复制一份副本，然后 `bgsave`子进程会把该副本数据写入 RDB 文件，在这个过程中，主线程仍然可以直接修改原来的数据。

![图片](https://mmbiz.qpic.cn/mmbiz_png/PxMzT0Oibf4gQQkD0EnlcIxFe4YtTDiaYEdQp9Kr3eOobTBrY7nctUSwD8TduMRjMcxr9J5AqNKEW9b5r2xMDI9w/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

要注意，Redis 对 RDB 的执行频率非常重要，因为这会影响快照数据的完整性以及 Redis 的稳定性，所以在 Redis 4.0 后，**增加了 AOF 和 RDB 混合的数据持久化机制：** 把数据以 RDB 的方式写入文件，再将后续的操作命令以 AOF 的格式存入文件，既保证了 Redis 重启速度，又降低数据丢失风险。



## 重写机制

随着命令不断写入AOF，文件会越来越大，为了解决这个问题，Redis 引入AOF重写机制压缩文件体 积。

- 重写后的AOF文件会变小，原因如下
  -  进程内已经超时的数据不再写入文件。 旧的AOF文件含有无效命令，如del key1、hdel key2、srem keys、set a111、set a222等。
  -  重写使用进程内数据直接生成，这样新的AOF文件只保 留最终数据的写入命令。
  -  多条写命令可以合并为一个，如：lpush list a、lpush list b、lpush list c可以转化为：lpush list a b c。为了防止单条命令过大造成客户端缓冲区溢 出，对于list、set、hash、zset等类型 操作，以64个元素为界拆分为多条。 
- 手动触发：直接调用bgrewriteaof命令 
- 自动触发：根据auto-aof-rewrite-min-size和auto-aof-rewrite-percentage参 数确定自动触发时 机。

![image-20220422202918015](http://cdn.gtrinee.top/image-20220422202918015.png)

1. 执行AOF重写请求。 
2. 父进程执行fork创建子进程，开销等同于bgsave过程。 
   1. 主进程fork操作完成后，继续响应其他命令。所有修改命令依然写 入AOF缓冲区并根据 appendfsync策略同步到硬盘，保证原有AOF机制正确 性。 
   2.  由于fork操作运用写时复制技术，子进程只能共享fork操作时的内 存数据。由于父进程依然响 应命令，Redis使用“AOF重写缓冲区”保存这部 分新数据，防止新AOF文件生成期间丢失这部分数 据。 
3.  子进程根据内存快照，按照命令合并规则写入到新的AOF文件。每 次批量写入硬盘数据量由配置 aof-rewrite-incremental-fsync控制，默认为 32MB，防止单次刷盘数据过多造成硬盘阻塞。

## 重启加载持久化文件

![image-20220422203032964](http://cdn.gtrinee.top/image-20220422203032964.png)

1. AOF持久化开启且存在AOF文件时，优先加载AOF文件 
2.  AOF关闭或者AOF文件不存在时，加载RDB文件 
3.  加载AOF/RDB文件成功后，Redis启动成功。 
4. AOF/RDB文件存在错误时，Redis启动失败并打印错误信息。





# 架构——主从复制

- 在分布式系统中为了解决单点问题，通常会把数据复制多个副本部署到其他机器，满足故障恢复和 负载均衡等需求。Redis也是如此，它为我们提供了复制功能，实现了相同数据的多个Redis副本。 复制功能是高可用Redis 的基础，后面章节的哨兵和集群都是在复制的基础上实现高可用的。 
- 优点
  - 满足故障和负载均衡等需求
-  缺点
  - 若主节点出现问题，则不能提供服务，需要人工修改配置将从变主，无法实现高可用
  - 主从复制主节点的写能力有限 
  - 单机节点的存储能力有限

# 数据同步方式

## 全量同步

- Redis全量复制一般发生在Slave初始化阶段，这时Slave需要将Master上的所有数据都复制一份。 步骤如下：
  - 从服务器连接主服务器，发送SYNC命令；
  - 主服务器接收到SYNC命名后，开始执行BGSAVE命令生成RDB文件并使用缓冲区记录此后执 行的所有写命令；
  - 主服务器BGSAVE执行完后，向所有从服务器发送快照文件，并在发送期间继续记录被执行的 写命令； 
  - 从服务器收到快照文件后丢弃所有旧数据，载入收到的快照； 
  - 主服务器快照发送完毕后开始向从服务器发送缓冲区中的写命令； 
  - 从服务器完成对快照的载入，开始接收命令请求，并执行来自主服务器缓冲区的写命令；

## 增量同步

- Redis增量复制是指Slave初始化后开始正常工作时主服务器发生的写操作同步到从服务器的过程。
- 增量复制的过程主要是主服务器每执行一个写命令就会向从服务器发送相同的写命令，从服务器接收并执行收到的写命令。

## 同步策略

- 主从刚刚连接的时候，进行全量同步；全同步结束后，进行增量同步。当然，如果有需要，slave 在任何时候都可 以发起全量同步。redis 策略是，无论如何，首先会尝试进行增量同步，如不成 功，要求从机进行全量同步。

## 部署主从复制

- 一台主服务器的配置文件

```bash
#/bin/bash
mkdir /usr/local/redis/{data,conf,log} -pv
cat << EOF > /usr/local/redis/conf/redis6380.conf
bind 127.0.0.1
port 6380
daemonize yes
pidfile /usr/local/redis/redis_6380.pid
loglevel notice
logfile /usr/local/redis/log/redis_6380.log
dir /usr/local/redis/data/
EOF 
```

- 两台从服务器的配置文件

```bash
cat << EOF > /usr/local/redis/conf/redis6381.conf
bind 127.0.0.1
port 6381
daemonize yes 
pidfile /usr/local/redis/redis_6381.pid
loglevel notice
logfile /usr/local/redis/redis_6381.log
dir /usr/local/redis/data/
slaveof 127.0.0.1 6380
EOF
cat << EOF > /usr/local/redis/conf/redis6382.conf
bind 127.0.0.1
port 6382
daemonize yes
pidfile /usr/local/redis/redis_6382.pid
loglevel notice
logfile /usr/local/redis/redis_6382.log
dir /usr/local/redis/data/
slaveof 127.0.0.1 6380
EOF
```

- 启动则完成主从复制架构的部署

```bash
redis-server /usr/local/redis/conf/redis6380.conf
redis-server /usr/local/redis/conf/redis6381.conf
redis-server /usr/local/redis/conf/redis6382.conf
```

验证测试

```bash
127.0.0.1:6380> info Replication
# Replication
role:master
connected_slaves:2
slave0:ip=127.0.0.1,port=6381,state=online,offset=1334,lag=1
slave1:ip=127.0.0.1,port=6382,state=online,offset=1334,lag=1
master_repl_offset:1334
repl_backlog_active:1
repl_backlog_size:1048576
repl_backlog_first_byte_offset:2
repl_backlog_histlen:1333
127.0.0.1:6380> set name yingges
OK
127.0.0.1:6380> exit
[root@node1 ~]# redis-cli -p 6381
127.0.0.1:6381> get name
"yingges"
127.0.0.1:6381> set name2 redis
(error) READONLY You can't write against a read only slave.
```

- 建议可以使用三台机器部署实验，ip地址分别改为新的地址，因为主从复制在一台机器上没有现实意义



# 架构——哨兵

## 简介

- Redis的主从复制模式下，一旦主节点由于故障不能提供服务，需要**人工将从节点晋升为主节点**， 同时还要通知应用方更新主节点地址，对于很多 应用场景这种故障处理的方式是无法接受的。 
- **Redis较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂**。

## 工作原理

- 每个哨兵(sentinel) 会向其它哨兵(sentinel)、master、slave定时发送消息,以确认对方是否”活”着, 如果发现对方在指定时间( down-after-milliseconds项 )内未回应,则暂时认为对方已挂(主观宕机:sdown)，若“哨兵群”中的多数 sentinel,都报告某一master没响应,系统才认为该master”彻底死 亡”(即:客观上的真正down机:odown),**通过一定的 vote算法,从剩下的slave节点中,选一台提升为 master,然后自动修改相关配置。**

![image-20220422215010833](http://cdn.gtrinee.top/image-20220422215010833.png)



# 实验部署

- 部署哨兵1：监听26378端口

```bash
#!/bin/bash
cat << EOF > /usr/local/redis/conf/redis-sentinel26738.conf
port 26378
daemonize yes
dir "/tmp"
sentinel monitor mymaster 127.0.0.1 6380 2
sentinel down-after-milliseconds mymaster 60000
sentinel failover-timeout mymaster 180000
sentinel parallel-syncs mymaster 1
logfile "/usr/local/redis/log/sentinel.log.26378"
EOF
```

- 配置哨兵2：监听26379端口

```bash
#!/bin/bash
cat << EOF > /usr/local/redis/conf/redis-sentinel26739.conf
port 26379
daemonize yes
dir "/tmp"
sentinel monitor mymaster 127.0.0.1 6380 2
sentinel down-after-milliseconds mymaster 60000
sentinel failover-timeout mymaster 180000
sentinel parallel-syncs mymaster 1
logfile "/usr/local/redis/log/sentinel.log.26379"
EOF
```

- 启动哨兵服务

```bash
[root@master redis]# redis-sentinel /usr/local/redis/conf/redissentinel26739.conf
[root@master redis]# redis-sentinel /usr/local/redis/conf/redissentinel26738.conf
```

- 通常情况下我们尽量启动3个哨兵(奇数)及以上监听一个主节点。
- 验证测试

```bash
关闭master上redis服务
查看日志字段：
+switch-master mymaster 127.0.0.1 6380 127.0.0.1 6382
master切换
重启旧master上redis服务
查看日志字段：
+convert-to-slave slave 127.0.0.1:6380 127.0.0.1 6380 @ mymaster 127.0.0.1
6382
成为slave
127.0.0.1:6382> info Replication
# Replication
role:master
connected_slaves:2
slave0:ip=127.0.0.1,port=6381,state=online,offset=131255,lag=0
slave1:ip=127.0.0.1,port=6380,state=online,offset=131388,lag=0
master_repl_offset:131388
repl_backlog_active:1
repl_backlog_size:1048576
repl_backlog_first_byte_offset:2
repl_backlog_histlen:131387
```



# 架构——集群

**Redis Cluster（集群）**

Redis Cluster 是一种分布式去中心化的运行模式，是在 Redis 3.0 版本中推出的 Redis 集群方案，它将数据分布在不同的服务器上，以此来降低系统对单主节点的依赖，从而提高 Redis 服务的读写性能。

![图片](https://mmbiz.qpic.cn/mmbiz_png/PxMzT0Oibf4gQQkD0EnlcIxFe4YtTDiaYEPD7tSnKYtda6EqFftoP9bXhwLvNCBFZKcbfltueJM6oIl67qeiav96g/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

面试官：

使用哨兵模式在数据上有副本数据做保证，在可用性上又有哨兵监控，一旦master宕机会选举salve节点为master节点，这种已经满足了我们的生产环境需要，**那为什么还需要使用集群模式呢？**

小张：

额，哨兵模式归根节点还是主从模式，在主从模式下我们可以 通过增加salve节点来扩展读并发能力，但是没办法扩展写能力和存储能力，存储能力只能是master节点能够承载的上限。所以为了扩展写能力和存储能力，我们就需要引入集群模式。

- redis的哨兵模式基本已经可以实现高可用，读写分离 ，但是在这种模式下**每台redis服务器都存储 相同的数据，很浪费内存**  ，所以在redis3.0上**加入了cluster模式**，实现的redis的**分布式存储，也 就是说每台redis节点上存储不同的内容**。
-  优点 
  - 将Redis的写操作分摊到了多个节点上，**提高写的并发能力，扩容简单** 
- 缺点 
  - 每个Node承担着互相监听、**高并发数据写入、高并发数据读出，工作任务繁重**



## 工作原理

- 对象保存到Redis之前先经过CRC16哈希到一个指定的Node上。 
- 每个Node被平均分配了一个Slot段，对应着0-16384，Slot不能重复也不能缺失，否则会导致对象 重复存储或无法 存储。
-  Node之间也互相监听，一旦有Node退出或者加入，会按照Slot为单位做数据的迁移。例如Node1 如果掉线了，0- 5640这些Slot将会平均分摊到Node2和Node3上,由于Node2和Node3本身维护的 Slot还会在自己身上不会被重新 分配，所以迁移过程中不会影响到5641-16384Slot段的使用。

![image-20220422221814476](http://cdn.gtrinee.top/image-20220422221814476.png)



# 实验部署

- 环境准备

```bash
#!/bin/bash
yum install gcc-c++ -y
wget http://download.redis.io/releases/redis-5.0.4.tar.gz
tar xzf redis-5.0.4.tar.gz
cd redis-5.0.4
make install PREFIX=/usr/local/redis
PATH=$PATH:/usr/local/redis/bin
```

- 部署

```bash
[root@node2 ~]# mkdir /usr/local/redis-cluster
[root@node2 ~]# cd /usr/local/redis-cluster/
[root@node2 redis-cluster]# bash -x redis-cluster.sh
#!/bin/bash
mkdir /usr/local/redis-cluster/redis{7000..7005} -pv
touch /usr/local/redis-cluster/redis{7000..7005}/redis.conf
#!/bin/bash
for i in {7000..7005};
do
cat << EOF > /usr/local/redis-cluster/redis$i/redis.conf
daemonize yes
port $i
cluster-enabled yes
cluster-config-file /usr/local/redis-cluster/redis$i/nodes-$i.conf
cluster-node-timeout 5000
appendonly yes
EOF
redis-server /usr/local/redis-cluster/redis$i/redis.conf
done
#检查各进程是否ok


[root@node2 local]# ps -ef | grep redis
root 5761 1 0 03:46 ? 00:00:00 redis-server *:7000 [cluster]
root 5767 1 0 03:46 ? 00:00:00 redis-server *:7001 [cluster]
root 5773 1 0 03:46 ? 00:00:00 redis-server *:7002 [cluster]
root 5779 1 0 03:46 ? 00:00:00 redis-server *:7003 [cluster]
root 5785 1 0 03:46 ? 00:00:00 redis-server *:7004 [cluster]
root 5791 1 0 03:46 ? 00:00:00 redis-server *:7005 [cluster]
[root@node2 local]# redis-cli --cluster create 127.0.0.1:7000 127.0.0.1:7001
\
> 127.0.0.1:7002 127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005 \
> --cluster-replicas 1
#输入yes，即按照此方式分配master和slave
M: 511ba9acbff21c59de7654342dc3847a9c9309d7 127.0.0.1:7000
slots:[0-5460] (5461 slots) master
M: fb3ee7237c0a1e164469f312b8fd65379139e6f0 127.0.0.1:7001
slots:[5461-10922] (5462 slots) master
M: 970f5bbc15256edbdd4587dda6dd4050dc6c651a 127.0.0.1:7002
slots:[10923-16383] (5461 slots) master
S: 37bef4ed48428e9c530b5c963c3afc3975a7049b 127.0.0.1:7003
replicates fb3ee7237c0a1e164469f312b8fd65379139e6f0
S: fd4c06655852c01b5c850d438cf4eca71a101a70 127.0.0.1:7004
replicates 970f5bbc15256edbdd4587dda6dd4050dc6c651a
S: 86ef91e58e5736bcda38582d824242bbf74d2d25 127.0.0.1:7005
replicates 511ba9acbff21c59de7654342dc3847a9c9309d7
```



- 验证测试

```bash
[root@node2 local]# redis-cli -c -p 7000
#查询集群信息
127.0.0.1:7000> cluster info
cluster_state:ok
cluster_slots_assigned:16384
cluster_slots_ok:16384
cluster_slots_pfail:0
cluster_slots_fail:0
cluster_known_nodes:6
cluster_size:3
cluster_current_epoch:6
cluster_my_epoch:1
cluster_stats_messages_ping_sent:353
cluster_stats_messages_pong_sent:357
cluster_stats_messages_sent:710
cluster_stats_messages_ping_received:352
cluster_stats_messages_pong_received:353
cluster_stats_messages_meet_received:5
cluster_stats_messages_received:710
#查询集群各节点
127.0.0.1:7000> cluster nodes
86ef91e58e5736bcda38582d824242bbf74d2d25 127.0.0.1:7005@17005 slave
511ba9acbff21c59de7654342dc3847a9c9309d7 0 1554278064038 6 connected
fd4c06655852c01b5c850d438cf4eca71a101a70 127.0.0.1:7004@17004 slave
970f5bbc15256edbdd4587dda6dd4050dc6c651a 0 1554278062005 5 connected
970f5bbc15256edbdd4587dda6dd4050dc6c651a 127.0.0.1:7002@17002 master - 0
1554278063031 3
connected 10923-16383
37bef4ed48428e9c530b5c963c3afc3975a7049b 127.0.0.1:7003@17003 slave
fb3ee7237c0a1e164469f312b8fd65379139e6f0 0 1554278062000 4 connected

fb3ee7237c0a1e164469f312b8fd65379139e6f0 127.0.0.1:7001@17001 master - 0
1554278062529 2
connected 5461-10922
511ba9acbff21c59de7654342dc3847a9c9309d7 127.0.0.1:7000@17000 myself,master
- 0
1554278063000 1 connected 0-5460
[root@node2 local]# redis-cli -c -p 7000
127.0.0.1:7000> set name eagles
-> Redirected to slot [5798] located at 127.0.0.1:7001
OK # 数据分配特性
```





# [redis](https://www.nowcoder.com/jump/super-jump/word?word=redis)缓存穿透、雪崩、击穿

当查**询Redis中没有的数据时，该查询会下沉到数据库层**，同时数据库层也没有该数据，当这种情况大量出现或被恶意攻击时，**接口的访问全部透过Redis访问数据库，而数据库中也没有这些数据，我们称这种现象为"缓存穿透**"。缓存穿透会穿透Redis的保护，提升底层数据库的负载压力，同时这类穿透查询没有数据返回也造成了网络和计算资源的浪费。

![img](https://ask.qcloudimg.com/http-save/yehe-4752702/536kcr8ns8.png?imageView2/2/w/1620)

解决方案：

- **在接口访问层对用户做校验，如接口传参、登陆状态、n秒内访问接口的次数；**
- **利用布隆过滤器，将数据库层有的数据key存储在位数组中，以判断访问的key在底层数据库中是否存在；**

第一种解决方案很好理解，这里介绍一下第二种方案，在前一篇文章中我们介绍了Redis的布隆过滤器，我们知道布隆过滤器可以判断key一定不在集合内以及key极有可能在集合内。

基于布隆过滤器，我们可以先将**数据库中数据的key存储**在布隆过滤器的位数组中，每次客户端查询数据时先访问Redis：

- 如果Redis内不存在该数据，则通过布隆过滤器判断数据是否在底层数据库内；
- 如果布隆过滤器告诉我们该key在底层库内不存在，则 直接返回null给客户端即可，避免了查询底层数据库的动作；
- 如果布隆过滤器告诉我们该key极有可能在底层数据库内存在，那么将查询下推到底层数据库即可；

![img](https://ask.qcloudimg.com/http-save/yehe-4752702/n41yh8r1hu.png?imageView2/2/w/1620)

布隆过滤器有误判率，虽然不能完全避免数据穿透的现象，但已经可以将99.99%的穿透查询给屏蔽在Redis层了，极大的降低了底层数据库的压力，减少了资源浪费。



**缓存击穿**

缓存击穿和缓存穿透从名词上可能很难区分开来，它们的区别是：**穿透表示底层数据库没有数据且缓存内也没有数据，击穿表示底层数据库有数据而缓存内没有数据。**当热点数据key从缓存内失效时，**大量访问同时请求这个数据，就会将查询下沉到数据库层，此时数据库层的负载压力会骤增，我们称这种现象为"缓存击穿"。**

![img](https://ask.qcloudimg.com/http-save/yehe-4752702/97521eq6uv.png?imageView2/2/w/1620)

解决方案：

- **延长热点key的过期时间或者设置永不过期，如排行榜，首页等一定会有高并发的接口；**
- 利用互斥锁保证同一时刻只有一个客户端可以查询底层数据库的这个数据，一旦查到数据就缓存至Redis内，避免其他大量请求同时穿过Redis访问底层数据库；

![img](https://ask.qcloudimg.com/http-save/yehe-4752702/m9q3i5vz8a.png?imageView2/2/w/1620)

在使用互斥锁的时候需要避免出现死锁或者锁过期的情况：

- 使用前面文章介绍过的lua脚本或事务将获取锁和设置过期时间作为一个原子性操作(如：set kk vv nx px 30000)，以避免出现某个客户端获取锁之后宕机导致的锁不被释放造成死锁现象；
- 另起一个线程监控获取锁的线程的查询状态，快到锁过期时间时还没查询结束则延长锁的过期时间，避免多次查询多次锁过期造成计算资源的浪费；



**缓存雪崩**

**缓存雪崩是缓存击穿的"大面积"版**，缓存击穿是**数据库缓存到Redis内的热点数据失效导致大量并发查询穿过redis直接击打到底层数据库，而缓存雪崩是指Redis中大量的key几乎同时过期**，然后大量并发查询穿过redis击打到底层数据库上，此时数据库层的负载压力会骤增，我们称这种现象为"缓存雪崩"。事实上缓存雪崩相比于缓存击穿更容易发生，对于大多数公司来讲，同时超大并发量访问同一个过时key的场景的确太少见了，而大量key同时过期，大量用户访问这些key的几率相比缓存击穿来说明显更大。

![img](https://ask.qcloudimg.com/http-save/yehe-4752702/gcy1ji8j6p.png?imageView2/2/w/1620)

解决方案：

- 在可接受的时间范围内随机设置key的过期时间，分散key的过期时间，以防止大量的key在同一时刻过期；
- 对于一定要在固定时间让key失效的场景(例如每日12点准时更新所有最新排名)，可以在固定的失效时间时在接口服务端设置随机延时，将请求的时间打散，让一部分查询先将数据缓存起来；
- 延长热点key的过期时间或者设置永不过期，这一点和缓存击穿中的方案一样；

![img](https://ask.qcloudimg.com/http-save/yehe-4752702/02slxxzmy5.png?imageView2/2/w/1620)

![img](https://ask.qcloudimg.com/http-save/yehe-4752702/1o9mle4fz4.png?imageView2/2/w/1620)







