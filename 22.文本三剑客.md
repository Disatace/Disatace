# 文本三剑客

## 通配符

```bash
*：匹配0或多个字符
?：匹配任意一个字符
[list]：匹配list中任意单个字符
[c1-c2]：匹配c1-c2中任意单个字符
[^c1-c2]/[!c1-c2]：不匹配c1-c2中任意字符
{string1,string2,...}：匹配{}中任意单个字符串
```

- shell 元字符

```bash
IFS：<tab>/<space>/<enter>
CR：<enter>
=：设定变量
$：取变量值
>/< ：重定向
|：管道
&：后台执行命令
()：在子shell中执行命令/运算或命令替换
{}：函数中执行/变量替换的界定范围
;：命令结束后，忽略其返回值，继续执行下一个命令
&&：命令结束后，若为true，继续执行下一个命令
||：命令结束后，若为false，继续执行下一个命令
！：非
#：注释
\：转义符

''：硬转义，内部所有shell元字符，通配符都会被关掉
""：软转义，引号内部只允许出现特定的shell元字符,$用于参与代换 用于代替命令。
```



# find文件查找

特点

- 查找速度慢
- 精确查找
- 实时查找

## 查找条件

```bash
根据文件名查找：
-name "filename" 支持global
#  find /etc -name "ens33"
-iname "filename" 忽略大小写
-regex "PATTERN" 以Pattern匹配整个文件路径字符串，而不仅仅是文件名称
根据属主和属组查找：
-user USERNAME：查找属主为指定用户的文件
-group GROUPNAME：查找属组为指定属组的文件
-uid UserID：查找属主为指定的ID号的文件
-gid GroupID：查找属组为指定的GID号的文件
-nouser：查找没有属主的文件
-nogroup：查找没有属组的文件
根据文件类型查找：
-type Type：
f/d/l/s/b/c/p
根据文件大小来查找：
-size [+|-]N[bcwkMG]
#find /etc -size +5M 大于5M
根据时间戳:
天：
-atime [+|-]N
-mtime
-ctime
分钟：
-amin N
-cmin N
-mmin N
-amin n : 在过去 n 分钟内被读取过

-anewer file : 比文件 file 更晚被读取过的文件

-atime n : 在过去 n 天内被读取过的文件

-cmin n : 在过去 n 分钟内被修改过

-cnewer file :比文件 file 更新的文件

-ctime n : 在过去 n 天内创建的文件

-mtime n : 在过去 n 天内修改过的文件

根据权限查找：
-perm [+|-]MODE
MODE：精确权限匹配
/MODE：任何一类(u，g，o)对象的权限中只要能一位匹配即可
-MODE：每一类对象都必须同时拥有为其指定的权限标准
组合条件：
与：-a
或：-o
非：-not
相关案例：找出/tmp目录下，属主不是root，且文件名不是fstab的文件：
find /tmp \( -not -user root -a -not -name 'fstab'\) -ls

按照正则表达式
[root@localhost ~]# find /etc -regex '.*ifcfg-ens[0-9][0-9]'
# .* 任意多个字符
# [0-9] 任意一个数字


#find仅列某一级目录的内容
test@fileserver2:/opt$ find /opt/ -maxdepth 1
```

## 处理动作

```bash
-print：默认的处理动作，显示至屏幕
-ls：类型于对查找到的文件执行“ls -l”命令
-delete：删除查找到的文件
-fls /path/to/somefile：查找到的所有文件的长格式信息保存至指定文件中
-ok COMMAND {}\：对查找到的每个文件执行由COMMAND指定的命令
对于每个文件执行命令之前，都会交换式要求用户确认
-exec COMMAND {} \：对查找到的每个文件执行由COMMAND指定的命令
[root@server1 ~]# find /etc/init.d/ -perm -111 -exec cp -r {} dir1/ \;
{}：用于引用查找到的文件名称自身
注意：find传递查找到的文件至后面指定的命令时，查找到所有符合条件的文件一次性传递给后面的命
令；另一种方式可规避此问题
find | xargs COMMAND
```

# 正则表达式

```bash
#字符匹配
.：匹配任意单个字符
[]：匹配指定范围内任意单个字符
[^]：匹配指定范围外任意单个字符
[:alnum:]：字母与数字字符
[:alpha:]：字母
[:ascii:]：ASCII字符
[:blank:]：空格或制表符
[:cntrl:]：ASCII控制字符
[:digit:]：数字
[:graph:]：非控制、非空格字符
[:lower:]：小写字母
[:print:]：可打印字符
[:punct:]：标点符号字符
[:space:]：空白字符，包括垂直制表符
[:upper:]：大写字母
[:xdigit:]：十六进制数字
##匹配次数
*：匹配前面的字符任意次数
.*：匹配任意长度的字符
\?：匹配其前面字符0或1次，即前面的可有可无
\+：匹配其前面的字符至少1次
\{m\}：匹配前面的字符m次
\{m,n\}：匹配前面的字符至少m次，至多n次
\{0,n\}：匹配前面的字符至多n次
\{m,\}：匹配前面的字符至少m次
##位置锚定
^：行首锚定，用于模式的最左侧
$：行末锚定，用于模式的最右侧
^PATTERN$：用于模式匹配整行；
^$：空行
\< 或 \b：词首锚定，用于单词模式的左侧
\> 或 \b：词尾锚定，用于单词模式的右侧
\<PATTERN\>：匹配整个单词
##分组
\(\):将一个或多个字符捆绑在一起；当作一个字符
\(xy\)*ab
Note：分组括号中的模式匹配到的内容会被正则表达式引擎记录于内部的变量中，这些变量的命令
方式为：
\1，\2，\3……
\1：从左侧起，第一个左括号以及与之匹配右括号之间的模式所匹配到的字符；
\(ab\+\(xy\)*\):
\1：ab\+\(xy\)*
\2：xy
```



# grep

作用：过滤文本内容

- -E ：扩展正则表达式
- -i:忽略大小写
- -n：打印行号
- -o：只打印匹配的内容
- -c:打印匹配字符串多少行
- -v：取反
- **-a 或 --text** : 不要忽略二进制的数据。
- **-A<显示行数> 或 --after-context=<显示行数>** : 除了显示符合范本样式的那一列之外，并显示该行之后的内容。
- **-b 或 --byte-offset** : 在显示符合样式的那一行之前，标示出该行第一个字符的编号。
- **-B<显示行数> 或 --before-context=<显示行数>** : 除了显示符合样式的那一行之外，并显示该行之前的内容。
- **-c 或 --count** : 计算符合样式的列数。
- **-C<显示行数> 或 --context=<显示行数>或-<显示行数>** : 除了显示符合样式的那一行之外，并显示该行之前后的内容。
- **-d <动作> 或 --directories=<动作>** : 当指定要查找的是目录而非文件时，必须使用这项参数，否则grep指令将回报信息并停止动作。
- **-e<范本样式> 或 --regexp=<范本样式>** : 指定字符串做为查找文件内容的样式。
- **-E 或 --extended-regexp** : 将样式为延伸的正则表达式来使用。
- **-f<规则文件> 或 --file=<规则文件>** : 指定规则文件，其内容含有一个或多个规则样式，让grep查找符合规则条件的文件内容，格式为每行一个规则样式。
- **-F 或 --fixed-regexp** : 将样式视为固定字符串的列表。
- **-G 或 --basic-regexp** : 将样式视为普通的表示法来使用。
- **-h 或 --no-filename** : 在显示符合样式的那一行之前，不标示该行所属的文件名称。
- **-H 或 --with-filename** : 在显示符合样式的那一行之前，表示该行所属的文件名称。
- **-i 或 --ignore-case** : 忽略字符大小写的差别。
- **-l 或 --file-with-matches** : 列出文件内容符合指定的样式的文件名称。
- **-L 或 --files-without-match** : 列出文件内容不符合指定的样式的文件名称。
- **-n 或 --line-number** : 在显示符合样式的那一行之前，标示出该行的列数编号。
- **-o 或 --only-matching** : 只显示匹配PATTERN 部分。
- **-q 或 --quiet或--silent** : 不显示任何信息。
- **-r 或 --recursive** : 此参数的效果和指定"-d recurse"参数相同。
- **-s 或 --no-messages** : 不显示错误信息。
- **-v 或 --invert-match** : 显示不包含匹配文本的所有行。
- **-V 或 --version** : 显示版本信息。
- **-w 或 --word-regexp** : 只显示全字符合的列。
- **-x --line-regexp** : 只显示全列符合的列。

## 实例

实例2：打印出所有的a无论大小写，并且显示该字符串所在的行 ： -n选项

```bash
[root@localhost ~]# grep -in "a" test
1:asdkahsduoa
2:aslkdsl
5:A
7:aSDD
8:CASDC
10:asdo
11:ca
#实例3：仅仅打印出所有匹配的字符串： -o选项
[root@localhost ~]# grep -io "a" test
#实例8：打印出不包含大小s的所有行 取反 -v
[root@localhost ~]# grep -iv "S" test
#grep可以从文件当中直接搜索某个关键词,也可以从标准输入里面搜索
[root@localhost ~]# grep root /etc/passwd
root:x:0:0:root:/root:/bin/bash
operator:x:11:0:operator:/root:/sbin/nologin
[root@localhost ~]# cat /etc/passwd | grep "root"
root:x:0:0:root:/root:/bin/bash
operator:x:11:0:operator:/root:/sbin/nologin
```

```bash

```

当我们要找出一个数字或者一个字母连续出现多次时，如果我们重复输入是非常麻烦的，这时我们就可以指定匹配前面的命令的次数来实现多次查找。

**输入：**

```
cat ./passwd |egrep "\<[0-9]{2,3}\>"
```

**egrep**：拓展正则表达式，也可以用grep -E，如果我们不是用拓展的正则表达式那么grep后面的命令中的所有符号都要使用\转义才可以使用

**‘string’ 单引号 (single quote)**
被单引号用括住的内容，将被视为单一字串。在引号内的代表变数的$符号，没有作用，也就是说，他被视为一般符号处理，防止任何变量替换。
heyyou=homeecho ‘$heyyou’ # We get $heyyou 

**“string” 双引号 (double quote)**
被双引号用括住的内容，将被视为单一字串。它防止通配符扩展，但允许变量扩展。这点与单引数的处理方式不同。

\<：词首锚定，\>：词尾锚定：如果不用词首词尾锚定，那么我们匹配到的数字将会是所有满足{}里输入的个数，

![image-20220414145515458](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220414145515458.png)

**例如：**

这里我们输入{2,3}，**那么就是匹配前面的命令最少两次最多三次**，而且会在一行连续的数字一直匹配下去。

f1文件里本来话有个1，因为不满足最少匹配次数而没有显示。



当我们输入词首和词尾锚定时，我们只匹配到了12和123。

知道了这些，我们就可以匹配/etc/passwd里的两位数字，三位数字的内容了

**输入：**`cat /etc/passwd | egrep "\<[0-9]{2,3}\>"`

**或者：** `cat /etc/passwd | grep -E "\<[0-9]{2,3}\>"`

**再或者：** `cat /etc/passwd | grep "\<[0-9]{2,3}>"`

![image-20220414145525624](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220414145525624.png)

## 基于grep的正则表达式

![image-20220222122157834](http://cdn.gtrinee.top/image-20220222122157834.png)



![image-20220222122217228](http://cdn.gtrinee.top/image-20220222122217228.png)

## 最常用

```bash
#grep -EV "^#|^$" /etc/ssh/ssd_config 查看配置文件并且去掉所有注释和空行
```

# sed

sed可依照script的指令，来处理、编辑文本文件。 Sed主要用来自动编辑一个或多个文件；简化对文件的反复操作；编写转换程序等。

## 语法

`sed的命令格式： sed [option] 'sed command' filename**`

 `**sed的脚本格式：sed [option] -f 'sed script' filename`**

- -n:直打印模式匹配的行
- -e：默认选项
- -f：将sed的动作卸载一个文件内 -f filename  执行file那么内的sed动作
- -r：支持扩展表达式
- -i：直接修改文件内容

为什么要使用sed高级命令（G、H、g、h、n、N、x）？

由于各种各样的原因，比如用户希望在某个条件下脚本中的某个命令被执行，或者希望模式空间得到保留以便下一次的处理，都有可能使得**sed**在处理文件的时候不按照正常的流程来进行。这个时候，**sed**设置了一些高级命令来满足用户的要求。sed命令：

```bash
+ g：[address[,address]]g 将hold space中的内容拷贝到pattern space中，原来pattern space里的内容清除

+ G：[address[,address]]G 将hold space中的内容append到pattern space\n后

+ h：[address[,address]]h 将pattern space中的内容拷贝到hold space中，原来的hold space里的内容被清除

+ H：[address[,address]]H 将pattern space中的内容append到hold space\n后

+ d：[address[,address]]d 删除pattern中的所有行，并读入下一新行到pattern中

+ D：[address[,address]]D 删除multiline pattern中的第一行，不读入下一行

PS：不论是使用G、g还是H、h，它们都是将hold space里面的内容“copy”到pattern space中或者将pattern space中的内容“copy”到hold space中。sed命令：

+ g：[address[,address]]g 将hold space中的内容拷贝到pattern space中，原来pattern space里的内容清除

+ G：[address[,address]]G 将hold space中的内容append到pattern space\n后

+ h：[address[,address]]h 将pattern space中的内容拷贝到hold space中，原来的hold space里的内容被清除

+ H：[address[,address]]H 将pattern space中的内容append到hold space\n后

+ d：[address[,address]]d 删除pattern中的所有行，并读入下一新行到pattern中

+ D：[address[,address]]D 删除multiline pattern中的第一行，不读入下一行

PS：不论是使用G、g还是H、h，它们都是将hold space里面的内容“copy”到pattern space中或者将pattern space中的内容“copy”到hold space中。


```



## 动作说明

```bash
常用选项：
p：打印匹配的行(-n)
=：显示文件行号
a\：指定行号后添加新文本  sed '2a hello world'
i\：指定行号前添加新文本 sed '2i hello world'
d：删除定位行
c\：用新文本替换定位文本 sed '2,5c No 2-5 number' 
第2-5行的内容取代成为『No 2-5 number』
w filename：写文本到一个文件
r filename：从另一个文件读文本
s///：替换
替换标记：
g：行内全局替换
p：显示替换成功的行
w：将替换成功的结果保存至指定文件
q：第一个模式匹配后立即退出
{}：在定位行执行的命令组，用逗号分隔
g：将模式2粘贴到/pattern n/

a ：新增， a 的后面可以接字串，而这些字串会在新的一行出现(目前的下一行)～
c ：取代， c 的后面可以接字串，这些字串可以取代 n1,n2 之间的行！
d ：删除，因为是删除啊，所以 d 后面通常不接任何咚咚；
i ：插入， i 的后面可以接字串，而这些字串会在新的一行出现(目前的上一行)；
p ：打印，亦即将某个选择的数据印出。通常 p 会与参数 sed -n 一起运行～
s ：取代，可以直接进行取代的工作哩！通常这个 s 的动作可以搭配正规表示法！例如 1,20s/old/new/g就是啦！
```

## 实例

一、每行前后添加空行

1.每行后面添加一行空行：

 `sed G tmp`

 每行前面添加一行空行：

 sed ‘{x;p;x;}’ tmp

2.每行后面添加两行空行：

 sed ‘G;G’ tmp

 每行前面添加两行空行：

 sed '{x;p;x;x;p;x;}' tmp

3.每行后面添加三行空行：

 sed ‘G;G;G’ tmp

 每行前面添加三行空行：

 sed '{x;p;x;x;p;x;x;p;x}' tmp

依次类推，添加几行空行，就有几个G或者x;p;x

二、如果行后有空行，则删除，然后每行后面添加空行

sed '/^$/d;G' tmp

三、在匹配行前后添加空行

sed '/shui/G' tmp 如果一行里面有shui这个单词，那么在他后面会添加一个空行

sed '/shui/{x;p;x;G}' tmp 如果一行里面有shui这个单词，那么在他前后各添加一个空行

sed '/shui/{x;p;x;}' tmp 如果一行里面有shui这个单词，那么在他前面添加一个空行

sed ‘1{x;p;x;}’ tmp 在第一行前面添加空行，想在第几行，命令中的1就改成几

sed ‘1G’ tmp 在第一行后面添加空行，想在第几行，命令中的1就改成几

四、每几行后面添加一个空行

1.每两行后面增加一个空行

 sed 'N;/^$/d;G' file.txt

 每两行前面添加一个空行

 sed 'N;/^$/d;{x;p;x;}' tmp

2.每三行后面增加一个空行

 sed 'N;N;/^$/d;G' file.txt

 每三行前面增加一个空行

 sed 'N;N;/^$/d;{x;p;x;}' tmp

五、以x为开头或以x为结尾的行前后添加空行

1.以xi为开头的行后面添加空行

 sed '/^xi/G;' tmp

 以xi为结尾的行前面添加空行

 sed '/^xi/{x;p;x;}' tmp

2.以xi为结尾的行后面添加空行

 sed '/xi$/G;' tmp

 以xi为结尾的行后面添加空行

 sed '/xi$/{x;p;x;}' tmp



**用sed又如何实现奇数行和偶数行的输出呢？**
sed通常用-n -p选项结合来输出指定的行，sed有一个步长的设置，例如从第一行开始，每2行输出，则输出奇数行如下：

$ sed -n '1~2p' test1.txt-n
1	Jan
3	Mar
5	May
7	Jul
9	Sep
11	Nov

那么，从第二行开始，每2行输出，就是输出偶数行：
$ sed -n '2~2p' test1.txt
2	Feb
4	Apr
6	Jun
8	Aug
10	Oct
12	Dec

注意中间是个波浪号~

那么隔2行输出该怎么做呢？

$ awk 'NR%3==1' test1.txt
1	Jan
4	Apr
7	Jul
10	Oct

$ awk 'NR%3==2' test1.txt
2	Feb
5	May
8	Aug
11	Nov

$ sed -n '1~3p' test1.txt
1	Jan
4	Apr
7	Jul
10	Oct

```bash
#在testfile文件的第四行后添加一行，并将结果输出到标准输出
sed -e 4a\newline test
line one
line two
line three
line four
newline
line five
#将 /etc/passwd 的内容列出并且列印行号，同时，请将第 2~5 行删除
[root@localhost ~]# nl /etc/passwd | sed '2,5d'

sed 的动作为 '2,5d' ，那个 d 就是删除！因为 2-5 行给他删除了，所以显示的数据就没有 2-5 行罗～ 另
外，注意一下，原本应该是要下达 sed -e 才对，没有 -e 也行啦！同时也要注意的是， sed 后面接的动
作，请务必以 '' 两个单引号括住喔！
#要删除第 3 到最后一行
[root@localhost ~]# nl /etc/passwd | sed '3,$d'
```

### 数据的搜寻并删除 

删除/etc/passwd所有包含root的行，其他行输出

```bash
[root@localhost ~]# nl /etc/passwd | sed '/root/d'
```

搜索/etc/passwd,找到root对应的行，执行后面花括号中的一组命令，每个命令之间用分号分隔，这里 把bash替换为blueshell，再输出这行

```bash
[root@localhost ~]# nl /etc/passwd | sed -n '/root/{s/bash/blueshell/;p;q}'
1 root:x:0:0:root:/root:/bin/blueshell
最后的q是退出，不然会继续找下去
```

### 数据的搜寻并替换 

除了整行的处理模式之外， sed 还可以用行为单位进行部分数据的搜寻并取代

```bash
sed 's/要被取代的字串/新的字串/g' #g是全局替换
```

### 多点编辑

一条sed命令，删除/etc/passwd第三行到末尾的数据，并把bash替换为blueshell

`[root@localhost ~]# nl /etc/passwd | sed -e '3,$d' -e 's/bash/blueshell/'` 

#$是行末锚定#

**-e表示多点编辑**，第一个编辑命令删除/etc/passwd第三行到末尾的数据，第二条命令搜索bash替换为 blueshell。

### 直接修改文件内容(危险动作)

```bash
[root@localhost ~]# sed -i 's/\.$/\!/g' test
#s// 替换  \.加反斜杠防止认成正则. $末行
[root@localhost ~]# cat test
line one!
line two!
line three!
line four!
line five!
```

# sed中的正则匹配

##### 1. 行首/行尾

行首用^表示，行尾用$表示。例如有如下test.txt文件：



![img](https:////upload-images.jianshu.io/upload_images/20297934-2d6f27fbc49eb121.png?imageMogr2/auto-orient/strip|imageView2/2/w/452/format/webp)

如果我们想把其中第一列的Potri.去掉，那么可以：



```rust
sed 's/^Potri.//g' test.txt 
```

假如想在最后数字的后面加一列"yes":



```bash
sed 's/$/\tyes/g' test.txt
```



# awk

### 语法

```
awk [选项参数] 'script' var=value file(s)
或
awk [选项参数] -f scriptfile var=value file(s)
```

**选项参数说明：**

- -F fs or --field-separator fs
  指定输入文件折分隔符，fs是一个字符串或者是一个正则表达式，如-F:。
- -v var=value or --asign var=value
  赋值一个用户定义变量。
- -f scripfile or --file scriptfile
  从脚本文件中读取awk命令。

```bash
[root@localhost ~]# awk -F: '{print $0}' /etc/passwd
```

-F参数：指定分隔符，可指定一个或多个 print 后面做字符串的拼接

```bash
#只查看test.txt文件（100行）内第20到第30行的内容
[root@localhost ~]# seq 100 > test1
[root@localhost ~]# awk '{if(NR>=20 && NR<=30) print $1}' test.txt


[root@localhost ~]# cat test.txt
I am aaron, my qq is 1234567
[root@localhost ~]# awk -F '[ ,]+' '{print $3" "$7}' test.txt
aaron 1234567
```

## 运算符

| 运算符                  | 描述                             |
| :---------------------- | :------------------------------- |
| = += -= *= /= %= ^= **= | 赋值                             |
| ?:                      | C条件表达式                      |
| \|\|                    | 逻辑或                           |
| &&                      | 逻辑与                           |
| ~ 和 !~                 | 匹配正则表达式和不匹配正则表达式 |
| < <= > >= != ==         | 关系运算符                       |
| 空格                    | 连接                             |
| + -                     | 加，减                           |
| * / %                   | 乘，除与求余                     |
| + - !                   | 一元加，减和逻辑非               |
| ^ ***                   | 求幂                             |
| ++ --                   | 增加或减少，作为前缀或后缀       |
| $                       | 字段引用                         |
| in                      | 数组成员                         |

## 基本用法

```bash
输出奇数行：
$ awk 'NR%2' test1.txt
1	Jan
3	Mar
5	May
7	Jul
9	Sep
11	Nov
```



log.txt文本内容如下：

```
2 this is a test
3 Are you like awk
This's a test
10 There are orange,apple,mongo
```

用法一：

```
awk '{[pattern] action}' {filenames}   # 行匹配语句 awk '' 只能用单引号
```

实例：

```
# 每行按空格或TAB分割，输出文本中的1、4项
 $ awk '{print $1,$4}' log.txt
 ---------------------------------------------
 2 a
 3 like
 This's
 10 orange,apple,mongo
 # 格式化输出
 $ awk '{printf "%-8s %-10s\n",$1,$4}' log.txt
 ---------------------------------------------
 2        a
 3        like
 This's
 10       orange,apple,mongo
 
```

用法二：

```
awk -F  #-F相当于内置变量FS, 指定分割字符
```

实例：

```bash
# 使用","分割
 $  awk -F, '{print $1,$2}'   log.txt
 ---------------------------------------------
 2 this is a test
 3 Are you like awk
 This's a test
 10 There are orange apple
 # 或者使用内建变量
 $ awk 'BEGIN{FS=","} {print $1,$2}'     log.txt
 ---------------------------------------------
 2 this is a test
 3 Are you like awk
 This's a test
 10 There are orange apple
 # 使用多个分隔符.先使用空格分割，然后对分割结果再使用","分割
 $ awk -F '[ ,]'  '{print $1,$2,$5}'   log.txt
 ---------------------------------------------
 2 this test
 3 Are awk
 This's a
 10 There apple
```

用法三：

```
awk -v  # 设置变量
```

实例：

```
 $ awk -va=1 '{print $1,$1+a}' log.txt
 ---------------------------------------------
 2 3
 3 4
 This's 1
 10 11
 $ awk -va=1 -vb=s '{print $1,$1+a,$1b}' log.txt
 ---------------------------------------------
 2 3 2s
 3 4 3s
 This's 1 This'ss
 10 11 10s
```

用法四：

```
awk -f {awk脚本} {文件名}
```

实例：

```
 $ awk -f cal.awk log.txt
```

------

### 一、awk简介及常见用法

awk编程语言/数据处理引擎

- 创造者: Aho、Weinberger、Kernighan awk的名称取自三位创造者的名字的首字符
- 基于模式匹配检查输入文本,逐行处理并输出
- 通常用在Shell脚本中,获取指定的数据
- 单独用时,可对文本数据做统计
- awk默认支持扩展正则

**命令格式**

- 格式1:前置命令 | awk [选项] '[条件]{指令}'
- 格式2:前置命令 | awk [选项] '[条件]{指令}' 文件

**常用的选择**

- 选项 -F 可指定分隔符,可省略 (默认awk分隔符为空格和tab键)
- 选项 -v 赋值一个用户定义变量。

**常用的条件 可省略 (默认输入显示全部匹配项)**

- 可使用正则来限定范围, awk默认支持扩展正则

**awk常用内置变量**

- FS 保存或设置字段分隔符,例如FS= ":" 与-F功能一样
- RS：Record Separator，记录分隔符
- ORS：Output Record Separate，输出当前记录分隔符(行分隔符)
- OFS：Out of Field Separator，输出字段分隔符物，其中解释了缩写的含义
- $n 指定分隔的第n个字段,如 $1、$2分别表示文本的第1列、第2列依此类推
- $0 文本当前行的全部内容
- NR 文件当前行的行号
- NF 文件当前行的列数（有几列）

**常用的指令**

- print 是最常用的编辑指令；若有多条编辑指令，可用分号分隔。

**案例 1**
1）awk过滤数据时支持仅打印某一列，如第2列、第5列等。
处理文本时，若未指定分隔符，则默认将空格、制表符等作为分隔符。

```shell
[root@case100 ~]# cat awk.txt
hello the world
welcome to beijing
[root@case100 ~]# awk '{print $1,$3}' awk.txt     //打印文档第1列和第3列
hello world
welcome beijing
```

- 结合管道过滤命令输出：

```shell
[root@case100 ~]# df -h|awk '{print $4}'     //打印磁盘的剩余空间
```

2）选项 -F 可指定分隔符

- 输出passwd文件中以分号分隔的第1、7个字段，显示的不同字段之间以逗号隔开，操作如下：

```shell
[root@bigyong ~]# awk -F: '{print $1","$7 }' /etc/passwd
root,/bin/bash
bin,/sbin/nologin
daemon,/sbin/nologin
adm,/sbin/nologin
lp,/sbin/nologin
sync,/bin/sync
… …
```

3） 利用awk提取本机的网络流量、根分区剩余容量、获取远程失败的IP地址
提取IP地址
分步实现的思路及操作参考如下——
通过ifconfig eth0查看网卡信息，其中包括网卡流量：

```shell
[root@case100 ~]# ifconfig eth0
eth0flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500
        inet 192.168.4.100  netmask 255.255.255.0  broadcast 192.168.4.255
        ether 52:54:00:af:e6:6a  txqueuelen 1000  (Ethernet)
        RX packets 106729  bytes 5769307 (5.5 MiB)
        RX errors 0  dropped 100380  overruns 0  frame 0
        TX packets 4678  bytes 736178 (718.9 KiB)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0
```

RX为接收的数据量，TX为发送的数据量。packets以数据包的数量为单位，bytes以字节为单位：

```shell
[root@case100 ~]# ifconfig eth0 |awk '/RX p/{print $5}'    //过滤接收数据的流量
5797165
[root@case100 ~]# ifconfig eth0 |awk '/TX p/{print $5}'   //过滤发送数据的流量
761006
```

4）提取根分区剩余容量
分步实现的思路及操作参考如下——
通过df命令查看根分区的使用情况，其中包括剩余容量：

```shell
[root@case100 ~]# df -h /
文件系统        容量  已用  可用 已用% 挂载点
/dev/vda1        20G  8.8G   12G   44% /
```

输出上述结果中最后一行的第4列： 直接在awk中使用正则：

```shell
[root@case100 ~]# df -h / | awk '/\/$/{print $3}'
8.8G
```

5）选项 -v 赋值一个用户定义变量

```shell
[root@case100 ~]# echo  '1 2 3 4 5'|awk -v istor=100 '{if(istor=100){print $0}}'
1 2 3 4 5
```

6) 输出前4列

```shell
[root@case100 ~]# awk -F: '{NF=4}1' /etc/passwd
```

\7) 定义输出格式 输出:1和4列 分隔符为= 行分格符为 *(默认为回车)

- ORS：Output Record Separate，输出当前记录分隔符(行分隔符)
- OFS：Out of Field Separator，输出字段分隔符物，其中解释了缩写的含义

```shell
[root@k8s-node2 ~]# awk  -F: 'BEGIN{OFS="=";ORS="*"} {print $1,$4;}' /etc/passwd
root=0*bin=1*daemon=2*adm=4*lp=7*sync=0*shutdown=0*halt=0*mail=12*operator=0*games=100*ftp=50*nobody=99*systemd-bus-proxy=998*systemd-network=192*dbus=81*polkitd=997*tss=59*sshd=74*postfix=89*chrony=995*guanzj=0*zabbix=994*ng

#输出分隔符为*号
[root@k8s-node2 ~]# awk  -F: 'BEGIN{OFS="*"} {print $1,$4;}' /etc/passwd
root*0
bin*1
daemon*2
adm*4
lp*7
sync*0
shutdown*0
```

### 二、awk的过滤的时机BEGIN{ }END{ }指令

**awk的过滤的时机**
awk会逐行处理文本，支持在处理第一行之前做一些准备工作，以及在处理完最后一行之后做一些总结性质的工作。在命令格式上分别体现如下：

- awk [选项]'[条件]{指令}' 文件
- awk [选项]' BEGIN{指令} {指令} END{指令}' 文件
- BEGIN{ } 行前处理，读取文件内容前执行，指令执行1次
- { } 逐行处理，读取文件过程中执行，指令执行n次
- END{ } 行后处理，读取文件结束后执行，指令执行1次

```shell
[root@case100 ~]# awk 'BEGIN{A=22;print A}'
22
[root@case100 ~]# awk 'BEGIN{print x+1}'    #x可以不定义，直接用，默认值位0
1
[root@case100 ~]# awk 'BEGIN{print 3.2+3.5}'
6.7
```

**案例2**
1）统计系统中使用bash作为登录Shell的用户总个数：
a.预处理时赋值变量x=0
b.然后逐行读入/etc/passwd文件，如果发现登录Shell是/bin/bash则x加1
c.全部处理完毕后，输出x的值即可。相关操作及结果如下：

```shell
[root@case100 ~]# awk 'BEGIN{x=0}/bash$/{x++} END{print x}' /etc/passwd
5
```

2）格式化输出/etc/passwd文件
要求: 格式化输出passwd文件内容时，要求第一行为列表标题，中间打印用户的名称、UID、家目录信息，最后一行提示一共已处理文本的总行数，如图-1所示
![img](https://segmentfault.com/img/remote/1460000040650756)

3）根据实现思路编写、验证awk过滤语句
输出信息时，可以使用“\t”显示Tab制表位：

```shell
[root@case100 ~]# awk -F: 'BEGIN{print "USER\tUID\tHome"}    \
> {print $1 "\t" $3 "\t" $6}   \
> END{print "Total",NR,"lines."}' /etc/passwd

USER    UID    Home
root    0    /root
bin    1    /bin
daemon    2    /sbin
adm    3    /var/adm
lp    4    /var/spool/lpd
sync    5    /sbin
shutdown    6    /sbin
halt    7    /sbin
mail    8    /var/spool/mail
operator    11    /root
games    12    /usr/games
ftp    14    /var/ftp
nobody    99    /
systemd-network    192    /
```

**案例3**
1）使用正则设置条件
输出其中以bash结尾的完整记录：

```shell
[root@case100 ~]# awk -F: '/bash$/{print}' /etc/passwd
root:x:0:0:root:/root:/bin/bash
nginx:x:1000:1000::/home/nginx:/bin/bash
```

2）输出包含root的行数据：

```shell
[root@case100 ~]# awk -F: '/root/' /etc/passwd
root:x:0:0:root:/root:/bin/bash
operator:x:11:0:operator:/root:/sbin/nologin
```

3）输出root或adm账户的用户名和UID信息：

```shell
[root@case100 ~]# awk -F: '/^(root|adm)/{print $1,$3}' /etc/passwd
root 0
adm 3
```

4）输出账户名称包含root的基本信息（第1列包含root）：

```shell
[root@case100 ~]# awk -F: '$1~/root/' /etc/passwd
root:x:0:0:root:/root:/bin/bash
```

5）输出其中登录Shell不以nologin结尾（对第7个字段做!~反向匹配）的用户名、登录Shell信息：

```shell
[root@case100 ~]# awk -F: '$7!~/nologin$/{print $1,$3}' /etc/passwd
root 0
sync 5
shutdown 6
halt 7
nginx 1000
... ...
```

### 三、awk数值/字符串比较/逻辑比较设置条件

使用数值/字符串比较设置条件

- 比较符号：==(等于) !=（不等于） >（大于）
- \>=（大于等于） <（小于） <=（小于等于)

使用逻辑比较设置条件

- && 逻辑与:期望多个条件都成立
- || 逻辑或:只要有一个条件成立即满足要求

1）输出第3行（行号NR等于3）的用户记录：

```shell
[root@case100 ~]# awk -F:  'NR==3{print}'  /etc/passwd
daemon:x:2:2:daemon:/sbin:/sbin/nologin
```

2）输出账户UID小于10的账户名称和UID信息：

```shell
[root@case100 ~]# awk -F:  '$3<10{print $1,$3}'  /etc/passwd
root 0
bin 1
daemon 2
adm 3
lp 4
... ...
```

3）输出账户UID大于等于1000的账户名称和UID信息：

```shell
[root@case100 ~]# awk -F: '$3>=1000{print $1,$3}' /etc/passwd
nginx 1000
bigyong 1001
kaka5 1002
harry 1003
```

4）输出用户名为“root”的行：

```shell
[root@case100 ~]# awk -F: '$1=="root"' /etc/passwd
root:x:0:0:root:/root:/bin/bash
```

5）逻辑测试条件
输出账户UID大于10并且小于20的账户信息：

```shell
[root@case100 ~]# awk -F: '$3>10 && $3<20 {print $1,$3}' /etc/passwd
operator 11
games 12
ftp 14
```

6）输出账户UID大于1000或者账户UID小于10的账户信息：

```shell
[root@case100 ~]# awk -F: '$3>100 || $3<1000{print $1,$3}' /etc/passwd
root 0
bin 1
daemon 2
... ...
```

7）数学运算

```shell
[root@case100 ~]# awk 'BEGIN{x++;print x}'
1
[root@case100 ~]# awk 'BEGIN{x=10;print x+=20}'
30
[root@case100 ~]# awk 'BEGIN{print 7+3}'
10
[root@case100 ~]# awk 'BEGIN{print 3+4}'
7
[root@case100 ~]# awk 'BEGIN{print 3*4}'
12
[root@case100 ~]# awk 'BEGIN{print 50%3}'
2
[root@case100 ~]# awk 'BEGIN{print 20/3}'
6.66667
[root@case100 ~]# seq 200|awk '\$1%3==0'   //找200以内3的倍数
3
6
9
12
15
... ...
```

8）列出UID间于1~1000的用户详细信息：

```shell
[root@case100 ~]# awk -F: '\$3>=1 && $3<=1000' /etc/passwd
bin:x:1:1:bin:/bin:/sbin/nologin
daemon:x:2:2:daemon:/sbin:/sbin/nologin
adm:x:3:4:adm:/var/adm:/sbin/nologin
lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin
sync:x:5:0:sync:/sbin:/bin/sync
... ...
```

9）输出/etc/hosts映射文件内以127或者192开头的记录：

```shell
[root@case100 ~]# awk '/^(127|192)/' /etc/hosts
127.0.0.1    localhost localhost.localdomain localhost4 localhost4.localdomain4
192.168.4.200  nginx01.test.com
```

10）列出100以内整数中7的倍数或是含7的数：

```shell
[root@case100 ~]# seq 100|awk '$1%7==0||$1~/7/'

7
14
17
21
27
28
... ...
```

**4 案例4：awk综合脚本应用**
编写脚本的任务要求如下：
分析出使用bash作登录Shell的本地用户
列出这些用户的shadow密码记录
按每行“用户名 -- 密码记录”保存结果
步骤一：根据实现思路编写脚本

```shell
[root@case100 ~]# cat awk-user.sh 
#!/bin/bash
A=$(awk -F: '/bash$/{print $1}' /etc/passwd)
for i in $A
do
    grep $i /etc/shadow | awk -F: '{print $1,"-->",$2}'
done
```

步骤二：验证、测试脚本

```shell
[root@case100 ~]# ./getuser-awk.sh 
root --> $6$SAyc777Q$DgGi7Pnln0or.Ds04oyL6Y.QnVlMgZDRHMKKICJhiUAHBy4lvziPAZoW0MJz81xYonskLozvzhvNa4H59ngSl1
nginx --> !!
bigyong --> !!
kaka5 --> $6$uyZDpbUl$.CjkBefPZHXrRTcKc1csv7ZbbhHMMD4oQmum9lajJ1ot9at6fmIey5AE4kmUSoaWE/ofmFxyP2Dc6PAcczXdw0
harry --> !!
```

## 运算符

| 运算符                  | 描述                             |
| :---------------------- | :------------------------------- |
| = += -= *= /= %= ^= **= | 赋值                             |
| ?:                      | C条件表达式                      |
| \|\|                    | 逻辑或                           |
| &&                      | 逻辑与                           |
| ~ 和 !~                 | 匹配正则表达式和不匹配正则表达式 |
| < <= > >= != ==         | 关系运算符                       |
| 空格                    | 连接                             |
| + -                     | 加，减                           |
| * / %                   | 乘，除与求余                     |
| + - !                   | 一元加，减和逻辑非               |
| ^ ***                   | 求幂                             |
| ++ --                   | 增加或减少，作为前缀或后缀       |
| $                       | 字段引用                         |
| in                      | 数组成员                         |

过滤第一列大于2的行

```
$ awk '$1>2' log.txt    #命令
#输出
3 Are you like awk
This's a test
10 There are orange,apple,mongo
```

过滤第一列等于2的行

```
$ awk '$1==2 {print $1,$3}' log.txt    #命令
#输出
2 is
```

过滤第一列大于2并且第二列等于'Are'的行

```
$ awk '$1>2 && $2=="Are" {print $1,$2,$3}' log.txt    #命令
#输出
3 Are you
```

------

## 内建变量

| 变量        | 描述                                              |
| :---------- | :------------------------------------------------ |
| $n          | 当前记录的第n个字段，字段间由FS分隔               |
| $0          | 完整的输入记录                                    |
| ARGC        | 命令行参数的数目                                  |
| ARGIND      | 命令行中当前文件的位置(从0开始算)                 |
| ARGV        | 包含命令行参数的数组                              |
| CONVFMT     | 数字转换格式(默认值为%.6g)ENVIRON环境变量关联数组 |
| ERRNO       | 最后一个系统错误的描述                            |
| FIELDWIDTHS | 字段宽度列表(用空格键分隔)                        |
| FILENAME    | 当前文件名                                        |
| FNR         | 各文件分别计数的行号                              |
| FS          | 字段分隔符(默认是任何空格)                        |
| IGNORECASE  | 如果为真，则进行忽略大小写的匹配                  |
| NF          | 一条记录的字段的数目                              |
| NR          | 已经读出的记录数，就是行号，从1开始               |
| OFMT        | 数字的输出格式(默认值是%.6g)                      |
| OFS         | 输出字段分隔符，默认值与输入字段分隔符一致。      |
| ORS         | 输出记录分隔符(默认值是一个换行符)                |
| RLENGTH     | 由match函数所匹配的字符串的长度                   |
| RS          | 记录分隔符(默认是一个换行符)                      |
| RSTART      | 由match函数所匹配的字符串的第一个位置             |
| SUBSEP      | 数组下标分隔符(默认值是/034)                      |

```
$ awk 'BEGIN{printf "%4s %4s %4s %4s %4s %4s %4s %4s %4s\n","FILENAME","ARGC","FNR","FS","NF","NR","OFS","ORS","RS";printf "---------------------------------------------\n"} {printf "%4s %4s %4s %4s %4s %4s %4s %4s %4s\n",FILENAME,ARGC,FNR,FS,NF,NR,OFS,ORS,RS}'  log.txt
FILENAME ARGC  FNR   FS   NF   NR  OFS  ORS   RS
---------------------------------------------
log.txt    2    1         5    1
log.txt    2    2         5    2
log.txt    2    3         3    3
log.txt    2    4         4    4
$ awk -F\' 'BEGIN{printf "%4s %4s %4s %4s %4s %4s %4s %4s %4s\n","FILENAME","ARGC","FNR","FS","NF","NR","OFS","ORS","RS";printf "---------------------------------------------\n"} {printf "%4s %4s %4s %4s %4s %4s %4s %4s %4s\n",FILENAME,ARGC,FNR,FS,NF,NR,OFS,ORS,RS}'  log.txt
FILENAME ARGC  FNR   FS   NF   NR  OFS  ORS   RS
---------------------------------------------
log.txt    2    1    '    1    1
log.txt    2    2    '    1    2
log.txt    2    3    '    2    3
log.txt    2    4    '    1    4
# 输出顺序号 NR, 匹配文本行号
$ awk '{print NR,FNR,$1,$2,$3}' log.txt
---------------------------------------------
1 1 2 this is
2 2 3 Are you
3 3 This's a test
4 4 10 There are
# 指定输出分割符
$  awk '{print $1,$2,$5}' OFS=" $ "  log.txt
---------------------------------------------
2 $ this $ test
3 $ Are $ awk
This's $ a $
10 $ There $
```

------

## 使用正则，字符串匹配

```
# 输出第二列包含 "th"，并打印第二列与第四列
$ awk '$2 ~ /th/ {print $2,$4}' log.txt
---------------------------------------------
this a
```

**~ 表示模式开始。// 中是模式。**

```
# 输出包含 "re" 的行
$ awk '/re/ ' log.txt
---------------------------------------------
3 Are you like awk
10 There are orange,apple,mongo
```

------

## 忽略大小写

```
$ awk 'BEGIN{IGNORECASE=1} /this/' log.txt
---------------------------------------------
2 this is a test
This's a test
```

------

## 模式取反

```
$ awk '$2 !~ /th/ {print $2,$4}' log.txt
---------------------------------------------
Are like
a
There orange,apple,mongo
$ awk '!/th/ {print $2,$4}' log.txt
---------------------------------------------
Are like
a
There orange,apple,mongo
```

------

## awk脚本

关于 awk 脚本，我们需要注意两个关键词 BEGIN 和 END。

- BEGIN{ 这里面放的是执行前的语句 }
- END {这里面放的是处理完所有的行后要执行的语句 }
- {这里面放的是处理每一行时要执行的语句}

假设有这么一个文件（学生成绩表）：

```
$ cat score.txt
Marry   2143 78 84 77
Jack    2321 66 78 45
Tom     2122 48 77 71
Mike    2537 87 97 95
Bob     2415 40 57 62
```

我们的 awk 脚本如下：

```
$ cat cal.awk
#!/bin/awk -f
#运行前
BEGIN {
    math = 0
    english = 0
    computer = 0
 
    printf "NAME    NO.   MATH  ENGLISH  COMPUTER   TOTAL\n"
    printf "---------------------------------------------\n"
}
#运行中
{
    math+=$3
    english+=$4
    computer+=$5
    printf "%-6s %-6s %4d %8d %8d %8d\n", $1, $2, $3,$4,$5, $3+$4+$5
}
#运行后
END {
    printf "---------------------------------------------\n"
    printf "  TOTAL:%10d %8d %8d \n", math, english, computer
    printf "AVERAGE:%10.2f %8.2f %8.2f\n", math/NR, english/NR, computer/NR
}
```

我们来看一下执行结果：

```
$ awk -f cal.awk score.txt
NAME    NO.   MATH  ENGLISH  COMPUTER   TOTAL
---------------------------------------------
Marry  2143     78       84       77      239
Jack   2321     66       78       45      189
Tom    2122     48       77       71      196
Mike   2537     87       97       95      279
Bob    2415     40       57       62      159
---------------------------------------------
  TOTAL:       319      393      350
AVERAGE:     63.80    78.60    70.00
```

## BEGIN和END模块

实例一：统计/etc/passwd的账户人数

```bash
[root@localhost ~]# awk 'BEGIN{count=0}{count++}END{print count}' /etc/passwd
19
```

实例二：统计某个文件夹下的文件占用的字节数

```bash
[root@localhost ~]# ll | awk 'BEGIN{size=0}{size+=$5} END{print size}'
5694
[root@localhost ~]# ll
总用量 28
-rw-------. 1 root root 1241 10月 30 11:57 anaconda-ks.cfg
-rwxr-xr-x. 1 root root   76 2月  19 23:22 myecho.sh
-rw-r--r--. 1 root root   64 2月  18 19:38 test
-rw-r--r--. 1 root root  292 2月  19 22:00 test1
-rw-r--r--. 1 root root 2011 2月  18 20:29 test2
-rw-r--r--. 1 root root 1986 2月  18 21:23 test3
-rw-r--r--. 1 root root   24 2月  19 22:10 test.txt
#$5是字节
```

## awk运算符

![image-20220222152252846](http://cdn.gtrinee.top/image-20220222152252846.png)

三目运算符 ?:

```bash
[root@node-1 ~]# awk 'BEGIN{a="b";print a=="b"?"ok":"err"}'
ok
[root@node-1 ~]# awk 'BEGIN{a="b";print a=="c"?"ok":"err"}'
err
```

## awk内置变量

![image-20220222152544354](http://cdn.gtrinee.top/image-20220222152544354.png)

```bash
[root@node-1 ~]# ifconfig | grep br0 | awk -F [" ":]+ 'NR==2{print $3}'
192.168.0.241

```

## if控制语句

```bash
[root@localhost ~]# awk 'BEGIN {num = 10; if (num % 2 == 0) printf "%d is even number.\n", num }'
10 is even number.

```

范例

`$ awk  '{if($6 > 20 && $6 <=50) {safe++;print "OK"}}' filename`
说明：在if操作块中测试表达式。如果第6个字段的值大于20并且小于50，就要将表达式后面的那些语句作为一个块来执行，因此，必须用花括号把它们括起来。

if/else 语句
if/else语句实现双路判断。如果关键字if后面的表达式为真，就执行与该表达式关联的语句块。如果这个表达式的运算结果为假或0，则执行关键字else后面的语句块。如果if或else包含多条语旬，就必须用花括号把它们合成一个语句块。

格式

```bash
if (表达式 )  {
  语句;语句;...
}  else  {
  语句;语句;...
}
```


范例

```bash
$ awk  '{if($6 > 50) {print $1 " Too high";} else {print "Range is OK";}}' filename
说明：如果第一个表达式为真，即第6个字段($6)的值大于50 ，则print函数打印第1个字段和字符串"Too high"。否则就执行else后的语句，打印字符串"Range is OK"。

```

## for循环

```bash
awk 'BEGIN { for (i = 1; i <= 5; ++i) print i }'

#do while
awk 'BEGIN {i = 1; do { print i; ++i } while (i < 6) }'
```















[AWK 关于_w3cschool](https://www.w3cschool.cn/awk/c2li1k8d.html)