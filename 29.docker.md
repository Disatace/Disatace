# 29.Docker

Docker是一个在2013年开源的应用程序，并且是一个基于go语言编写的PAAS服务。 

Docker最早采用LXC技术，之后改为自己研发并开源的**runc**技术运行容器。

 Docker相比虚拟机的交付速度更快，资源消耗更低，Docker采用客户端、服务端架构，使用远程api来 管理和创建Docker容器。 

Docker的三大理念是build（构建）、ship（运输）、run（运行）。 

Docker遵从apache2.0协议，并通过namespace、cgroup等技术来提供容器的资源隔离与安全保障。



怎么出现的

- 轻量、高效的虚拟化

  Docker 公司位于旧金山,原名dotCloud，底层利用了Linux容器技术（在操作系统中实现资源隔离与限制）。为了方便创建和管理这些容器，dotCloud 开发了一套内部工具，之后被命名为“Docker”。Docker就是这样诞生的。

  （思考为啥要用Linux容器技术？）

  ![](http://cdn.gtrinee.top/docker-differents.svg)

Hypervisor： 一种运行在基础物理服务器和操作系统之间的中间软件层，可允许多个操作系统和应用共享硬件 。常见的VMware的 Workstation 、ESXi、微软的Hyper-V或者思杰的XenServer。

Container Runtime：通过Linux内核虚拟化能力管理多个容器，多个容器共享一套操作系统内核。因此摘掉了内核占用的空间及运行所需要的耗时，使得容器极其轻量与快速。

- 软件交付过程中的环境依赖

  ![](F:\BaiduNetdiskDownload\14小时搞定k8s企业级devops实践\课件\DevOps训练营课件最新版(2020-04-11)\images\why.png)

几个知识点

- 可以把应用程序代码及运行依赖环境打包成镜像，作为交付介质，在各环境部署

- 可以将镜像（image）启动成为容器(container)，并且提供多容器的生命周期进行管理（启、停、删）

- container容器之间相互隔离，且每个容器可以设置资源限额

- 提供轻量级虚拟化功能，容器就是在宿主机中的一个个的虚拟的空间，彼此相互隔离，完全独立

- CS架构的软件产品

  ![](F:\BaiduNetdiskDownload\14小时搞定k8s企业级devops实践\课件\DevOps训练营课件最新版(2020-04-11)\images\docker-engine.png)

###### 

> Docker 1.8之前，使用[LXC](https://linuxcontainers.org/fr/lxc/introduction/)，Docker在上层做了封装， 把LXC复杂的容器创建与使用方式简化为自己的一套命令体系。 
>
> 之后，为了实现跨平台等复杂的场景，Docker抽出了libcontainer项目，把对namespace、cgroup的操作封装在libcontainer项目里，支持不同的平台类型。
>
> 2015年6月，Docker牵头成立了 OCI（Open Container Initiative开放容器计划）组织，这个组织的目的是建立起一个围绕容器的通用标准 。 容器格式标准是一种不受上层结构绑定的协议，即不限于某种特定操作系统、硬件、CPU架构、公有云等 ， 允许任何人在遵循该标准的情况下开发应用容器技术，这使得容器技术有了一个更广阔的发展空间。
>
> OCI成立后，libcontainer 交给OCI组织来维护，但是libcontainer中只包含了与kernel交互的库，因此基于libcontainer项目，后面又加入了一个CLI工具，并且项目改名为runC (https://github.com/opencontainers/runc )， 目前runC已经成为一个功能强大的runtime工具。
>
> Docker也做了架构调整。将容器运行时相关的程序从docker daemon剥离出来，形成了**containerd**。containerd向上为Docker Daemon提供了`gRPC接口`，使得Docker Daemon屏蔽下面的结构变化，确保原有接口向下兼容。向下通过`containerd-shim`结合`runC`，使得引擎可以独立升级，避免之前Docker Daemon升级会导致所有容器不可用的问题。
>
>  ![](http://cdn.gtrinee.top/containerd.png)



# Docker与虚拟机之间的对比

如下图分别是虚拟机与docker的实现框架。

![虚拟化是物理层面隔离](https://upload-images.jianshu.io/upload_images/5918960-ee82f20d52883e4c.png?imageMogr2/auto-orient/strip|imageView2/2/w/256/format/webp)

虚拟化是物理层面隔离

Hypervisor： 一种运行在基础物理服务器和操作系统之间的中间软件层，可允许多个操作系统和应用共享硬件 。常见的VMware的 Workstation 、ESXi、微软的Hyper-V或者思杰的XenServer。

![img](https://upload-images.jianshu.io/upload_images/5918960-34f6f589e0beeb04.png?imageMogr2/auto-orient/strip|imageView2/2/w/282/format/webp)

容器是APP层面的隔离



比较两图的差异，左图虚拟机的Guest OS层和Hypervisor层在docker中被Docker Engine层所替代。虚拟机的Guest OS即为虚拟机安装的[操作系统](https://link.jianshu.com?t=http://lib.csdn.net/base/operatingsystem)，它是一个**完整操作系统内核**；虚拟机的Hypervisor层可以简单理解为一个硬件虚拟化平台，它在Host OS是以内核态的驱动存在的。



虚拟机**实现资源隔离的方法是利用独立的OS**，并利用**Hypervisor虚拟化CPU、内存、IO设备等实现的。**例如，为了虚拟CPU，Hypervisor会为每个虚拟的CPU创建一个[数据结构](https://link.jianshu.com?t=http://lib.csdn.net/base/datastructure)，模拟CPU的全部寄存器的值，在适当的时候跟踪并修改这些值。需要指出的是在大多数情况下，虚拟机软件代码是直接跑在硬件上的，而不需要Hypervisor介入。只有在一些权限高的请求下，Guest OS需要运行内核态修改CPU的寄存器数据，Hypervisor会介入，修改并维护虚拟的CPU状态。



对比虚拟机实现资源和环境隔离的方案，**docker就显得简练很多**。docker Engine可以简单看成对[Linux](https://link.jianshu.com?t=http://lib.csdn.net/base/linux)的NameSpace、Cgroup、镜像管理文件**系统操作的封装**。docker并没有和虚拟机一样利用一个完全独立的Guest OS实现环境隔离，它利用的是目前[linux](https://link.jianshu.com?t=http://lib.csdn.net/base/linux)内核本身支持的容器方式实现资源和环境隔离。简单的说，docker利用namespace实现系统环境的隔离；利用Cgroup实现资源限制；利用镜像实现根目录环境的隔离。

![image-20230227093817405](http://cdn.gtrinee.top/image-20230227093817405.png)





# Docker的组成

```
官网：https://docs.docker.com/get-started/overview/
Docker主机 host：一个物理机或者虚拟机，用于运行docker服务进程和容器
Docker服务端 Server：Docker守护进程，运行docker容器
Docker客户端 client：客户端使用docker命令或其他工具调用docker api
Docker仓库 registry：保存镜像的仓库，类似于git或svn这样的版本控制器
Docker镜像 images：镜像可以理解为创建实例使用的模板
Docker容器 container：容器是从镜像生成对外提供服务的一个或一组服务
```

![image-20230227103001155](http://cdn.gtrinee.top/image-20230227103001155.png)

#### 心要素及常用操作详解

![](http://cdn.gtrinee.top/docker%E6%9E%B6%E6%9E%84.png)

三大核心要素：镜像(Image)、容器(Container)、仓库(Registry)

（先整体看下流程，再逐个演示）

###### 镜像（Image）

打包了业务代码及运行环境的包，是静态的文件，不能直接对外提供服务。

###### 容器（Container）

镜像的运行时，可以对外提供服务。本质上讲是利用namespace和cgroup等技术在宿主机中创建的独立的虚拟空间。

###### 仓库（Registry）

- 公有仓库，Docker Hub，阿里，网易...
- 私有仓库，企业内部搭建
  - Docker Registry，Docker官方提供的镜像仓库存储服务
  - Harbor, 是Docker Registry的更高级封装，它除了提供友好的Web UI界面，角色和用户权限管理，用户操作审计等功能 
- 镜像访问地址形式 registry.devops.com/demo/hello:latest,若没有前面的url地址，则默认寻找Docker Hub中的镜像，若没有tag标签，则使用latest作为标签
- 公有的仓库中，一般存在这么几类镜像 
  - 操作系统基础镜像（centos，ubuntu，suse，alpine）
  - 中间件（nginx，redis，mysql，tomcat）
  - 语言编译环境（python，java，golang）
  - 业务镜像（django-demo...）

# Docker安装及基础命令

- 安装docker-ce以及客户端

```bash
root@docker-server ~]# yum install wget.x86_64 -y
[root@docker-server ~]# rm -rf /etc/yum.repos.d/*
[root@docker-server ~]# wget -O /etc/yum.repos.d/Centos-7.repo
http://mirrors.aliyun.com/repo/Centos-7.repo
[root@docker-server ~]# wget -O /etc/yum.repos.d/epel-7.repo
http://mirrors.aliyun.com/repo/epel-7.repo
[root@docker-server ~]# wget -O /etc/yum.repos.d/docker-ce.repo
https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
[root@docker-server ~]# yum install docker-ce -y

```

- 启动docker

```bash
[root@docker-server ~]# systemctl enable docker.service
Created symlink from /etc/systemd/system/multiuser.target.wants/docker.service to /usr/lib/systemd/system/docker.service.
[root@docker-server ~]# systemctl start docker.service

#快速开始
root@docker-server ~]# docker pull nginx
[root@docker-server ~]# docker images
REPOSITORY TAG IMAGE ID CREATED SIZE
nginx latest d1a364dc548d 5 days ago 133MB
[root@docker-server ~]# docker run -d -p 80:80 nginx
e617ca1db9a5d242e6b4145b9cd3dff9f7955c6ab1bf160f13fb6bec081a29e4
[root@docker-server ~]# docker ps
CONTAINER ID IMAGE COMMAND CREATED STATUS
PORTS NAMES
e617ca1db9a5 nginx "/docker-entrypoint.…" 6 seconds ago Up 5
seconds 0.0.0.0:80->80/tcp, :::80->80/tcp intelligent_turing
[root@docker-server ~]# docker exec -it e617ca1db9a5 bash
root@e617ca1db9a5:/# cd /usr/share/nginx/html/
root@e617ca1db9a5:/usr/share/nginx/html# ls
50x.html index.html
root@e617ca1db9a5:/usr/share/nginx/html# echo 'docker nginx test' >
index.html
[root@docker-server ~]# curl 192.168.80.10
docker nginx test
```



# 镜像加速配置 

打开网址 http://cr.console.aliyun.com/ 登陆之后点击镜像加速器，按照指导说明即

# Linux namespace技术

![image-20230302195022797](http://cdn.gtrinee.top/image-20230302195022797.png)

如果一个宿主机运行了N个容器，多个容器带来的以下问题怎么解决：

```
1. 怎么样保证每个容器都有不同的文件系统并且能互不影响？
2. 一个docker主进程内的各个容器都是其子进程， 那么如何实现同一个主进程下不同类型的子进程？
各个子进程间通信能相互访问吗？
3. 每个容器怎么解决IP以及端口分配的问题？
4. 多个容器的主机名能一样吗？
5. 每个容器都要不要有root用户？怎么解决账户重名问题呢？
```

以上问题怎么解决

 namespace是Linux系统的底层概念，在内核层实现，即有一些不同类型的命名空间都部署在核内，各 个docker容器运行在同一个docker主进程并且**共用同一个宿主机系统内核**，各个docker容器运行在宿主 机的用户空间，每个容器都要有类似于虚拟机一样的相互隔离的运行空间，**但是容器技术是在一个进程 内实现运行指定服务的运行环境**，并且还可以保护宿主机内核不受其他进程的干扰和影响，如文件系统、网络空间、进程空间等，目前主要通过以下技术实现容器运行空间的相互隔离：

命名空间是全局资源的一种抽象，将资源放到不同的命名空间中，各个命名空间中的资源是相互隔离的。 通俗来讲，**就是docker在启动一个容器的时候，会调用Linux Kernel Namespace的接口，来创建一块虚拟空间**，创建的时候，可以支持设置下面这几种（可以随意选择）,docker默认都设置。

- pid：用于进程隔离（PID：进程ID）
- net：管理网络接口（NET：网络）
- ipc：管理对 IPC 资源的访问（IPC：进程间通信（信号量、消息队列和共享内存））
- mnt：管理文件系统挂载点（MNT：挂载）
- uts：隔离主机名和域名
- user：隔离用户和用户组（3.8以后的内核才支持）



### MNT Namespace

每个容器都要有独立的根文件系统有独立的用户空间，以实现容器里面启动服务并且使用容器的运行环 境。

- 连接进入某一个容器中，并创建一个文件

```bash
[root@docker-server ~]# docker exec -it nginx-1 bash
root@0e72f06bba41:/# echo 'hello world test!' > /opt/test1
root@0e72f06bba41:/# exit

```

- 宿主机是使用了chroot技术把容器锁定到一个指定的运行目录里

```bash
[root@docker-server diff]# find / -name test1
/var/lib/docker/overlay2/f9cc560395b5e3b11d2b1293922c4d31e6a6a32ca59af3d9274e
abdfc6832424/diff/opt/test1
/var/lib/docker/overlay2/f9cc560395b5e3b11d2b1293922c4d31e6a6a32ca59af3d9274e
abdfc6832424/merged/opt/test1
[root@docker-server diff]#

```

### IPC Namespace

一个容器内的进程间通信，**允许一个容器内的不同进程数据互相访问，但是不能跨容器访问其他容器的数据** 

### UTS Namespace

包含了运行内核的名称、版本、底层体系结构类型等信息用于系统表示，其中包含了 **hostname和域名**，它使得一个容器拥有属于自己hostname标识，这个主机名标识独立于宿主机系统和 其上的其他容器。

### PID Namespace

Linux系统中，有一个pid为1的进程（init/systemd）是其他所有进程的父进程，那么在每个容器内也要 有一个父进程来管理其下属的进程，那么多个容器的进程通PID namespace进程隔离

```bash
root@0e72f06bba41:/# apt update
# ifconfig
root@0e72f06bba41:/# apt install net-tools
# top
root@0e72f06bba41:/# apt install procps
# ping
root@0e72f06bba41:/# apt install iputils-ping
root@0e72f06bba41:/# ps -ef
UID PID PPID C STIME TTY TIME CMD
root 10 0 03:20 ? 00:00:00 nginx: master process nginx -g d
nginx 32 1 0 03:20 ? 00:00:00 nginx: worker process
nginx 33 1 0 03:20 ? 00:00:00 nginx: worker process
nginx 34 1 0 03:20 ? 00:00:00 nginx: worker process
nginx 35 1 0 03:20 ? 00:00:00 nginx: worker process
nginx 36 1 0 03:20 ? 00:00:00 nginx: worker process
nginx 37 1 0 03:20 ? 00:00:00 nginx: worker process
nginx 38 1 0 03:20 ? 00:00:00 nginx: worker process
nginx 39 1 0 03:20 ? 00:00:00 nginx: worker process
root 59 0 0 03:35 pts/0 00:00:00 bash
root 503 59 0 03:42 pts/0 00:00:00 ps -ef
```

**那么宿主机的PID与容器内的PID是什么关系？**

```bash
[root@node1 yum.repos.d]# docker ps
CONTAINER ID   IMAGE     COMMAND                   CREATED         STATUS         PORTS                      NAMES  6969b628d791   nginx     "/docker-entrypoint.…"   3 seconds ago   Up 2 seconds   0.0.0.0:80->80/tcp, :::80->80/tcp   gifted_panini


[root@node1 yum.repos.d]# pstree -p
systemd(1)─┬─NetworkManager(6339)─┬─{NetworkManager}(6585)
           │                      └─{NetworkManager}(6587)
           ├─agetty(6465)
           ├─auditd(5844)───{auditd}(5848)
           ├─chronyd(6479)
           ├─containerd(7973)─┬─{containerd}(7982)
           │                  ├─{containerd}(7983)
           │                  ├─{containerd}(7984)
           │                  ├─{containerd}(7985)
           │                  ├─{containerd}(7986)
           │                  └─{containerd}(7994)
           ├─containerd-shim(17569)─┬─nginx(17588)───nginx(17637)
           │                        ├─{containerd-shim}(17570)
           │                        ├─{containerd-shim}(17571)
           │                        ├─{containerd-shim}(17572)
           │                        ├─{containerd-shim}(17573)
           │                        ├─{containerd-shim}(17574)
           │                        ├─{containerd-shim}(17575)
           │                        ├─{containerd-shim}(17576)
           │                        ├─{containerd-shim}(17577)
           │                        ├─{containerd-shim}(17608)
           │                        └─{containerd-shim}(17609)
           ├─crond(6435)
           ├─dbus-daemon(6119)
           ├─dockerd(8891)─┬─docker-proxy(17553)─┬─{docker-proxy}(17554)
           │               │                     ├─{docker-proxy}(17555)
           │               │                     ├─{docker-proxy}(17556)
           │               │                     └─{docker-proxy}(17558)
           │               ├─docker-proxy(17557)─┬─{docker-proxy}(17559)
           │               │                     ├─{docker-proxy}(17560)
           │               │                     ├─{docker-proxy}(17561)
           │               │                     └─{docker-proxy}(17562)
           │               ├─{dockerd}(8892)
           │               ├─{dockerd}(8893)
           │               ├─{dockerd}(8894)
           │               ├─{dockerd}(8895)
           │               ├─{dockerd}(8896)
           │               ├─{dockerd}(8898)
           │               ├─{dockerd}(11406)
           │               └─{dockerd}(11410)
           ├─lvmetad(3134)
           ├─master(6904)─┬─pickup(13086)
           │              └─qmgr(6906)
           ├─polkitd(6340)─┬─{polkitd}(6580)
           │               ├─{polkitd}(6581)
           │               ├─{polkitd}(6582)
           │               ├─{polkitd}(6583)
           │               ├─{polkitd}(6584)
           │               └─{polkitd}(6588)
           ├─rsyslogd(6822)─┬─{rsyslogd}(6827)
           │                └─{rsyslogd}(6828)
           ├─sshd(6818)─┬─sshd(7075)───bash(7082)───pstree(17661)
           │            └─sshd(7080)───sftp-server(7099)
           ├─systemd-journal(3107)
           ├─systemd-logind(6369)
           ├─systemd-udevd(3135)
           └─tuned(6820)─┬─{tuned}(7061)
                         ├─{tuned}(7062)
                         ├─{tuned}(7063)
                         └─{tuned}(7078)

```

### Net Namespace

每一个容器都类似于虚拟机一样有自己的网卡、监听端口、TCP/IP协议栈等，Docker使用network namespace启动一个vethX接口，这样容器将拥有它自己的桥接IP地址，通常是docker0，而docker0实 质就是linux的虚拟网桥。

```bash
[root@node1 yum.repos.d]# ifconfig
docker0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500
        inet 172.17.0.1  netmask 255.255.0.0  broadcast 172.17.255.255
        inet6 fe80::42:51ff:fe1e:b3df  prefixlen 64  scopeid 0x20<link>
        ether 02:42:51:1e:b3:df  txqueuelen 0  (Ethernet)
        RX packets 0  bytes 0 (0.0 B)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 5  bytes 446 (446.0 B)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0

ens33: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500
        inet 192.168.153.30  netmask 255.255.255.0  broadcast 192.168.153.255
        inet6 fe80::1206:1ce2:e592:fc5e  prefixlen 64  scopeid 0x20<link>
        ether 00:0c:29:63:1e:89  txqueuelen 1000  (Ethernet)
        RX packets 93684  bytes 114247634 (108.9 MiB)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 30456  bytes 2255770 (2.1 MiB)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0

lo: flags=73<UP,LOOPBACK,RUNNING>  mtu 65536
        inet 127.0.0.1  netmask 255.0.0.0
        inet6 ::1  prefixlen 128  scopeid 0x10<host>
        loop  txqueuelen 1000  (Local Loopback)
        RX packets 32  bytes 2592 (2.5 KiB)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 32  bytes 2592 (2.5 KiB)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0

vethdc819e6: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500
        inet6 fe80::74e0:84ff:fe77:6008  prefixlen 64  scopeid 0x20<link>
        ether 76:e0:84:77:60:08  txqueuelen 0  (Ethernet)
        RX packets 0  bytes 0 (0.0 B)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 8  bytes 656 (656.0 B)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0

```

![image-20230227132424164](http://cdn.gtrinee.top/image-20230227132424164.png)

### User Namespace

各个容器内可能会出现重名的用户和用户组名称，或重复的用户UID或者GID，那么怎么隔离各个容器内 的用户空间呢？

 User Namespace**允许在各个宿主机的各个容器空间内创建相同的用户名以及相同的uid和gid，只是此 用户的有效范围仅仅是当前的容器内，不能访问另外一个容器内的文件系统，即相互隔离、互不影响、 永不相见**

# Linux control groups

通过namespace可以保证容器之间的隔离，但是**无法控制每个容器可以占用多少资源**， 如果其中的某一个容器正在执行 CPU 密集型的任务，那么就会影响其他容器中任务的性能与执行效率，导致多个容器相互影响并且抢占资源。如何对多个容器的资源使用进行限制就成了解决进程虚拟资源隔离之后的主要问题。 

![](http://cdn.gtrinee.top/cgroup.png)

Control Groups（简称 CGroups）就是能够**隔离宿主机器上的物理资源，例如 CPU、内存、磁盘 I/O 和网络带宽。**每一个 CGroup 都是一组被相同的标准和参数限制的进程。而我们需要做的，其实就是把容器这个进程加入到指定的Cgroup中。深入理解CGroup，请[点此](![image-20200323195718300](C:\Users\liyongxin\AppData\Roaming\Typora\typora-user-images\image-20200323195718300.png))。



在一个容器内部，如果不对其做任何资源限制，则宿主机会允许其占用无限大的内存空间，有时候会因 为代码bug程序会一直申请内存，直到把宿主机内存占完，为了避免此类的问题出现，宿主机有必要对 容器进行**资源分配限制**，比如cpu、内存等，Linux Cgroups的全称是Linux control Groups，它最重要 的作用就是**限制一个进程组能够使用的资源上线**，包括cpu、内存、磁盘、网络等等。



```bash
[root@node1 yum.repos.d]# cat /boot/config-3.10.0-957.el7.x86_64 | grep cgroup -i
CONFIG_CGROUPS=y
# CONFIG_CGROUP_DEBUG is not set
CONFIG_CGROUP_FREEZER=y
CONFIG_CGROUP_PIDS=y
CONFIG_CGROUP_DEVICE=y
CONFIG_CGROUP_CPUACCT=y
CONFIG_CGROUP_HUGETLB=y
CONFIG_CGROUP_PERF=y
CONFIG_CGROUP_SCHED=y
CONFIG_BLK_CGROUP=y
# CONFIG_DEBUG_BLK_CGROUP is not set
CONFIG_NETFILTER_XT_MATCH_CGROUP=m
CONFIG_NET_CLS_CGROUP=y
CONFIG_NETPRIO_CGROUP=y

#内存模块
[root@docker-server ~]# cat /boot/config-3.10.0-693.el7.x86_64 | grep mem -i
| grep cg -i
CONFIG_MEMCG=y
CONFIG_MEMCG_SWAP=y
CONFIG_MEMCG_SWAP_ENABLED=y
CONFIG_MEMCG_KMEM=y

CPU:使用调度程序为cgroup任务提供 CPU 的访问。
cpuacct:产生cgroup任务的 CPU 资源报告。
cpuset：如果是多核心的CPU,这个子系统会为cgroup任务分配单的CPU和内存。
devices:允许或拒绝cgroup任务对设备的访问。
freezer:暂停和恢复cgroup任务。
memory:设置每个cgroup 的内存限制以及产生内存资源报告。
net_cls:标记每个网络包以供 cgroup方便使用。
ns:命名空间子系统。
perf event:增加了对每个group的监测跟踪的能力，可以监测属于某个特定的group 的所有线程以及
运行在特定CPU上的线程


```

# UnionFS 联合文件系统

Linux namespace和cgroup分别解决了容器的资源隔离与资源限制，那么容器是很轻量的，通常每台机器中可以运行几十上百个容器， 这些个容器是共用一个image，还是各自将这个image复制了一份，然后各自独立运行呢？ 如果每个容器之间都是全量的文件系统拷贝，那么会导致至少如下问题：

- 运行容器的速度会变慢
- 容器和镜像对宿主机的磁盘空间的压力

怎么解决这个问题------**Docker的存储驱动**

- 镜像分层存储
- UnionFS

Docker 镜像是由一系列的层组成的，每层代表 Dockerfile 中的一条指令，比如下面的 Dockerfile 文件：

```dockerfile
FROM ubuntu:15.04
COPY . /app
RUN make /app
CMD python /app/app.py
```

这里的 Dockerfile 包含4条命令，其中每一行就创建了一层，下面显示了上述Dockerfile构建出来的镜像运行的容器层的结构：

![](F:\BaiduNetdiskDownload\14小时搞定k8s企业级devops实践\课件\DevOps训练营课件最新版(2020-04-11)\images\container-layers.jpg)

镜像就是由这些层一层一层堆叠起来的，**镜像中的这些层都是只读的，当我们运行容器的时候，就可以在这些基础层至上添加新的可写层，也就是我们通常说的`容器层`，对于运行中的容器所做的所有更改（比如写入新文件、修改现有文件、删除文件）都将写入这个容器层。**

对容器层的操作，主要利用了**写时复制（CoW）技术。**CoW就是copy-on-write，表示只在需要写时才去复制，这个是针对已有文件的修改场景。 CoW技术可以让所有的容器共享image的文件系统，所有数据都从image中读取，只有当要对文件进行写操作时，才从image里把要写的文件复制到自己的文件系统进行修改。所以无论有多少个容器共享同一个image，所做的写操作都是对从image中复制到自己的文件系统中的复本上进行，并不会修改image的源文件，且多个容器操作同一个文件，会在每个容器的文件系统里生成一个复本，每个容器修改的都是自己的复本，相互隔离，相互不影响。使用CoW可以有效的提高磁盘的利用率。 

![](F:\BaiduNetdiskDownload\14小时搞定k8s企业级devops实践\课件\DevOps训练营课件最新版(2020-04-11)\images\sharing-layers.jpg)

镜像中每一层的文件都是分散在不同的目录中的，如何把这些不同目录的文件整合到一起呢？

UnionFS 其实是一种为 Linux 操作系统设计的用于把多个文件系统联合到同一个挂载点的文件系统服务。  它能够将不同文件夹中的层联合（Union）到了同一个文件夹中，整个联合的过程被称为联合挂载（Union Mount）。

![](F:\BaiduNetdiskDownload\14小时搞定k8s企业级devops实践\课件\DevOps训练营课件最新版(2020-04-11)\images\aufs.png)

上图是AUFS的实现，AUFS是作为Docker存储驱动的一种实现，Docker 还支持了不同的存储驱动，包括 aufs、devicemapper、overlay2、zfs 和  Btrfs 等等，在最新的 Docker 中，overlay2 取代了 aufs 成为了推荐的存储驱动，但是在没有 overlay2 驱动的机器上仍然会使用 aufs 作为 Docker 的默认驱动。 



## docker info信息

```bash
[root@docker-server ~]# docker info
Client:
Context: default
Debug Mode: false
Plugins:
app: Docker App (Docker Inc., v0.9.1-beta3)
buildx: Build with BuildKit (Docker Inc., v0.5.1-docker)
scan: Docker Scan (Docker Inc.)

Server:
Containers: 2 # 当前主机运行容器总数
Running: 1 # 有几个容器是正在运行的
Paused: 0 # 有几个容器是暂停的
Stopped: 1 # 有几个容器是停止的
Images: 1 # 当前服务器的镜像数
Server Version: 20.10.6 # 服务端版本
Storage Driver: overlay2 # 正在使用的存储引擎
Backing Filesystem: xfs # 后端文件系统，即服务器的磁盘文件系统
Supports d_type: true # 是否支持d_type
Native Overlay Diff: true # 是否支持差异数据存储
userxattr: false
Logging Driver: json-file # 日志文件类型
Cgroup Driver: cgroupfs # cgroups类型
Cgroup Version: 1
Plugins: # 插件
Volume: local # 卷
Network: bridge host ipvlan macvlan null overlay
Log: awslogs fluentd gcplogs gelf journald json-file local logentries
splunk syslog
Swarm: inactive # 是否支持swarm
Runtimes: io.containerd.runc.v2 io.containerd.runtime.v1.linux runc
Default Runtime: runc # 默认的runtime
Init Binary: docker-init # 初始化容器的守护进程
containerd version: d71fcd7d8303cbf684402823e425e9dd2e99285d
runc version: b9ee9c6314599f1b4a7f497e1f1f856fe433d3b7
init version: de40ad0
Security Options: # 安全选项
seccomp
Profile: default
Kernel Version: 3.10.0-693.el7.x86_64 # 宿主机内核版本
Operating System: CentOS Linux 7 (Core) # 宿主机操作系统
OSType: linux # 宿主机操作系统类型
Architecture: x86_64 # 宿主机架构
CPUs: 1 # 宿主机cpu数量
Total Memory: 1.781GiB # 宿主机总内存
Name: docker-server # 宿主机主机名
ID: ARN5:ESPO:FEZ4:KDZ6:RWGG:WQ3X:SIXN:3FVG:ATXH:JAXA:ENGH:RAVE
Docker Root Dir: /var/lib/docker # 宿主机数据保存目录
Debug Mode: false
Registry: https://index.docker.io/v1/ # 镜像仓库
Labels:
Experimental: false # 是否是测试版
Insecure Registries:
127.0.0.0/8
Live Restore Enabled: false # 是否开启活动容器（重启不关闭容器）
```



![](E:\桌面文件\英格笔记\正式课\linux笔记\images\run容器流程图.jpg)

![](http://cdn.gtrinee.top/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4.jpg)

# 实际操作

1. 解压离线包

   为了保证镜像下载的速度，因此提前在一台节点下载了离线镜像包，做解压：

   ```powershell
   $ tar zxf registry.tar.gz -C /opt
   $ ll /opt/registry-data
   total 25732
   drwxr-xr-x 3 root root     4096 Apr  9 20:11 registry
   -rw------- 1 root root 26344448 Apr  9 22:15 registry-v2.tar
   ```

2. 查看所有镜像：

```powershell
$ docker images
```

2. 拉取镜像:

```powershell
$ docker pull nginx:alpine
```

NAME是镜像名称，TAG是镜像的标签（往往用来是表示版本信息），通常情况下，描述一个镜 像需要包括名称+标签，如果不指定标签，标签的值默认为latest。

> 可以使用docker inspect命令获取该镜像的详细信息

3. 如何唯一确定镜像: 

- image_id 
- repository:tag

```powershell
$ docker images
REPOSITORY    TAG                 IMAGE ID            CREATED             SIZE
nginx         alpine              377c0837328f        2 weeks ago         19.7MB
```

4. **导出**镜像到文件中

   可以将**镜像**从本地导出为一个压缩文件，然后复制到其他服务器进行导入使用

   ```powershell
   $ docker save -o nginx-alpine.tar nginx:alpine
   ```

   

   ```bash
   #导出方法一
   root@docker-server ~]# docker save centos:latest -o /opt/centos.tar.gz
   [root@docker-server ~]# ll /opt/centos.tar.gz
   -rw------- 1 root root 216535040 6月 9 10:33 /opt/centos.tar.gz
   #方法二
   root@docker-server ~]# docker save centos:latest > /opt/centos-1.tar.gz
   [root@docker-server ~]# ll /opt/centos-1.tar.gz
   -rw-r--r-- 1 root root 216535040 6月 9 10:35 /opt/centos-1.tar.gz
   ```

   

5. 从文件中加载镜像/**导入**

   先将导出的镜像发到需要导入的docker服务器中

   ```powershell
   $ docker load -i nginx-alpine.tar
   ```

   ```bash
   #导入方法一
   root@docker-server ~]# docker load -i /opt/centos.tar.gz
   Loaded image: centos:latest
   
   #导入方法二
   [root@docker-server ~]# docker load < /opt/centos.tar.gz
   Loaded image: centos:latest
   ```

   

6. 部署镜像仓库

   https://docs.docker.com/registry/ 

   ![image-20230227141441871](http://cdn.gtrinee.top/image-20230227141441871.png)

   ```powershell
   ## 使用docker镜像启动镜像仓库服务
   $ docker run -d -p 5000:5000 --restart always -v /opt/registry-data/registry:/var/lib/registry --name registry registry:2
    
   ## 默认仓库不带认证，若需要认证，参考https://docs.docker.com/registry/deploying/#restricting-access
   ```

   假设启动镜像仓库服务的主机地址为172.21.32.6，该目录中已存在的镜像列表：

   | 现镜像仓库地址                                               | 原镜像仓库地址                                               |
   | ------------------------------------------------------------ | ------------------------------------------------------------ |
   | 172.21.32.6:5000/coreos/flannel:v0.11.0-amd64                | quay.io/coreos/flannel:v0.11.0-amd64                         |
   | 172.21.32.6:5000/mysql:5.7                                   | mysql:5.7                                                    |
   | 172.21.32.6:5000/nginx:alpine                                | nginx:alpine                                                 |
   | 172.21.32.6:5000/centos:centos7.5.1804                       | centos:centos7.5.1804                                        |
   | 172.21.32.6:5000/elasticsearch/elasticsearch:7.4.2           | docker.elastic.co/elasticsearch/elasticsearch:7.4.2          |
   | 172.21.32.6:5000/fluentd-es-root:v1.6.2-1.0                  | gcr.io/google_containers/fluentd-elasticsearch:v2.4.0        |
   | 172.21.32.6:5000/kibana/kibana:7.4.2                         | docker.elastic.co/kibana/kibana:7.4.2                        |
   | 172.21.32.6:5000/kubernetesui/dashboard:v2.0.0-beta5         | kubernetesui/dashboard:v2.0.0-beta5                          |
   | 172.21.32.6:5000/kubernetesui/metrics-scraper:v1.0.1         | kubernetesui/metrics-scraper:v1.0.1                          |
   | 172.21.32.6:5000/kubernetes-ingress-controller/nginx-ingress-controller:0.30.0 | quay.io/kubernetes-ingress-controller/nginx-ingress-controller:0.30.0 |

   

7. 推送本地镜像到镜像仓库中

   ```powershell
   $ docker tag nginx:alpine localhost:5000/nginx:alpine
   $ docker push localhost:5000/nginx:alpine
   ## 我的镜像仓库给外部访问，不能通过localhost，尝试使用内网地址172.21.16.3:5000/nginx:alpine
   $ docker tag nginx:alpine 172.21.16.3:5000/nginx:alpine
   $ docker push 172.21.16.3:5000/nginx:alpine
   The push refers to repository [172.21.16.3:5000/nginx]
   Get https://172.21.16.3:5000/v2/: http: server gave HTTP response to HTTPS client
   ## docker默认不允许向http的仓库地址推送，如何做成https的，参考：https://docs.docker.com/registry/deploying/#run-an-externally-accessible-registry
   ## 我们没有可信证书机构颁发的证书和域名，自签名证书需要在每个节点中拷贝证书文件，比较麻烦，因此我们通过配置daemon的方式，来跳过证书的验证：
   $ cat /etc/docker/daemon.json
   {
     "registry-mirrors": [
       "https://8xpk5wnt.mirror.aliyuncs.com"
     ],
     "insecure-registries": [
        "172.21.16.3:5000"
     ]
   }
   $ systemctl restart docker
   $ docker push 172.21.16.3:5000/nginx:alpine
   $ docker images	# IMAGE ID相同，等于起别名或者加快捷方式
   REPOSITORY               TAG                 IMAGE ID            CREATED             SIZE
   172.21.16.3:5000/nginx   alpine              377c0837328f        4 weeks ago         
   nginx                    alpine              377c0837328f        4 weeks ago         
   localhost:5000/nginx     alpine              377c0837328f        4 weeks ago         
   registry                 2                   708bc6af7e5e        2 months ago       
   ```

8. 删除镜像

   ```powershell
   docker rmi nginx:alpine
   ```

   使用镜像id

   ```bash
   [root@docker-server ~]# docker rmi 300e315adb2f
   Error response from daemon: conflict: unable to delete 300e315adb2f (must be
   forced) - image is referenced in multiple repositories
   [root@docker-server ~]# docker rmi 300e315adb2f -f
   Untagged: centos:latest
   Untagged:
   centos@sha256:5528e8b1b1719d34604c87e11dcd1c0a20bedf46e83b5632cdeac91b8c04ef
   c1
   Untagged: mycentos:latest
   Deleted:
   sha256:300e315adb2f96afe5f0b2780b87f28ae95231fe3bdd1e16b9ba606307728f55
   Deleted:
   sha256:2653d992f4ef2bfd27f94db643815aa567240c37732cae1405ad1c1309ee9859
   [root@docker-server ~]# docker images
   REPOSITORY TAG IMAGE ID CREATED SIZE
   hello-world latest d1165f221234 3 months ago 13.3k
   ```

   

9. 查看容器列表

   ```powershell
   ## 查看运行状态的容器列表
   $ docker ps
   
   ## 查看全部状态的容器列表
   $ docker ps -a
   ```

10. 启动容器

    ```powershell
    ## 后台启动
    $ docker run --name nginx -d nginx:alpine
    ##查看run流程#
    ##查看容器进程
    ## 等同于在虚拟机中开辟了一块隔离的独立的虚拟空间
    ## 启动容器的同时进入容器，-ti与/bin/sh或者/bin/bash配套使用，意思未分配一个tty终端
    $ docker run --name nginx -ti nginx:alpine /bin/sh
    （注意：退出容器后，该容器会变成退出状态，因为容器内部的1号进程退出）
    
    ## 实际上，在运行容器的时候，镜像地址后面跟的命令等于是覆盖了原有的容器的CMD命令，因此，执行的这些命令在容器内部就是1号进程，若该进程不存在了，那么容器就会处于退出的状态，比如，宿主机中执行
    1. echo 1,执行完后，该命令立马就结束了
    2. ping www.baidu.com,执行完后，命令的进程会持续运行
    $ docker run -d --name test_echo nginx:alpine echo 1,容器会立马退出
    $ docker run -d --name test_ping nginx:alpine ping www.baidu.com,容器不会退出，但是因为没有加-d参数，因此一直在前台运行，若ctrl+C终止，则容器退出，因为1号进程被终止了
    
    
    ## 映射端口,把容器的端口映射到宿主机中,-p <host_port>:<container_port>
    $ docker run --name nginx -d -p 8080:80 nginx:alpine
    
    ## 资源限制,-cpuset-cpus用于设置容器可以使用的 vCPU 核。-c,--cpu-shares用于设置多个容器竞争 CPU 时，各个容器相对能分配到的 CPU 时间比例。假设有三个正在运行的容器，这三个容器中的任务都是 CPU 密集型的。第一个容器的 cpu 共享权值是 1024，其它两个容器的 cpu 共享权值是 512。第一个容器将得到 50% 的 CPU 时间，而其它两个容器就只能各得到 25% 的 CPU 时间了。如果再添加第四个 cpu 共享值为 1024 的容器，每个容器得到的 CPU 时间将重新计算。第一个容器的CPU 时间变为 33%，其它容器分得的 CPU 时间分别为 16.5%、16.5%、33%。必须注意的是，这个比例只有在 CPU 密集型的任务执行时才有用。在四核的系统上，假设有四个单进程的容器，它们都能各自使用一个核的 100% CPU 时间，不管它们的 cpu 共享权值是多少。
    $ docker run --cpuset-cpus="0-3" --cpu-shares=512 --memory=500m nginx:alpine
    ```

    ![](http://cdn.gtrinee.top/run%E5%AE%B9%E5%99%A8%E6%B5%81%E7%A8%8B%E5%9B%BE.jpg)

    docker create命令新建的工期处于停滞状态，可以使用docker start命令来启动它

    参数

    ![image-20230227142509980](http://cdn.gtrinee.top/image-20230227142509980.png)

    指定端口映射

    ```bash
    # 方式1，本地端口80映射到容器80端口
    [root@docker-server ~]# docker run -p 80:80 --name nginx-1 nginx:latest
    # 方式2，本地ip：本地端口：容器端口
    [root@docker-server ~]# docker run -p 192.168.80.10:80:80 --name nginx-1 nginx:latest
    # 方式3，本地ip：本地随机端口：容器端口
    [root@docker-server ~]# docker run -p 192.168.80.10::80 --name nginx-1 nginx:latest
    # 方式4，本地ip：本地端口：容器端口/协议默认为tcp协议
    [root@docker-server ~]# docker run -p 192.168.80.10:80:80/tcp --name nginx-1  nginx:latest
    
    ```

    查看容器已经映射的端口

    ```bash
    [root@docker-server ~]# docker port nginx-1
    80/tcp -> 0.0.0.0:80
    80/tcp -> :::80
    ```

    

11. 容器数据持久化

    ```powershell
    ## 挂载主机目录
    $ docker run --name nginx -d  -v /opt:/opt -v /var/log:/var/log nginx:alpine
    $ docker run --name mysql -e MYSQL_ROOT_P ASSWORD=123456 -d -v /opt/mysql/:/var/lib/mysql mysql:5.7
    
    ## 使用volumes卷
    $ docker volume ls
    $ docker volume create my-vol
    $ docker run --name nginx -d -v my-vol:/opt/my-vol nginx:alpine
    $ docker exec -ti nginx touch /opt/my-vol/a.txt
    
    ## 验证数据共享
    $ docker run --name nginx2 -d -v my-vol:/opt/hh nginx:alpine
    $ docker exec -ti nginx2 ls /opt/hh/
    a.txt
    ```

12. 进入容器或者执行容器内的命令

    ```powershell
    $ docker exec -ti <container_id_or_name> /bin/sh
    $ docker exec -ti <container_id_or_name> hostname
    ```

13. 主机与容器之间拷贝数据

    ```powershell
    ## 主机拷贝到容器
    $ echo '123'>/tmp/test.txt
    $ docker cp /tmp/test.txt nginx:/tmp
    $ docker exec -ti nginx cat /tmp/test.txt
    123
    
    ## 容器拷贝到主机
    $ docker cp nginx:/tmp/test.txt ./
    ```

14. 查看容器日志

    ```powershell
    ## 查看全部日志
    $ docker logs nginx
    
    ## 实时查看最新日志
    $ docker logs -f nginx
    
    ## 从最新的100条开始查看
    $ docker logs --tail=100 -f nginx
    ```

15. 停止或者删除容器

    ```powershell
    ## 停止运行中的容器
    $ docker stop nginx
    
    ## 启动退出容器
    $ docker start nginx
    
    ## 删除退出容器
    $ docker rm nginx
    
    ## 删除运行中的容器
    $ docker rm -f nginx
    ```

16. 查看容器或者镜像的明细

    ```powershell
    ## 查看容器详细信息，包括容器IP地址等
    $ docker inspect nginx
    
    ## 查看镜像的明细信息
    $ docker inspect nginx:alpine
    ```

    

### 指定容器DNS

dns服务，默认采用dns地址 

一是通过将dns地址配置在宿主机上 

二是将参数配置在docker启动脚本里面

```bash
[root@docker-server ~]# docker run -it --rm --dns 8.8.8.8 centos bash
[root@a6ce80126e75 /]# cat /etc/resolv.conf
nameserver 8.8.8.8
[root@a6ce80126e75 /]# ping www.baidu.com -c 1
PING www.a.shifen.com (180.101.49.11) 56(84) bytes of data.
64 bytes from 180.101.49.11 (180.101.49.11): icmp_seq=1 ttl=127 time=9.35 ms
--- www.a.shifen.com ping statistics ---
1 packets transmitted, 1 received, 0% packet loss, time 0ms
rtt min/avg/max/mdev = 9.346/9.346/9.346/0.000 ms
[root@a6ce80126e75 /]# exit
exit
```

## 导入导出容器

### docker export

导出容器是指，导出一个已经创建的容器到一个文件，不管此时这个容器是否处于运行状态

```bash
[root@docker-server ~]# docker run -d -it centos
43f2397b9456d27a3b84dba0d79ae9a1dd8dddf40440d7d73fca71cddea0e10d
[root@docker-server ~]# docker ps
CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS
NAMES
43f2397b9456 centos "/bin/bash" 2 seconds ago Up 2 seconds
awesome_rubin
[root@docker-server ~]# docker export -o /opt/centos.tar 43f
[root@docker-server ~]# ll /opt/centos.tar
-rw------- 1 root root 216525312 6月 9 13:28 /opt/centos.tar
```

导出的文件可以使用docker import命令导入变成镜像

```bash
[root@docker-server ~]# docker import /opt/centos.tar mycentos:v1
sha256:acf250a6cabb56e0464102dabedb0a562f933facd3cd7b387e665459da46bf29
[root@docker-server ~]# docker images
REPOSITORY TAG IMAGE ID CREATED SIZE
mycentos v1 acf250a6cabb 9 seconds ago 209MB
nginx latest d1a364dc548d 2 weeks ago 133MB
hello-world latest d1165f221234 3 months ago 13.3kB
centos latest 300e315adb2f 6 months ago 209MB
```

# 手动制作yum版nginx镜像：

Docker镜像制作类似于**虚拟机的模板**制作，即按照公司的实际业务将需要安装的软件、相关配置等基础 环境配置完成，然后将虚拟机再提交为模板，最后再批量从模板批量创建新的虚拟机，这样可以极大地 简化业务中相同环境的虚拟机运行环境的部署工作，Docker的镜像制作分为手动制作可自动制作（基于 **DockerFIle**），企业通常都是**基于DockerFile制作镜像**。

- 启动一个centos容器，安装好常用软件以及nginx

```bash
[root@docker-server ~]# docker run -it centos bash
# 安装wget、epel、nginx等相关常用软件
[root@0195bc1d0f7b ~]# yum install epel-release -y
[root@0195bc1d0f7b ~]# yum install nginx -y
[root@0195bc1d0f7b ~]# yum install vim wget pcre pcre-devel zlib zlib-devel openssl openssl-devel iproute net-tools iotop -y

```

- 关闭nginx后台运行

```bash
[root@0195bc1d0f7b ~]# vim /etc/nginx/nginx.conf
user nginx;
worker_processes auto;
error_log /var/log/nginx/error.log;
pid /run/nginx.pid;
daemon off;
```

- 自定义web界面

```bash
[root@0195bc1d0f7b ~]# echo 'eagleslab nginx!' >
/usr/share/nginx/html/index.html

```

- 提交为镜像

```bash
[root@docker-server ~]# docker commit --help
Usage: docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]]
Create a new image from a container's changes
Options:
-a, --author string Author (e.g., "John Hannibal Smith
<hannibal@a-team.com>")
-c, --change list Apply Dockerfile instruction to the created image
-m, --message string Commit message
-p, --pause Pause container during commit (default true)

[root@docker-server ~]# docker commit -a "2177780569@qq.com" -m "my nginx
image v1" 0195bc1d0f7b centos_nginx:v1
sha256:c29204bfca8d89a06a3bb841cc6ada3c8202798e8f92b5d24c592d48105379d7

[root@docker-server ~]# docker images
REPOSITORY TAG IMAGE ID CREATED SIZE
centos_nginx v1 c29204bfca8d 9 seconds ago 386MB
mycentos v1 acf250a6cabb About an hour ago 209MB
nginx latest d1a364dc548d 2 weeks ago 133MB
hello-world latest d1165f221234 3 months ago 13.3kB
centos latest 300e315adb2f 6 months ago 209MB
```

```

-m 来指定提交的说明信息，跟我们使用的版本控制工具一样；

-a 可以指定更新的用户信息；之后是用来创建镜像的容器的 ID；最后指定目标镜像的仓库名和 tag 信息。创建成功后会返回这个镜像的 ID 信息；

-c 制作镜像之后执行的命令

0195bc1d0f7b 容器ID，就是希望将哪个容器重新制作

centos-nginx 制作之后的镜像名称

```



- 从自己的镜像启动容器

```bash
[root@node1 opt]# docker run -d -p 83:80 --name nginx03 centos_nginx:v1
104041268cf348166af3050ef60167deabeb308234e6b67688ed20933966b823
[root@node1 opt]# docker ps -a

[root@node1 opt]# curl 192.168.153.30:83
<!DOCTYPE html>

```

![image-20230227160753742](http://cdn.gtrinee.top/image-20230227160753742.png)

# DockerFile制作镜像

DockerFile可以说是一种可以 被**Docker程序解释的脚本**，DockerFile是由一条条的命令组成的，每条命 令对应linux下面的一条命令，Docker程序将这些DockerFile指令再翻译成真正的linux命令，其有自己 的书写方式和支持的命令，Docker程序读取DockerFile并根据指令生成Docker镜像，相比手动制作镜像 的方式，**DockerFile更能直观地展示镜像是怎么产生的**，有了写好的各种各样的DockerFIle文件，当后 期某个镜像有额外的需求时，只要在之前的DockerFile添加或者修改相应的操作即可重新生成新的 Docker镜像，避免了重复手动制作镜像的麻烦。

![image-20230227160840333](http://cdn.gtrinee.top/image-20230227160840333.png)

![image-20230227160849941](http://cdn.gtrinee.top/image-20230227160849941.png)

Dockerfile是一堆指令，在docker build的时候，按照该指令进行操作，最终生成我们期望的镜像

- FROM 指定基础镜像，必须为第一个命令

  ```
  格式：
  	FROM <image>
  	FROM <image>:<tag>
  示例：
  	FROM mysql:5.7
  注意：
  	tag是可选的，如果不使用tag时，会使用latest版本的基础镜像
  ```

- MAINTAINER 镜像维护者的信息

  ```
  格式：
  	MAINTAINER <name>
  示例：
  	MAINTAINER Yongxin Li
      MAINTAINER inspur_lyx@hotmail.com
      MAINTAINER Yongxin Li <inspur_lyx@hotmail.com>
  ```

- COPY|ADD 添加本地文件到镜像中

  ```
  格式：
  	COPY <src>... <dest>
  示例：
      ADD hom* /mydir/          # 添加所有以"hom"开头的文件
      ADD test relativeDir/     # 添加 "test" 到 `WORKDIR`/relativeDir/
      ADD test /absoluteDir/    # 添加 "test" 到 /absoluteDir/
  ```

- WORKDIR 工作目录

  ```
  格式：
  	WORKDIR /path/to/workdir
  示例：
      WORKDIR /a  (这时工作目录为/a)
  注意：
  	通过WORKDIR设置工作目录后，Dockerfile中其后的命令RUN、CMD、ENTRYPOINT、ADD、COPY等命令都会在该目录下执行
  ```

- RUN 构建镜像过程中执行命令

  ```
  格式：
  	RUN <command>
  示例：
      RUN yum install nginx
      RUN pip install django
      RUN mkdir test && rm -rf /var/lib/unusedfiles
  注意：
  	RUN指令创建的中间镜像会被缓存，并会在下次构建中使用。如果不想使用这些缓存镜像，可以在构建时指定--no-cache参数，如：docker build --no-cache
  ```

- CMD 构建容器后调用，也就是在容器启动时才进行调用

  ```
  格式：
      CMD ["executable","param1","param2"] (执行可执行文件，优先)
      CMD ["param1","param2"] (设置了ENTRYPOINT，则直接调用ENTRYPOINT添加参数)
      CMD command param1 param2 (执行shell内部命令)
  示例：
      CMD ["/usr/bin/wc","--help"]
      CMD ping www.baidu.com
  注意：
  	CMD不同于RUN，CMD用于指定在容器启动时所要执行的命令，而RUN用于指定镜像构建时所要执行的命令。
  ```

- ENTRYPOINT 设置容器初始化命令，使其可执行化

  ```
  格式：
      ENTRYPOINT ["executable", "param1", "param2"] (可执行文件, 优先)
      ENTRYPOINT command param1 param2 (shell内部命令)
  示例：
      ENTRYPOINT ["/usr/bin/wc","--help"]
  注意：
  	ENTRYPOINT与CMD非常类似，不同的是通过docker run执行的命令不会覆盖ENTRYPOINT，而docker run命令中指定的任何参数，都会被当做参数再次传递给ENTRYPOINT。Dockerfile中只允许有一个ENTRYPOINT命令，多指定时会覆盖前面的设置，而只执行最后的ENTRYPOINT指令
  ```

- ENV

  ```
  格式：
      ENV <key> <value>
      ENV <key>=<value>
  示例：
      ENV myName John
      ENV myCat=fluffy
  ```

- EXPOSE

  ```
  格式：
      EXPOSE <port> [<port>...]
  示例：
      EXPOSE 80 443
      EXPOSE 8080
      EXPOSE 11211/tcp 11211/udp
  注意：
      EXPOSE并不会让容器的端口访问到主机。要使其可访问，需要在docker run运行容器时通过-p来发布这些端口，或通过-P参数来发布EXPOSE导出的所有端口
  
  ```

  ![](http://cdn.gtrinee.top/Dockerfile%E8%A7%A3%E9%87%8A.png)

# 制作nginx镜像

DockerFile可以说是一种可以被Docker程序解释的脚本，DockerFIle是由一条条的命令组成的，每条命 令对应Linux下面的一条命令，Docker程序将这些DockerFile指令再翻译成真正的Linux命令，其有自己 的书写方式和支持的命令，Docker程序读取DockerFile并根据指令生成Docker镜像。

- 下载镜像

```bash
[root@docker-server ~]# docker pull centos:7
```

- 创建目录环境

```bash
[root@docker-server opt]# mkdir -pv
dockerfile/{web/{nginx,apache},system/{centos,ubuntu}}
mkdir: 已创建目录 "dockerfile"
mkdir: 已创建目录 "dockerfile/web"
mkdir: 已创建目录 "dockerfile/web/nginx"
mkdir: 已创建目录 "dockerfile/web/apache"
mkdir: 已创建目录 "dockerfile/system"
mkdir: 已创建目录 "dockerfile/system/centos"
mkdir: 已创建目录 "dockerfile/system/ubuntu"
```

- 下载源码包

```bash
root@docker-server opt]# cd dockerfile/web/nginx/
[root@docker-server nginx]# pwd
/opt/dockerfile/web/nginx

[root@docker-server nginx]# wget http://nginx.org/download/nginx1.20.1.tar.gz
[root@docker-server nginx]# ls
Dockerfile nginx-1.20.1.tar.gz

```

- 编写DockerFile

```bash
[root@docker-server nginx]# cat Dockerfile
# 第一行先定义基础镜像，后面的本地有效的镜像名，如果本地有会从远程仓库下载
FROM centos:7

# 镜像维护者的信息
MAINTAINER bbj1030 123456@qq.com

# 将编译安装nginx的步骤执行一遍
RUN yum install -y vim wget tree lrzsz gcc gcc-c++ automake pcre pcre-devel
zlib zlib-devel openssl openssl-devel iproute net-tools iotop

# 上传nginx压缩包
ADD nginx-1.20.1.tar.gz /usr/local/src/

RUN cd /usr/local/src/nginx-1.20.1 \
&& ./configure --prefix=/usr/local/nginx --with-http_sub_module \
&& make \
&& make install \
&& cd /usr/local/nginx

# 可以添加自己事先准备的配置文件
# ADD nginx.conf /usr/local/nginx/conf/nginx.conf

RUN useradd -s /sbin/nologin nginx \
&& ln -sv /usr/local/nginx/sbin/nginx /usr/sbin/nginx \
&& echo 'test nginx !' > /usr/local/nginx/html/index.html

# 声明端口号
EXPOSE 80 443

CMD ["nginx", "-g", "daemon off;"]

```

- 构建镜像

```bash
[root@docker-server nginx]# docker build -t nginx:v1 .
[root@docker-server nginx]# docker images | grep v1
nginx v1 d6396708058c 17 minutes ago 520MB

```

![image-20230228151126847](http://cdn.gtrinee.top/image-20230228151126847.png)

- 测试

```bash
[root@docker-server nginx]# docker run -d -it -p 80:80 nginx:v1
```

# 官方docker仓库

- 准备账户 登陆到docker hub官网创建账号，登陆后点击settings完善信息 填写账户基本信息

![image-20230228152118390](http://cdn.gtrinee.top/image-20230228152118390.png)

- 登陆仓库

```bash

[root@docker-server ~]# docker login docker.io

[root@docker-server ~]# ls -a
. .bash_history .bashrc Dockerfile .tcshrc
.. .bash_logout .cshrc docker_in.sh .viminfo
anaconda-ks.cfg .bash_profile .docker .pki
[root@node1 ~]# cat .docker/config.json
{
        "auths": {
                "https://index.docker.io/v1/": {
                        "auth": "Z3RyaW5lZTpnamgyMDAyNzE1MjI="
                }
        }

```



![image-20230228152406086](http://cdn.gtrinee.top/image-20230228152406086.png)

- 给镜像tag标签并上传

```bash
[root@docker-server ~]# docker tag nginx:v1 docker.io/bbj1030/nginx:v1
[root@docker-server ~]# docker images
REPOSITORY TAG IMAGE ID CREATED SIZE
bbj1030/nginx v1 8ec4312e6814 23 minutes ago 520MB
nginx v1 8ec4312e6814 23 minutes ago 520MB
[root@docker-server ~]# docker push docker.io/bbj1030/nginx:v1
The push refers to repository [docker.io/bbj1030/nginx]
9a47281960fb: Pushed
600bb14a86ba: Pushed
936484a716e0: Pushed
1103b6d0580b: Pushed
174f56854903: Mounted from library/centos
v1: digest:
sha256:d56ccf29be1dd9afd41a9491438c33e4c775629a3cdc38eda7f5f88ff34d23f7
size: 1372
```

# Docker Compose

> compose、machine 和 swarm 是docker 原生提供的三大编排工具。简称docker三剑客。
>
> Docker Compose能够在 Docker 节点上，以单引擎模式(Single-Engine Mode)进行多容器应用的部 署和管理。多数的现代应用通过多个更小的微服务互相协同来组成一个完整可用的应用。
>
> 部署和管理繁多的服务是困难的。而这正是 Docker Compose 要解决的问题。Docker Compose 并不 是通过脚本和各种冗长的 docker 命令来将应用组件组织起来，而是通过一个声明式的配置文件描述整 个应用，从而使用一条命令完成部署。应用部署成功后，还可以通过一系列简单的命令实现对其完整声 明周期的管理。甚至，配置文件还可以置于版本控制系统中进行存储和管理。

### Compose 简介

Compose 是用于定义和运行多容器 Docker 应用程序的工具。通过 Compose，您可以使用 YML 文件来配置应用程序需要的所有服务。然后，使用一个命令，就可以从 YML 文件配置中创建并启动所有服务。

如果你还不了解 YML 文件配置，可以先阅读 [YAML 入门教程](https://www.runoob.com/w3cnote/yaml-intro.html)。

Compose 使用的三个步骤：

- 使用 Dockerfile 定义应用程序的环境。
- 使用 docker-compose.yml 定义构成应用程序的服务，这样它们可以在隔离环境中一起运行。
- 最后，执行 docker-compose up 命令来启动并运行整个应用程序。

docker-compose.yml 的配置案例如下（配置参数参考下文）：

## 实例

```yaml
# yaml 配置实例
version: '3'
services:
  web:
    build: .
    ports:
   - "5000:5000"
    volumes:
   - .:/code
    - logvolume01:/var/log
    links:
   - redis
  redis:
    image: redis
volumes:
  logvolume01: {}
```

------

## Compose 安装

Linux 上我们可以从 Github 上下载它的二进制包来使用，最新发行的版本地址：https://github.com/docker/compose/releases。

运行以下命令以下载 Docker Compose 的当前稳定版本：

```
$ sudo curl -L "https://github.com/docker/compose/releases/download/v2.2.2/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
```

要安装其他版本的 Compose，请替换 v2.2.2。

> Docker Compose 存放在 GitHub，不太稳定。
>
> 你可以也通过执行下面的命令，高速安装 Docker Compose。
>
> ```
> curl -L https://get.daocloud.io/docker/compose/releases/download/v2.4.1/docker-compose-`uname -s`-`uname -m` > /usr/local/bin/docker-compose
> ```

将可执行权限应用于二进制文件：

```
$ sudo chmod +x /usr/local/bin/docker-compose
```

创建软链：

```
$ sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose
```

测试是否安装成功：

```
$ docker-compose version
cker-compose version 1.24.1, build 4667896b
```

**注意**： 对于 alpine，需要以下依赖包： py-pip，python-dev，libffi-dev，openssl-dev，gcc，libc-dev，和 make。

## 使用

### 1、准备

创建一个测试目录：

```
$ mkdir composetest
$ cd composetest
```

在测试目录中创建一个名为 app.py 的文件，并复制粘贴以下内容：

```python
import time

import redis
from flask import Flask

app = Flask(__name__)
cache = redis.Redis(host='redis', port=6379)


def get_hit_count():
    retries = 5
    while True:
        try:
            return cache.incr('hits')
        except redis.exceptions.ConnectionError as exc:
            if retries == 0:
                raise exc
            retries -= 1
            time.sleep(0.5)


@app.route('/')
def hello():
    count = get_hit_count()
    return 'Hello World! I have been seen {} times.\n'.format(count)
```

在此示例中，redis 是应用程序网络上的 redis 容器的主机名，该主机使用的端口为 6379。

在 composetest 目录中创建另一个名为 **requirements.txt** 的文件，内容如下：

```
flask
redis
```

### 2、创建 Dockerfile 文件

在 composetest 目录中，创建一个名为 **Dockerfile** 的文件，内容如下：

```
FROM python:3.7-alpine
WORKDIR /code
ENV FLASK_APP app.py
ENV FLASK_RUN_HOST 0.0.0.0
RUN apk add --no-cache gcc musl-dev linux-headers
COPY requirements.txt requirements.txt
RUN pip install -r requirements.txt
COPY . .
CMD ["flask", "run"]
```

**Dockerfile 内容解释：**

- **FROM python:3.7-alpine**: 从 Python 3.7 映像开始构建镜像。

- **WORKDIR /code**: 将工作目录设置为 /code。

- ```
  ENV FLASK_APP app.py
  ENV FLASK_RUN_HOST 0.0.0.0
  ```

  设置 flask 命令使用的环境变量。

- **RUN apk add --no-cache gcc musl-dev linux-headers**: 安装 gcc，以便诸如 MarkupSafe 和 SQLAlchemy 之类的 Python 包可以编译加速。

- ```
  COPY requirements.txt requirements.txt
  RUN pip install -r requirements.txt
  ```

  复制 requirements.txt 并安装 Python 依赖项。

- **COPY . .**: 将 . 项目中的当前目录复制到 . 镜像中的工作目录。

- **CMD ["flask", "run"]**: 容器提供默认的执行命令为：flask run。

### 3、创建 docker-compose.yml

在测试目录中创建一个名为 docker-compose.yml 的文件，然后粘贴以下内容：

```yaml
# yaml 配置
version: '3'
services:
  web:
    build: .
    ports:
     - "5000:5000"
  redis:
    image: "redis:alpine"
```

该 Compose 文件定义了两个服务：web 和 redis。

- **web**：该 web 服务使用从 Dockerfile 当前目录中构建的镜像。然后，它将容器和主机绑定到暴露的端口 5000。此示例服务使用 Flask Web 服务器的默认端口 5000 。
- **redis**：该 redis 服务使用 Docker Hub 的公共 Redis 映像。

### 4、使用 Compose 命令构建和运行您的应用

在测试目录中，执行以下命令来启动应用程序：

：

```
docker-compose up
```

如果你想在后台执行该服务可以加上 **-d** 参数：

```
docker-compose up -d
```

------

## yml 配置指令参考

### version

指定本 yml 依从的 compose 哪个版本制定的。

### build

指定为构建镜像上下文路径：

例如 webapp 服务，指定为从上下文路径 ./dir/Dockerfile 所构建的镜像：

```
version: "3.7"
services:
  webapp:
    build: ./dir
```

或者，作为具有在上下文指定的路径的对象，以及可选的 Dockerfile 和 args：

```
version: "3.7"
services:
  webapp:
    build:
      context: ./dir
      dockerfile: Dockerfile-alternate
      args:
        buildno: 1
      labels:
        - "com.example.description=Accounting webapp"
        - "com.example.department=Finance"
        - "com.example.label-with-empty-value"
      target: prod
```

- context：上下文路径。
- dockerfile：指定构建镜像的 Dockerfile 文件名。
- args：添加构建参数，这是只能在构建过程中访问的环境变量。
- labels：设置构建镜像的标签。
- target：多层构建，可以指定构建哪一层。

### cap_add，cap_drop

添加或删除容器拥有的宿主机的内核功能。

```
cap_add:
  - ALL # 开启全部权限

cap_drop:
  - SYS_PTRACE # 关闭 ptrace权限
```

### cgroup_parent

为容器指定父 cgroup 组，意味着将继承该组的资源限制。

```
cgroup_parent: m-executor-abcd
```

### command

覆盖容器启动的默认命令。

```
command: ["bundle", "exec", "thin", "-p", "3000"]
```

### container_name

指定自定义容器名称，而不是生成的默认名称。

```
container_name: my-web-container
```

### depends_on

设置依赖关系。

- docker-compose up ：以依赖性顺序启动服务。在以下示例中，先启动 db 和 redis ，才会启动 web。
- docker-compose up SERVICE ：自动包含 SERVICE 的依赖项。在以下示例中，docker-compose up web 还将创建并启动 db 和 redis。
- docker-compose stop ：按依赖关系顺序停止服务。在以下示例中，web 在 db 和 redis 之前停止。

```
version: "3.7"
services:
  web:
    build: .
    depends_on:
      - db
      - redis
  redis:
    image: redis
  db:
    image: postgres
```

注意：web 服务不会等待 redis db 完全启动 之后才启动。

### deploy

指定与服务的部署和运行有关的配置。只在 swarm 模式下才会有用。

```
version: "3.7"
services:
  redis:
    image: redis:alpine
    deploy:
      mode：replicated
      replicas: 6
      endpoint_mode: dnsrr
      labels: 
        description: "This redis service label"
      resources:
        limits:
          cpus: '0.50'
          memory: 50M
        reservations:
          cpus: '0.25'
          memory: 20M
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s
```

可以选参数：

**endpoint_mode**：访问集群服务的方式。

```
endpoint_mode: vip 
# Docker 集群服务一个对外的虚拟 ip。所有的请求都会通过这个虚拟 ip 到达集群服务内部的机器。
endpoint_mode: dnsrr
# DNS 轮询（DNSRR）。所有的请求会自动轮询获取到集群 ip 列表中的一个 ip 地址。
```

**labels**：在服务上设置标签。可以用容器上的 labels（跟 deploy 同级的配置） 覆盖 deploy 下的 labels。

**mode**：指定服务提供的模式。

- **replicated**：复制服务，复制指定服务到集群的机器上。

- **global**：全局服务，服务将部署至集群的每个节点。

- 图解：下图中黄色的方块是 replicated 模式的运行情况，灰色方块是 global 模式的运行情况。

  ![img](https://www.runoob.com/wp-content/uploads/2019/11/docker-composex.png)

**replicas：mode** 为 replicated 时，需要使用此参数配置具体运行的节点数量。

**resources**：配置服务器资源使用的限制，例如上例子，配置 redis 集群运行需要的 cpu 的百分比 和 内存的占用。避免占用资源过高出现异常。

**restart_policy**：配置如何在退出容器时重新启动容器。

- condition：可选 none，on-failure 或者 any（默认值：any）。
- delay：设置多久之后重启（默认值：0）。
- max_attempts：尝试重新启动容器的次数，超出次数，则不再尝试（默认值：一直重试）。
- window：设置容器重启超时时间（默认值：0）。

**rollback_config**：配置在更新失败的情况下应如何回滚服务。

- parallelism：一次要回滚的容器数。如果设置为0，则所有容器将同时回滚。
- delay：每个容器组回滚之间等待的时间（默认为0s）。
- failure_action：如果回滚失败，该怎么办。其中一个 continue 或者 pause（默认pause）。
- monitor：每个容器更新后，持续观察是否失败了的时间 (ns|us|ms|s|m|h)（默认为0s）。
- max_failure_ratio：在回滚期间可以容忍的故障率（默认为0）。
- order：回滚期间的操作顺序。其中一个 stop-first（串行回滚），或者 start-first（并行回滚）（默认 stop-first ）。

**update_config**：配置应如何更新服务，对于配置滚动更新很有用。

- parallelism：一次更新的容器数。
- delay：在更新一组容器之间等待的时间。
- failure_action：如果更新失败，该怎么办。其中一个 continue，rollback 或者pause （默认：pause）。
- monitor：每个容器更新后，持续观察是否失败了的时间 (ns|us|ms|s|m|h)（默认为0s）。
- max_failure_ratio：在更新过程中可以容忍的故障率。
- order：回滚期间的操作顺序。其中一个 stop-first（串行回滚），或者 start-first（并行回滚）（默认stop-first）。

**注**：仅支持 V3.4 及更高版本。

### devices

指定设备映射列表。

```
devices:
  - "/dev/ttyUSB0:/dev/ttyUSB0"
```

### dns

自定义 DNS 服务器，可以是单个值或列表的多个值。

```
dns: 8.8.8.8

dns:
  - 8.8.8.8
  - 9.9.9.9
```

### dns_search

自定义 DNS 搜索域。可以是单个值或列表。

```
dns_search: example.com

dns_search:
  - dc1.example.com
  - dc2.example.com
```

### entrypoint

覆盖容器默认的 entrypoint。

```
entrypoint: /code/entrypoint.sh
```

也可以是以下格式：

```
entrypoint:
    - php
    - -d
    - zend_extension=/usr/local/lib/php/extensions/no-debug-non-zts-20100525/xdebug.so
    - -d
    - memory_limit=-1
    - vendor/bin/phpunit
```

### env_file

从文件添加环境变量。可以是单个值或列表的多个值。

```
env_file: .env
```

也可以是列表格式：

```
env_file:
  - ./common.env
  - ./apps/web.env
  - /opt/secrets.env
```

### environment

添加环境变量。您可以使用数组或字典、任何布尔值，布尔值需要用引号引起来，以确保 YML 解析器不会将其转换为 True 或 False。

```
environment:
  RACK_ENV: development
  SHOW: 'true'
```

### expose

暴露端口，但不映射到宿主机，只被连接的服务访问。

仅可以指定内部端口为参数：

```
expose:
 - "3000"
 - "8000"
```

### extra_hosts

添加主机名映射。类似 docker client --add-host。

```
extra_hosts:
 - "somehost:162.242.195.82"
 - "otherhost:50.31.209.229"
```

以上会在此服务的内部容器中 /etc/hosts 创建一个具有 ip 地址和主机名的映射关系：

```
162.242.195.82  somehost
50.31.209.229   otherhost
```

### healthcheck

用于检测 docker 服务是否健康运行。

```
healthcheck:
  test: ["CMD", "curl", "-f", "http://localhost"] # 设置检测程序
  interval: 1m30s # 设置检测间隔
  timeout: 10s # 设置检测超时时间
  retries: 3 # 设置重试次数
  start_period: 40s # 启动后，多少秒开始启动检测程序
```

### image

指定容器运行的镜像。以下格式都可以：

```
image: redis
image: ubuntu:14.04
image: tutum/influxdb
image: example-registry.com:4000/postgresql
image: a4bc65fd # 镜像id
```

### logging

服务的日志记录配置。

driver：指定服务容器的日志记录驱动程序，默认值为json-file。有以下三个选项

```
driver: "json-file"
driver: "syslog"
driver: "none"
```

仅在 json-file 驱动程序下，可以使用以下参数，限制日志得数量和大小。

```
logging:
  driver: json-file
  options:
    max-size: "200k" # 单个文件大小为200k
    max-file: "10" # 最多10个文件
```

当达到文件限制上限，会自动删除旧得文件。

syslog 驱动程序下，可以使用 syslog-address 指定日志接收地址。

```
logging:
  driver: syslog
  options:
    syslog-address: "tcp://192.168.0.42:123"
```

### network_mode

设置网络模式。

```
network_mode: "bridge"
network_mode: "host"
network_mode: "none"
network_mode: "service:[service name]"
network_mode: "container:[container name/id]"
```

networks

配置容器连接的网络，引用顶级 networks 下的条目 。

```
services:
  some-service:
    networks:
      some-network:
        aliases:
         - alias1
      other-network:
        aliases:
         - alias2
networks:
  some-network:
    # Use a custom driver
    driver: custom-driver-1
  other-network:
    # Use a custom driver which takes special options
    driver: custom-driver-2
```

**aliases** ：同一网络上的其他容器可以使用服务名称或此别名来连接到对应容器的服务。

### restart

- no：是默认的重启策略，在任何情况下都不会重启容器。
- always：容器总是重新启动。
- on-failure：在容器非正常退出时（退出状态非0），才会重启容器。
- unless-stopped：在容器退出时总是重启容器，但是不考虑在Docker守护进程启动时就已经停止了的容器

```
restart: "no"
restart: always
restart: on-failure
restart: unless-stopped
```

注：swarm 集群模式，请改用 restart_policy。

### secrets

存储敏感数据，例如密码：

```
version: "3.1"
services:

mysql:
  image: mysql
  environment:
    MYSQL_ROOT_PASSWORD_FILE: /run/secrets/my_secret
  secrets:
    - my_secret

secrets:
  my_secret:
    file: ./my_secret.txt
```

### security_opt

修改容器默认的 schema 标签。

```
security-opt：
  - label:user:USER   # 设置容器的用户标签
  - label:role:ROLE   # 设置容器的角色标签
  - label:type:TYPE   # 设置容器的安全策略标签
  - label:level:LEVEL  # 设置容器的安全等级标签
```

### stop_grace_period

指定在容器无法处理 SIGTERM (或者任何 stop_signal 的信号)，等待多久后发送 SIGKILL 信号关闭容器。

```
stop_grace_period: 1s # 等待 1 秒
stop_grace_period: 1m30s # 等待 1 分 30 秒 
```

默认的等待时间是 10 秒。

### stop_signal

设置停止容器的替代信号。默认情况下使用 SIGTERM 。

以下示例，使用 SIGUSR1 替代信号 SIGTERM 来停止容器。

```
stop_signal: SIGUSR1
```

### sysctls

设置容器中的内核参数，可以使用数组或字典格式。

```
sysctls:
  net.core.somaxconn: 1024
  net.ipv4.tcp_syncookies: 0

sysctls:
  - net.core.somaxconn=1024
  - net.ipv4.tcp_syncookies=0
```

### tmpfs

在容器内安装一个临时文件系统。可以是单个值或列表的多个值。

```
tmpfs: /run

tmpfs:
  - /run
  - /tmp
```

### ulimits

覆盖容器默认的 ulimit。

```
ulimits:
  nproc: 65535
  nofile:
    soft: 20000
    hard: 40000
```

### volumes

将主机的数据卷或着文件挂载到容器里。

```
version: "3.7"
services:
  db:
    image: postgres:latest
    volumes:
      - "/localhost/postgres.sock:/var/run/postgres/postgres.sock"
      - "/localhost/data:/var/lib/postgresql/data"
```

# 数据处理

如果正在运行中的容器修改了已经存在的文件内容或者生成了新的内容，那么新产生的数据将会被复制 到读写层。 

Docker的镜像是分层设计的，**镜像层是只读的**，通过镜像启动的容器**添加了一层可读写的文件系统，**用 户写入的数据都保存在这一层当中。 

如果要将写入到容器的数据永久保存，则需要将容器中的数据保存到宿主机的指定目录，目前Docker的 数据类型分为两种分别是**数据卷和数据卷容器。**

```bash
[root@node1 ~]# docker inspect nginx | grep Dir
            "WorkingDir": "",
            "WorkingDir": "",
                "LowerDir": "/var/lib/docker/overlay2/ba20c7dd1c4dbeb171f52822ff2dc3407af690ab58d4d3fb9e4f3f9a2696f1e4/diff:/var/lib/docker/overlay2/42146cdfaaa8b65595e20fdd7e59d123bacee2f6b0cc42954442aaf727b1a993/diff:/var/lib/docker/overlay2/39ab36f68fab1205615bb1f31533f03d996afe31fc976926f709f082ae389e98/diff:/var/lib/docker/overlay2/eec8792d16596cf6aad8c9da480b7bfb44337e2b0583e7ca8d95e806328891aa/diff:/var/lib/docker/overlay2/a9b250837c4088d75750431659e5566b31b04cb9dd52748f761ccc8bb8646d42/diff",
                "MergedDir": "/var/lib/docker/overlay2/a4c79787dbc185ef2e5e27f97a15bfc7e84eacb192b3c5f9fcd895780abb639f/merged",
                "UpperDir": "/var/lib/docker/overlay2/a4c79787dbc185ef2e5e27f97a15bfc7e84eacb192b3c5f9fcd895780abb639f/diff",
                "WorkDir": "/var/lib/docker/overlay2/a4c79787dbc185ef2e5e27f97a15bfc7e84eacb192b3c5f9fcd895780abb639f/work"
LoweDir：image镜像层本身（只读）
UpperDir：容器的上层读写层
MergeDir：容器的文件系统，使用Union FS(联合文件系统)将镜像层和容器层合并给容器使用
WorkDir：容器在宿主机的工作目录
[root@docker-server1 ~]#
```



- 在容器中创建一个文件，观察文件

```bash
root@3ef443d9a62d:/# touch gjhpwd.txt
root@3ef443d9a62d:/# md5sum gjhpwd.txt
d41d8cd98f00b204e9800998ecf8427e  gjhpwd.txt
root@3ef443d9a62d:/# exit
exit
[root@node1 ~]# find / -name gjh*
/var/lib/docker/overlay2/ed3d0ba64eed881337a3be1b5615bcef2cf1f768cbf2836048a8e84a828ec563/diff/gjhpwd.txt
/var/lib/docker/overlay2/ed3d0ba64eed881337a3be1b5615bcef2cf1f768cbf2836048a8e84a828ec563/merged/gjhpwd.txt

```

- 删除容器后发现文件消失

```bash
[root@node1 ~]# docker ps -a
CONTAINER ID   IMAGE     COMMAND                   CREATED          STATUS          PORTS                               NAMES
3ef443d9a62d   nginx     "/docker-entrypoint.…"   10 minutes ago   Up 10 minutes   0.0.0.0:83->80/tcp, :::83->80/tcp   priceless_cray
[root@node1 ~]# docker rm -fv 3ef44
3ef44
[root@node1 ~]# find / -name gjh*
/var/db/sudo/lectured/gjh
/var/spool/mail/gjh
/home/gjh
[root@node1 ~]#

```

# 数据卷 

## 什么是数据卷？

 数据卷实际上就是宿主机上的目录或者是文件，可以被直接mount到容器当中使用。 实际生产环境中，需要针对不同类型的服务、不同类型的数据存储要求做相应的规划，最终保证服务的 可扩展性、稳定性以及数据的安全性。

![image-20230228173206250](http://cdn.gtrinee.top/image-20230228173206250.png)

## 数据卷案例 

创建目录并准备页面

```bash
[root@docker-server1 ~]# mkdir -p /data/web
[root@docker-server1 ~]# echo 'eaglslab nginx test!' > /data/web/index.html
[root@docker-server1 ~]# cat /data/web/index.html
eaglslab nginx test
```

- 启动两个容器并验证数据

```bash
[root@docker-server1 ~]# docker run -d -it --name web1 -v/data/web/:/usr/share/nginx/html/ -p 8080:80 nginx
588c494dc9098e0a43e15bce3162c34676dd981609edc32d46bf4beb59b9cf19
[root@docker-server1 ~]# docker run -d -it --name web2 -v data/web/:/usr/share/nginx/html/ -p 8081:80 nginx
ff6b3731a9ba3e0f91d2c8d89bb6573eb5e5a9b840163bc1122a9e5678d108b7
[root@docker-server1 ~]# curl 192.168.80.10:8080
eaglslab nginx test!
[root@docker-server1 ~]# curl 192.168.80.10:8081
eaglslab nginx test!
[root@docker-server1 ~]# echo 'hello world!' > /data/web/index.html
[root@docker-server1 ~]# curl 192.168.80.10:8080
hello world!
[root@docker-server1 ~]# curl 192.168.80.10:8081
hello world!
```

- 进入到容器内测试写入数据

```bash
[root@docker-server1 ~]# docker exec -it web1 bash
root@588c494dc909:/# echo 'docker test!' > /usr/share/nginx/html/index.html
[root@docker-server1 ~]# curl 192.168.80.10:8080
docker test!
[root@docker-server1 ~]# curl 192.168.80.10:8081
docker test!

```

- 尝试只读挂载

```bash
# 删除容器的时候不会删除宿主机的目录
[root@docker-server1 ~]# docker rm -fv web1
web1
[root@docker-server1 ~]# docker rm -fv web2
web2
[root@docker-server1 ~]# cat /data/web/index.html
docker test!
# 通过只读方式挂载以后，在容器内部是不允许修改数据的
[root@docker-server1 ~]# docker run -d -it --name web1 -v /data/web/:/usr/share/nginx/html/:ro -p 8080:80 nginx
a395b27958ca0cdcf52a86bd17813dcbcda4ed774895adcc99e85fc114ab84ff
[root@docker-server1 ~]# docker exec -it web1 bash
root@a395b27958ca:/# echo 123 > /usr/share/nginx/html/index.html
bash: /usr/share/nginx/html/index.html: Read-only file system
```

- 文件挂载

```bash
[root@docker-server1 ~]# docker run -d -it --name web2 -v /data/web/index.html:/usr/share/nginx/html/index.html:ro -p 8081:80 nginx
4b34c957372d314cdb0f85d7e2c65b095615adfe3051ae6b4266b7bacd50f374
[root@docker-server1 ~]# curl 192.168.80.10:8081
docker test!

```

## 数据卷特点

1. 数据卷是宿主机的目录或者文件，并且可以在多个容器之间共同使用 
2. 在宿主机对数据卷更改数据后会在所有容器里面会立即更新  
3. 数据卷的数据可以持久保存，即使删除使用该数据卷卷的容器也不影响 
4. 在容器里面写入数据不会影响到镜像本身。 
5. 需要挂载多个目录或者文件的时候可以使用多个-v参数指定 
6. 数据卷使用场景包括日志输出、静态web页面、应用配置文件、多容器间目录或文件共享

## 数据卷容器

数据卷容器功能是可以让数据在多个docker容器之间共享，即可以让B容器访问A容器的内容，而容器c 也可以访问A容器的内容，即先要创建一个后台运行的容器作为Server，用于卷提供，这个卷可以为其 他容器提供数据存储服务，其他使用此卷的容器作为客户端。

- 先启动一个卷容器Server

```bash
[root@docker-server1 ~]# docker run -d -it --name nginx-web -v /data/web/:/usr/share/nginx/html/:ro -p 8081:80 nginx

```

- 启动两个客户端容器

```bash
[root@docker-server1 ~]# docker run -d -it --name web1 -p 8082:80 --volumesfrom nginx-web nginx:latest
ac22faa405ec07c065042465cd7f9d456be891effdd5d13d9571b96ef9c550f7
[root@docker-server1 ~]# docker run -d -it --name web2 -p 8083:80 --volumesfrom nginx-web nginx:latest
e084845475b01dedfdae7362f6fbece7b5ab57ff6289c8c9bf08251f5ba448ed
```

- 访问测试

```bash
[root@docker-server1 ~]# curl 192.168.80.10:8081
docker test!
[root@docker-server1 ~]# curl 192.168.80.10:8082
docker test!
[root@docker-server1 ~]# curl 192.168.80.10:8083
docker test!
```

- 停止卷容器可以创建新容器

```bash
[root@docker-server1 ~]# docker stop nginx-web
nginx-web
[root@docker-server1 ~]# docker run -d -it --name web3 -p 8084:80 --volumesfrom nginx-web nginx:latest
6ebd95c132ee1a9e4b43d1849efc628ca7185187a59d70b3816ff16dd47b6e8e
[root@docker-server1 ~]# curl 192.168.80.10:8084
docker test!
```

- 删除卷容器之后不可以再创建新容器

```bash
[root@docker-server1 ~]# docker rm -fv nginx-web
nginx-web
[root@docker-server1 ~]# docker run -d -it --name web4 -p 8085:80 --volumesfrom nginx-web nginx:latest
docker: Error response from daemon: No such container: nginx-web.
See 'docker run --help'.
# 但是之前已经创建好的容器不会有任何影响
[root@docker-server1 ~]# curl 192.168.80.10:8082
docker test!
```

总结：

 在当前环境下，**即使把提供卷的容器Server删除，已经运行的容器Client依然可以使用挂载的卷，**因为 容器是通过挂载的方式访问数据的，**但是无法创建新的卷容器客户端**，但是再把卷容器Server创建后即 可正常创建卷容器client，此方式可以用于线上共享数据目录等环境，因为即使数据卷容器被删除了，其他已经运行的容器依然可以挂载使用 

数据卷容器可以作为共享的方式为其他容器提供文件共享，可以在生成中启动一个实例挂载本地的目 录，然后其他的容器分别挂载此容器的目录，即可保证各个容器之间的数据一致性。



# 容器之间的互联

在同一个宿主机上的容器之间可以通过端口映射的方式，经过宿主机中转进行互相访问呢，也可以通过 docker0网桥互相访问

## 直接互联

- 启动两个容器

```bash
[root@docker-server1 ~]# docker run -d -it nginx
[root@docker-server1 ~]# docker run -d -it nginx
```

- 安装相关工具包

```bash
root@855ab8d0bd74:/# apt update
root@855ab8d0bd74:/# apt install net-tools -y
root@855ab8d0bd74:/# apt install iputils-ping -y
root@855ab8d0bd74:/# apt install procps -y

```

- 检测网络连通性

```bash
root@855ab8d0bd74:/# ping 172.17.0.3 -c 2
PING 172.17.0.3 (172.17.0.3) 56(84) bytes of data.
64 bytes from 172.17.0.3: icmp_seq=1 ttl=64 time=0.052 ms
64 bytes from 172.17.0.3: icmp_seq=2 ttl=64 time=0.081 ms
--- 172.17.0.3 ping statistics ---
2 packets transmitted, 2 received, 0% packet loss, time 1ms
rtt min/avg/max/mdev = 0.052/0.066/0.081/0.016 ms

```

## 使用名称互联

- 查看web2容器的hosts文件，发现已经实现名称解析

```bash
[root@docker-server1 ~]# docker run -d -it --name web1 nginx
[root@docker-server1 ~]# docker run -d -it --name web2 --link web1 nginx

[root@docker-server1 ~]# docker exec -it web2 bash
root@8a3e9cee9e37:/# cat /etc/hosts
127.0.0.1 localhost
::1 localhost ip6-localhost ip6-loopback
fe00::0 ip6-localnet
ff00::0 ip6-mcastprefix
ff02::1 ip6-allnodes
ff02::2 ip6-allrouters
172.17.0.2 web1 622eff54876f
172.17.0.3 8a3e9cee9e37

#连通性测试

root@8a3e9cee9e37:/# ping web1 -c 2
PING web1 (172.17.0.2) 56(84) bytes of data.
64 bytes from web1 (172.17.0.2): icmp_seq=1 ttl=64 time=0.068 ms
64 bytes from web1 (172.17.0.2): icmp_seq=2 ttl=64 time=0.045 ms
--- web1 ping statistics ---
2 packets transmitted, 2 received, 0% packet loss, time 1ms
rtt min/avg/max/mdev = 0.045/0.056/0.068/0.013 ms
```



# Docker网络



## 四类网络模式

![image-20230228203322543](http://cdn.gtrinee.top/image-20230228203322543.png)

Docker服务安装完成之后，默认在每个宿主机会生成一个名称为docker0的网卡，其ip地址都是 172.17.0.1/16，并且会生成三种不同类型的网络



```bash
[root@docker-server1 ~]# ifconfig
docker0: flags=4099<UP,BROADCAST,MULTICAST> mtu 1500
        inet 172.17.0.1 netmask 255.255.0.0 broadcast 172.17.255.255
        ether 02:42:14:75:bf:4c txqueuelen 0 (Ethernet)
        RX packets 0 bytes 0 (0.0 B)
        RX errors 0 dropped 0 overruns 0 frame 0
        TX packets 0 bytes 0 (0.0 B)
        TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0
ens33: flags=4163<UP,BROADCAST,RUNNING,MULTICAST> mtu 1500
        inet 192.168.80.10 netmask 255.255.255.0 broadcast 192.168.80.255
        inet6 fe80::eaf3:dc40:2bf:6da2 prefixlen 64 scopeid 0x20<link>
        ether 00:0c:29:f4:79:06 txqueuelen 1000 (Ethernet)
        RX packets 13079 bytes 18637594 (17.7 MiB)
        RX errors 0 dropped 0 overruns 0 frame 0
        TX packets 1747 bytes 124995 (122.0 KiB)
        TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0
lo: flags=73<UP,LOOPBACK,RUNNING> mtu 65536
        inet 127.0.0.1 netmask 255.0.0.0
        inet6 ::1 prefixlen 128 scopeid 0x10<host>
        loop txqueuelen 1 (Local Loopback)
        RX packets 72 bytes 5776 (5.6 KiB)
        RX errors 0 dropped 0 overruns 0 frame 0
        TX packets 72 bytes 5776 (5.6 KiB)
        TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0
[root@docker-server1 ~]# docker network list
NETWORK ID NAME DRIVER SCOPE
787342a0d883 bridge bridge local
9a6d7244e807 host host local
beace8354cca none null local
```

在启动容器的时候可以使用--network参数去指定网络类型，默认使用的是bridge网络类型

## bridge模式

那我们之前在演示创建docker容器的时候其实是没有指定的网络模式的，如果不指定的话默认就会使用bridge模式，bridge本意是桥的意思，其实就是网桥模式，那我们怎么理解网桥，如果需要做类比的话，我们可以把网桥看成一个**二层的交换机设备**，我们来看下这张图：

交换机通信简图

![](F:\BaiduNetdiskDownload\14小时搞定k8s企业级devops实践\课件\DevOps训练营课件最新版(2020-04-11)\images\交换机.png)



网桥模式示意图

![](F:\BaiduNetdiskDownload\14小时搞定k8s企业级devops实践\课件\DevOps训练营课件最新版(2020-04-11)\images\docker-bridge.jpeg)



网桥在哪，查看网桥

```powershell
$ yum install -y bridge-utils
$ brctl show
bridge name     bridge id               STP enabled     interfaces
docker0         8000.0242b5fbe57b       no              veth3a496ed
```

有了网桥之后，那我们看下docker在启动一个容器的时候做了哪些事情才能实现容器间的互联互通

Docker 创建一个容器的时候，会执行如下操作：

- 创建一对虚拟接口/网卡，也就是veth pair；
- 本地主机一端桥接 到默认的 docker0 或指定网桥上，并具有一个唯一的名字，如 veth9953b75；
- 容器一端放到新启动的容器内部，并修改名字作为 eth0，这个网卡/接口只在容器的命名空间可见；
- 从网桥可用地址段中（也就是与该bridge对应的network）获取一个空闲地址分配给容器的 eth0
- 配置默认路由到网桥

那整个过程其实是docker自动帮我们完成的，清理掉所有容器，来验证。

```powershell
## 清掉所有容器
$ docker rm -f `docker ps -aq`
$ docker ps
$ brctl show # 查看网桥中的接口，目前没有

## 创建测试容器test1
$ docker run -d --name test1 nginx:alpine
$ brctl show # 查看网桥中的接口，已经把test1的veth端接入到网桥中
$ ip a |grep veth # 已在宿主机中可以查看到
$ docker exec -ti test1 sh 
/ # ifconfig  # 查看容器的eth0网卡及分配的容器ip
/ # route -n  # 观察默认网关都指向了网桥的地址，即所有流量都转向网桥，等于是在veth pair接通了网线
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
0.0.0.0         172.17.0.1      0.0.0.0         UG    0      0        0 eth0
172.17.0.0      0.0.0.0         255.255.0.0     U     0      0        0 eth0

# 再来启动一个测试容器，测试容器间的通信
$ docker run -d --name test2 nginx:alpine
$ docker exec -ti test sh
/ # sed -i 's/dl-cdn.alpinelinux.org/mirrors.tuna.tsinghua.edu.cn/g' /etc/apk/repositories
/ # apk add curl
/ # curl 172.17.0.8:80

## 为啥可以通信，因为两个容器是接在同一个网桥中的，通信其实是通过mac地址和端口的的记录来做转发的。test1访问test2，通过test1的eth0发送ARP广播，网桥会维护一份mac映射表，我们可以大概通过命令来看一下，
$ brctl showmacs docker0
## 这些mac地址是主机端的veth网卡对应的mac，可以查看一下
$ ip a 

```

我们如何知道网桥上的这些虚拟网卡与容器端是如何对应？

通过ifindex，网卡索引号

```powershell
## 查看test1容器的网卡索引
$ docker exec -ti test1 cat /sys/class/net/eth0/ifindex

## 主机中找到虚拟网卡后面这个@ifxx的值，如果是同一个值，说明这个虚拟网卡和这个容器的eth0网卡是配对的。
$ ip a |grep @if
```

整理脚本，快速查看对应：

```powershell
for container in $(docker ps -q); do
    iflink=`docker exec -it $container sh -c 'cat /sys/class/net/eth0/iflink'`
    iflink=`echo $iflink|tr -d '\r'`
    veth=`grep -l $iflink /sys/class/net/veth*/ifindex`
    veth=`echo $veth|sed -e 's;^.*net/\(.*\)/ifindex$;\1;'`
    echo $container:$veth
done
```



上面我们讲解了容器之间的通信，那么容器与宿主机的通信是如何做的？

![](F:\BaiduNetdiskDownload\14小时搞定k8s企业级devops实践\课件\DevOps训练营课件最新版(2020-04-11)\images\2017-11-30-docker-network-topology.png)



添加端口映射：

```powershell
## 启动容器的时候通过-p参数添加宿主机端口与容器内部服务端口的映射
$ docker run --name test -d -p 8088:80 nginx:alpine
$ curl localhost:8088
```

端口映射如何实现的？先来回顾iptables链表图

![](F:\BaiduNetdiskDownload\14小时搞定k8s企业级devops实践\课件\DevOps训练营课件最新版(2020-04-11)\images\iptables.png)



访问本机的8088端口，数据包会从流入方向进入本机，因此涉及到PREROUTING和INPUT链，我们是通过做宿主机与容器之间加的端口映射，所以肯定会涉及到端口转换，那哪个表是负责存储端口转换信息的呢，就是nat表，负责维护网络地址转换信息的。因此我们来查看一下PREROUTING链的nat表：

```powershell
$ iptables -t nat -nvL PREROUTING
Chain PREROUTING (policy ACCEPT 159 packets, 20790 bytes)
 pkts bytes target     prot opt in     out     source               destination
    3   156 DOCKER     all  --  *      *       0.0.0.0/0            0.0.0.0/0            ADDRTYPE match dst-type LOCAL
```

规则利用了iptables的addrtype拓展，匹配网络类型为本地的包，如何确定哪些是匹配本地，

```powershell
$ ip route show table local type local
local 127.0.0.0/8 dev lo proto kernel scope host src 127.0.0.1
local 127.0.0.1 dev lo proto kernel scope host src 127.0.0.1
local 172.17.0.1 dev docker0 proto kernel scope host src 172.17.0.1
local 192.168.136.133 dev ens33 proto kernel scope host src 192.168.136.133
```

也就是说目标地址类型匹配到这些的，会转发到我们的TARGET中，TARGET是动作，意味着对符合要求的数据包执行什么样的操作，最常见的为ACCEPT或者DROP，此处的TARGET为DOCKER，很明显DOCKER不是标准的动作，那DOCKER是什么呢？我们通常会定义自定义的链，这样把某类对应的规则放在自定义链中，然后把自定义的链绑定到标准的链路中，因此此处DOCKER 是自定义的链。那我们现在就来看一下DOCKER这个自定义链上的规则。

```powershell
$ iptables -t nat -nvL DOCKER
Chain DOCKER (2 references)                                                                                                
 pkts bytes target     prot opt in     out     source               destination                                            
    0     0 RETURN     all  --  docker0 *       0.0.0.0/0            0.0.0.0/0                                             
    0     0 DNAT       tcp  --  !docker0 *       0.0.0.0/0            0.0.0.0/0            tcp dpt:8088 to:172.17.0.2:80 

```

此条规则就是对主机收到的目的端口为8088的tcp流量进行DNAT转换，将流量发往172.17.0.2:80，172.17.0.2地址是不是就是我们上面创建的Docker容器的ip地址，流量走到网桥上了，后面就走网桥的转发就ok了。
所以，外界只需访问192.168.136.133:8088就可以访问到容器中的服务了。

 数据包在出口方向走POSTROUTING链，我们查看一下规则：

```powershell
$ iptables -t nat -nvL POSTROUTING
Chain POSTROUTING (policy ACCEPT 1099 packets, 67268 bytes)
 pkts bytes target     prot opt in     out     source               destination
   86  5438 MASQUERADE  all  --  *      !docker0  172.17.0.0/16        0.0.0.0/0
    0     0 MASQUERADE  tcp  --  *      *       172.17.0.4           172.17.0.4           tcp dpt:80
```

大家注意MASQUERADE这个动作是什么意思，其实是一种更灵活的SNAT，把源地址转换成主机的出口ip地址，那解释一下这条规则的意思:

这条规则会将源地址为172.17.0.0/16的包（也就是从Docker容器产生的包），并且不是从docker0网卡发出的，进行源地址转换，转换成主机网卡的地址。大概的过程就是ACK的包在容器里面发出来，会路由到网桥docker0，网桥根据宿主机的路由规则会转给宿主机网卡eth0，这时候包就从docker0网卡转到eth0网卡了，并从eth0网卡发出去，这时候这条规则就会生效了，把源地址换成了eth0的ip地址。

> 注意一下，刚才这个过程涉及到了网卡间包的传递，那一定要打开主机的ip_forward转发服务，要不然包转不了，服务肯定访问不到。

###### 抓包演示

我们先想一下，我们要抓哪个网卡的包

- 首先访问宿主机的8088端口，我们抓一下宿主机的eth0

  ```powershell
  $ tcpdump -i eth0 port 8088 -w host.cap
  ```

- 然后最终包会流入容器内，那我们抓一下容器内的eth0网卡

  ```powershell
  # 容器内安装一下tcpdump
  $ sed -i 's/dl-cdn.alpinelinux.org/mirrors.tuna.tsinghua.edu.cn/g' /etc/apk/repositories
  $ apk add tcpdump
  $ tcpdump -i eth0 port 80 -w container.cap
  ```

到另一台机器访问一下，

```powershell
$ curl 172.21.32.6:8088/
```

停止抓包，拷贝容器内的包到宿主机

```powershell
$ docker cp test:/root/container.cap /root/
```

把抓到的内容拷贝到本地，使用wireshark进行分析。

```powershell
$ scp root@172.21.32.6:/root/*.cap /d/packages
```

（wireshark合并包进行分析）

![](F:\BaiduNetdiskDownload\14小时搞定k8s企业级devops实践\课件\DevOps训练营课件最新版(2020-04-11)\images\docker-dnat.jpeg)

![](F:\BaiduNetdiskDownload\14小时搞定k8s企业级devops实践\课件\DevOps训练营课件最新版(2020-04-11)\images\docker-snat.jpeg)

进到容器内的包做DNAT，出去的包做SNAT，这样对外面来讲，根本就不知道机器内部是谁提供服务，其实这就和一个内网多个机器公用一个外网IP地址上网的效果是一样的，对吧，那这也属于NAT功能的一个常见的应用场景。

## none网络类型

在使用none模式后，docker容器不会进行任何网络配置，其没有网卡、没有ip也没有路由，因此默认无 法与外界进行通信，需要手动添加网卡配置ip等，所以极少使用

![image-20230228204256490](http://cdn.gtrinee.top/image-20230228204256490.png)



## container网络类型

这个模式指定新创建的容器和已经存在的一个容器共享一个 Network Namespace，而不是和宿主机共 享。新创建的容器不会创建自己的网卡，配置自己的 IP，而是和一个指定的容器共享 IP、端口范围等。 同样，两个容器除了网络方面，其他的如文件系统、进程列表等还是隔离的。两个容器的进程可以通过 lo 网卡设备通信。

![image-20230228204344029](http://cdn.gtrinee.top/image-20230228204344029.png)

```bash
[root@docker-server1 ~]# docker run -d -it --name web5 --network container:web1 nginx
83db4f9af6f3d9d42bbd57691fcf82ef06cbf1a5874750effa314a4ec242aaaa
```





## host网络类型

如果启动容器的时候使用host模式，那么这个容器将不会获得一个独立的Network Namespace，而是 和宿主机共用一个Network Namespace。容器将不会虚拟出自己的网卡，配置自己的IP等，而是使用宿 主机的IP和端口。 

使用host模式的容器可以直接使用宿主机的IP地址与外界通信，容器内部的服务端口也可以使用宿主机 的端口，不需要进行NAT，host最大的优势就是网络性能比较好，但是docker host上已经使用的端口就 不能再用了，网络的隔离性不好。

![image-20230228205355851](http://cdn.gtrinee.top/image-20230228205355851.png)

```bash
[root@docker-server1 ~]# docker run -d -it --name web7 --network host nginx
e90cb3bfc1a3fbd187319ac3b995b116feb37422534b03662d624680e35eb2bb
[root@docker-server1 ~]# docker exec -it web7 bash
root@docker-server1:/# ifconfig
docker0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST> mtu 1500
    inet 172.17.0.1 netmask 255.255.0.0 broadcast 172.17.255.255
    inet6 fe80::42:14ff:fe75:bf4c prefixlen 64 scopeid 0x20<link>
    ether 02:42:14:75:bf:4c txqueuelen 0 (Ethernet)
    RX packets 9647 bytes 394222 (384.9 KiB)
    RX errors 0 dropped 0 overruns 0 frame 0
    TX packets 10932 bytes 43303360 (41.2 MiB)
    TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0
ens33: flags=4163<UP,BROADCAST,RUNNING,MULTICAST> mtu 1500
    inet 192.168.80.10 netmask 255.255.255.0 broadcast 192.168.80.255
    inet6 fe80::eaf3:dc40:2bf:6da2 prefixlen 64 scopeid 0x20<link>
    ether 00:0c:29:f4:79:06 txqueuelen 1000 (Ethernet)
    RX packets 60855 bytes 81177548 (77.4 MiB)
    RX errors 0 dropped 0 overruns 0 frame 0
    TX packets 17770 bytes 1472014 (1.4 MiB)
    TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0
lo: flags=73<UP,LOOPBACK,RUNNING> mtu 65536
    inet 127.0.0.1 netmask 255.0.0.0
    inet6 ::1 prefixlen 128 scopeid 0x10<host>
    loop txqueuelen 1 (Local Loopback)
    RX packets 72 bytes 5776 (5.6 KiB)
    RX errors 0 dropped 0 overruns 0 frame 0
    TX packets 72 bytes 5776 (5.6 KiB)
    TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0

```

# 资源限制介绍

**默认情况下，容器没有资源限制**，可以使用主机内核调度程序允许的尽可能多的给定资源，**docker提供 了控制容器可以限制容器使用多少内存或者cpu的方法，设置docker run命令的运行时配置标志。** 

其中一些功能要求宿主机的内核支持Linux功能，要检查支持，可以使用docker info命令，如果内核中 金庸了某项功能，可能会在输出结尾处看到警告。 

对于Linux主机，**如果没有足够的内容来执行其他重要的系统任务，将会抛出OOM异常**（内存溢出、内存泄漏、内存异常），随后系统会开始杀死进程以释放内存，凡是运行在宿主机的进程都有可能被kill， 包括dockerd和其他的应用程序，如果重要的系统进程被kill，会导致和该进程相关的服务全部宕机。 

产生OOM异常时，Dockerd**尝试通过调整docker守护程序上的OOM优先级来减轻这些风险**，以便它比 系统上的其他进程更不可能被杀死，但是容器的OOM优先级未调整时单个容器被杀死的可能性更大（不推荐调整容器的优先级这种方式）。 

Linux会每个进程算一个分数，最终他会将分数最高的进程kill掉

```
/proc/PID/oom_score_adj #范围为-1000到1000，值越高越容易被宿主机kill掉，如果将该值设
置为-1000，则进程永远不会被宿主机kernel kill。
/proc/PID/oom_adj #范围为-17到+15，取值越高越容易被干掉，如果是-17,则表示不能被kill，
该设置参数的存在是为了和旧版本的Linux内核兼容。
/proc/PID/oom_score #这个值是系统综合进程的内存消耗量、CPU时间(utime+ stime)、存活时
间(uptime - start time)和oom_adj计算出的进程得分，消耗内存越多得分越高，越容易被宿主机
kernel强制杀死。

```

## 容器的内存限制 

Docker可以**强制执行硬性内存限制**，即只允许容器使用给定的内存大小 

Docker也可以执行**非硬性内存限制**，即容器可以使用尽可能多的内存，除非内核检测到主机上的内存不 够用了



## 内存限制参数

```
-m or --memory：容器可以使用的最大内存量，如果设置此选项，则允许的最小值为4m
--memory-swap：容器可以使用的交换分区和物理内存大小总和，必须要在设置了物理内存限制
的前提才能设置交换分区的限制，经常将内存交换到磁盘的应用程序会降低性能。如果该参数设置
未-1，则容器可以使用主机上swap的最大空间
--memory-swappiness：设置容器使用交换分区的倾向性，值越高表示越倾向于使用swap分区，
范围为0-100，0为能不用就不用，100为能用就用。
--kernel-memory：容器可以使用的最大内核内存量，最小为4m，由于内核内存于用户空间内存
隔离，因此无法于用户空间内存直接交换，因此内核内存不足的容器可能会阻塞宿主机主机资源，
这会对主机和其他容器或者其他服务进程产生影响，因此不要设置内核内存大小
--memory-reservation：允许指定小于--memory的软限制当Docker检测到主机上的争用或内存不
足时会激活该限制，如果使用--memory-reservation，则必须将其设置为低于--memory才能使其
优先。因为它是软限制，所以不能保证容器不超过限制。
--oom-kill-disable：默认情况下，发生OOM时kernel会杀死容器内进程，但是可以使用该参数可
以禁止oom发生在指定的容器上，仅在已设置-m选项的容器上禁用oom，如果-m参数未配置，产
生oom时主机为了释放内存还会杀死进程
```

如果一个容器未作内存使用限制，则该容器可以利用到系统内存最大空间，默认创建的容器没有做内存 资源限制

-  拉取容器压测工具镜像

```bash
[root@docker-server1 ~]# docker pull lorel/docker-stress-ng
[root@docker-server1 ~]# docker run -it --rm lorel/docker-stress-ng -help
```

- 使用压测工具开启两个工作进程，每个工作进程最大允许使用内存256M，且宿主机不限制当前容 器的最大内存

```bash
[root@docker-server1 ~]# docker run -it --rm --name test1 lorel/dockerstress-ng --vm 2 --vm-bytes 256m
stress-ng: info: [1] defaulting to a 86400 second run per stressor
stress-ng: info: [1] dispatching hogs: 2 vm
[root@docker-server1 ~]# docker stats
CONTAINER ID NAME CPU % MEM USAGE / LIMIT MEM % NET I/O
BLOCK I/O PIDS
3ca32774fc20 test1 185.16% 514.3MiB / 1.781GiB 28.21% 648B / 0B
0B / 0B 5
```

  
